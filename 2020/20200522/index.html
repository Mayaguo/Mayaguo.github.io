<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="手撕Redis6.0, JAVA,数据库,linux,个人技术">
    <meta name="description" content="一分耕耘，一分收获。">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>手撕Redis6.0 | GMaya</title>
    <link rel="icon" type="image/x-icon, image/vnd.microsoft.icon" href="/favicon.ico">

    <link rel="stylesheet" type="text/css" href="/libs/awesome/css/all.css">
    <link rel="stylesheet" type="text/css" href="/libs/materialize/materialize.min.css">
    <link rel="stylesheet" type="text/css" href="/libs/aos/aos.css">
    <link rel="stylesheet" type="text/css" href="/libs/animate/animate.min.css">
    <link rel="stylesheet" type="text/css" href="/libs/lightGallery/css/lightgallery.min.css">
    <link rel="stylesheet" type="text/css" href="/css/matery.css">
    <link rel="stylesheet" type="text/css" href="/css/my.css">

    <script src="/libs/jquery/jquery.min.js"></script>
    <script src="https://sdk.jinrishici.com/v2/browser/jinrishici.js" charset="utf-8"></script>
<meta name="generator" content="Hexo 4.2.0"><link rel="alternate" href="/atom.xml" title="GMaya" type="application/atom+xml">
<link rel="stylesheet" href="/css/prism-tomorrow.css" type="text/css"></head>


<body>
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/" class="waves-effect waves-light">
                    
                    <img src="/medias/mylogo.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">GMaya</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>首页</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>标签</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>分类</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>归档</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/about" class="waves-effect waves-light">
      
      <i class="fas fa-user-circle" style="zoom: 0.6;"></i>
      
      <span>关于</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/links" class="waves-effect waves-light">
      
      <i class="fas fa-address-book" style="zoom: 0.6;"></i>
      
      <span>友情链接</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="搜索" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/medias/mylogo.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">GMaya</div>
        <div class="logo-desc">
            
            一分耕耘，一分收获。
            
        </div>
    </div>

    

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			首页
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			标签
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			分类
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			归档
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/about" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-user-circle"></i>
			
			关于
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/links" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-address-book"></i>
			
			友情链接
		</a>
          
        </li>
        
        
    </ul>
</div>


        </div>

        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('https://s1.wailian.download/2020/05/22/ReichenbachFalls_ZH-CN7578535270_1920x1080.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">手撕Redis6.0</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <link rel="stylesheet" href="/libs/tocbot/tocbot.css">
<style>
    #articleContent h1::before,
    #articleContent h2::before,
    #articleContent h3::before,
    #articleContent h4::before,
    #articleContent h5::before,
    #articleContent h6::before {
        display: block;
        content: " ";
        height: 100px;
        margin-top: -100px;
        visibility: hidden;
    }

    #articleContent :focus {
        outline: none;
    }

    .toc-fixed {
        position: fixed;
        top: 64px;
    }

    .toc-widget {
        width: 345px;
        padding-left: 20px;
    }

    .toc-widget .toc-title {
        margin: 35px 0 15px 0;
        padding-left: 17px;
        font-size: 1.5rem;
        font-weight: bold;
        line-height: 1.5rem;
    }

    .toc-widget ol {
        padding: 0;
        list-style: none;
    }

    #toc-content {
        height: calc(100vh - 250px);
        overflow: auto;
    }

    #toc-content ol {
        padding-left: 10px;
    }

    #toc-content ol li {
        padding-left: 10px;
    }

    #toc-content .toc-link:hover {
        color: #42b983;
        font-weight: 700;
        text-decoration: underline;
    }

    #toc-content .toc-link::before {
        background-color: transparent;
        max-height: 25px;

        position: absolute;
        right: 23.5vw;
        display: block;
    }

    #toc-content .is-active-link {
        color: #42b983;
    }

    #floating-toc-btn {
        position: fixed;
        right: 15px;
        bottom: 76px;
        padding-top: 15px;
        margin-bottom: 0;
        z-index: 998;
    }

    #floating-toc-btn .btn-floating {
        width: 48px;
        height: 48px;
    }

    #floating-toc-btn .btn-floating i {
        line-height: 48px;
        font-size: 1.4rem;
    }
</style>
<div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/tags/Redis/">
                                <span class="chip bg-color">Redis</span>
                            </a>
                        
                            <a href="/tags/%E6%96%B0%E7%89%B9%E6%80%A7/">
                                <span class="chip bg-color">新特性</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/categories/Redis/" class="post-category">
                                Redis
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp;
                    2020-05-22
                </div>
                

                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>文章字数:&nbsp;&nbsp;
                    22.4k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>阅读时长:&nbsp;&nbsp;
                    115 分
                </div>
                

                
            </div>
        </div>
        <hr class="clearfix">
        <div class="card-content article-card-content">
            <div id="articleContent">
                <h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><blockquote>
<p>Redis 是完全开源免费的，遵守BSD协议，是一个高性能的key-value数据库。性能极高： Redis能读的速度是110000次/s,写的速度是81000次/s 。</p>
</blockquote>
<h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><p><code>Linux</code>下安装<code>Redis</code>。去年好像写过一次。。。<a href="https://blog.csdn.net/gfl1427097103/article/details/83037214" target="_blank" rel="noopener">传送门</a></p>
<h3 id="下载"><a href="#下载" class="headerlink" title="下载"></a>下载</h3><p>本次下载的是<code>Redis</code>官网最新稳定版本</p>
<pre class=" language-powershell"><code class="language-powershell"><span class="token comment" spellcheck="true"># wget http://download.redis.io/releases/redis-6.0.3.tar.gz</span></code></pre>
<h3 id="解压"><a href="#解压" class="headerlink" title="解压"></a>解压</h3><pre class=" language-powershell"><code class="language-powershell"><span class="token comment" spellcheck="true"># tar -zxvf redis-6.0.3.tar.gz</span></code></pre>
<p><code>注意</code>：解压完成，尽量检查一下Redis所依赖的gcc版本，版本过低会编译失败。需要gcc 4.9以上。</p>
<p><strong>升级gcc版本：</strong></p>
<pre class=" language-powershell"><code class="language-powershell">
<span class="token operator">/</span><span class="token operator">/</span> 检查gcc版本
<span class="token comment" spellcheck="true"># gcc -v </span>
<span class="token operator">/</span><span class="token operator">/</span> 升级gcc到9
<span class="token comment" spellcheck="true"># yum -y install centos-release-scl</span>
<span class="token comment" spellcheck="true"># yum -y install devtoolset-9-gcc devtoolset-9-gcc-c++ devtoolset-9-binutils</span>
<span class="token comment" spellcheck="true"># scl enable devtoolset-9 bash</span>
<span class="token operator">/</span><span class="token operator">/</span> 以上为临时使用，如果长期使用执行下方：
<span class="token comment" spellcheck="true"># echo "source /opt/rh/devtoolset-9/enable" >>/etc/profile</span></code></pre>
<h3 id="编译"><a href="#编译" class="headerlink" title="编译"></a>编译</h3><p>进入<code>redis-6.0.3</code>文件夹，进行编译。</p>
<pre class=" language-powershell"><code class="language-powershell"><span class="token comment" spellcheck="true"># make PREFIX=/usr/local/redis install</span></code></pre>
<p>安装成功会出现：</p>
<pre class=" language-powershell"><code class="language-powershell">Hint: It<span class="token string">'s a good idea to run '</span>make test' </code></pre>
<p>然后执行<code>make test</code>测试一下。最终出现：</p>
<pre class=" language-powershell"><code class="language-powershell">All tests passed without errors<span class="token operator">!</span></code></pre>
<p><code>注：</code>如果出现tcl之类的错误，解决办法：</p>
<pre class=" language-powershell"><code class="language-powershell"><span class="token comment" spellcheck="true"># yum install tcl</span></code></pre>
<h3 id="启动和关闭"><a href="#启动和关闭" class="headerlink" title="启动和关闭"></a>启动和关闭</h3><p><strong>直接启动：</strong><br>注意自己的<code>.conf</code>文件和<code>/bin/</code>的路径</p>
<pre class=" language-powershell"><code class="language-powershell"><span class="token comment" spellcheck="true"># ./bin/redis-server ./redis-6.0.3/redis.conf</span></code></pre>
<p><strong>后台启动：</strong><br>编辑<code>redis.conf</code>，将<code>daemonize on</code>修改为 <code>daemonize yes</code></p>
<pre class=" language-powershell"><code class="language-powershell"><span class="token comment" spellcheck="true"># vi redis.conf</span></code></pre>
<p>直接输入<code>/daemonize</code> 快速搜索，<code>n</code>是寻找下一个。找到位置之后，输入<code>a</code>开启编辑，然后<code>Esc</code>,输入<code>:wq</code>保存退出。再次使用上面的启动命令即可。</p>
<p><strong>查看是否启动成功</strong></p>
<pre class=" language-powershell"><code class="language-powershell"><span class="token comment" spellcheck="true"># ps -ef | grep redis</span></code></pre>
<p><strong>简单使用</strong></p>
<pre class=" language-powershell"><code class="language-powershell"><span class="token comment" spellcheck="true"># ./bin/redis-cli </span></code></pre>
<p><img src="https://img-blog.csdnimg.cn/20200521152124569.png" alt=""><br><strong>关闭方式一</strong></p>
<pre class=" language-powershell"><code class="language-powershell"><span class="token comment" spellcheck="true"># ./bin/redis-cli shutdown</span></code></pre>
<p><strong>关闭方式二</strong><br>先查找出<code>Redis</code>的端口号，然后直接<code>kill</code>掉</p>
<pre class=" language-powershell"><code class="language-powershell"><span class="token comment" spellcheck="true"># ps -ef | grep redis</span></code></pre>
<p><code>-9</code> 代表强制</p>
<pre class=" language-powershell"><code class="language-powershell"><span class="token comment" spellcheck="true"># kill -9 39491</span></code></pre>
<h2 id="配置用户名和密码"><a href="#配置用户名和密码" class="headerlink" title="配置用户名和密码"></a>配置用户名和密码</h2><h3 id="版本6-0之前"><a href="#版本6-0之前" class="headerlink" title="版本6.0之前"></a>版本<code>6.0</code>之前</h3><p>编辑<code>redis.conf</code>，将<code>requirepass</code> 注释打开，后面跟上自己想要设置的密码。重启<code>Redis</code>即可<br><img src="https://img-blog.csdnimg.cn/20200521184238598.png" alt=""><br>客户端连接输入密码的两种方式：<br>方式一：<br>先进入客户端，然后输入密码。</p>
<pre class=" language-powershell"><code class="language-powershell"><span class="token namespace">[root@localhost redis]</span><span class="token comment" spellcheck="true"># ./bin/redis-cli </span>
127<span class="token punctuation">.</span>0<span class="token punctuation">.</span>0<span class="token punctuation">.</span>1:6379> auth admin</code></pre>
<p>方式二：<br>直接进入并输入密码</p>
<pre class=" language-powershell"><code class="language-powershell"><span class="token comment" spellcheck="true"># ./bin/redis-cli -a admin</span></code></pre>
<h3 id="版本6-0之后"><a href="#版本6-0之后" class="headerlink" title="版本6.0之后"></a>版本<code>6.0</code>之后</h3><p>提供了ACL,可以设置用户名和密码。<br>官方文档<a href="https://redis.io/topics/acl" target="_blank" rel="noopener">https://redis.io/topics/acl</a><br>如果只是设置密码，那么用户名就是“default”<br><img src="https://img-blog.csdnimg.cn/20200521194053635.png" alt=""><br><strong>创建一个适用于生产环境的用户：</strong></p>
<p>假如我这个用户<code>redis</code>环境主要用于<code>gmaya-shop</code>项目<br>那么我规定，这个用户使用的时候，所有存放的<code>key</code>必须以<code>gmaya-shop:</code>开头，不然不允许访问。只允许此用户使用<code>get</code>，和<code>set</code>命令。</p>
<pre class=" language-powershell"><code class="language-powershell">127<span class="token punctuation">.</span>0<span class="token punctuation">.</span>0<span class="token punctuation">.</span>1:6379> acl setuser gmayashopredis on >gmayapassword <span class="token operator">+</span>get <span class="token operator">+</span><span class="token function">set</span> ~gmaya<span class="token operator">-</span>shop:<span class="token operator">*</span></code></pre>
<ul>
<li>用户名：<code>gmayashopredis</code></li>
<li>密码：<code>gmayapassword</code></li>
<li>可用命令：<code>get</code>，<code>set</code></li>
<li>可操作的key： <code>gmaya-shop:</code>作为前缀的<code>key</code></li>
</ul>
<p>此时设置两个key</p>
<pre class=" language-powershell"><code class="language-powershell">127<span class="token punctuation">.</span>0<span class="token punctuation">.</span>0<span class="token punctuation">.</span>1:6379> <span class="token function">set</span> aaa 111
OK
127<span class="token punctuation">.</span>0<span class="token punctuation">.</span>0<span class="token punctuation">.</span>1:6379> <span class="token function">set</span> gmaya<span class="token operator">-</span>shop:userid 1001 
OK
</code></pre>
<p>切换<code>gmayashopredis</code> 用户</p>
<pre class=" language-powershell"><code class="language-powershell">127<span class="token punctuation">.</span>0<span class="token punctuation">.</span>0<span class="token punctuation">.</span>1:6379> auth gmayashopredis gmayapassword</code></pre>
<p><strong>测试</strong></p>
<pre class=" language-powershell"><code class="language-powershell">127<span class="token punctuation">.</span>0<span class="token punctuation">.</span>0<span class="token punctuation">.</span>1:6379> get aaa
<span class="token punctuation">(</span>error<span class="token punctuation">)</span> NOPERM this user has no permissions to access one of the keys used as arguments
127<span class="token punctuation">.</span>0<span class="token punctuation">.</span>0<span class="token punctuation">.</span>1:6379> get gmaya<span class="token operator">-</span>shop:userid
<span class="token string">"1001"</span></code></pre>
<h3 id="ACL常用命令"><a href="#ACL常用命令" class="headerlink" title="ACL常用命令"></a>ACL常用命令</h3><p><strong>查看当前用户:</strong></p>
<pre class=" language-powershell"><code class="language-powershell">127<span class="token punctuation">.</span>0<span class="token punctuation">.</span>0<span class="token punctuation">.</span>1:6379> acl getuser gmayashopredis
1<span class="token punctuation">)</span> <span class="token string">"flags"</span>
2<span class="token punctuation">)</span> 1<span class="token punctuation">)</span> <span class="token string">"on"</span>
3<span class="token punctuation">)</span> <span class="token string">"passwords"</span>
4<span class="token punctuation">)</span> 1<span class="token punctuation">)</span> <span class="token string">"74a3fbd0037d8c4c44137eb226451df5e5458446a768df424da0fd2a9938f7ba"</span>
5<span class="token punctuation">)</span> <span class="token string">"commands"</span>
6<span class="token punctuation">)</span> <span class="token string">"-@all +set +get"</span>
7<span class="token punctuation">)</span> <span class="token string">"keys"</span>
8<span class="token punctuation">)</span> 1<span class="token punctuation">)</span> <span class="token string">"gmaya-shop:*"</span>
</code></pre>
<p><strong>查看所有命令：</strong></p>
<pre class=" language-powershell"><code class="language-powershell">127<span class="token punctuation">.</span>0<span class="token punctuation">.</span>0<span class="token punctuation">.</span>1:6379> acl <span class="token function">cat</span></code></pre>
<p><strong>增加命令减少命令：</strong></p>
<pre class=" language-powershell"><code class="language-powershell">127<span class="token punctuation">.</span>0<span class="token punctuation">.</span>0<span class="token punctuation">.</span>1:6379> acl setuser gmayashopredis <span class="token operator">-</span>get
OK
127<span class="token punctuation">.</span>0<span class="token punctuation">.</span>0<span class="token punctuation">.</span>1:6379> acl setuser gmayashopredis <span class="token operator">+</span>hget
OK
127<span class="token punctuation">.</span>0<span class="token punctuation">.</span>0<span class="token punctuation">.</span>1:6379> acl getuser gmayashopredis
1<span class="token punctuation">)</span> <span class="token string">"flags"</span>
2<span class="token punctuation">)</span> 1<span class="token punctuation">)</span> <span class="token string">"on"</span>
3<span class="token punctuation">)</span> <span class="token string">"passwords"</span>
4<span class="token punctuation">)</span> 1<span class="token punctuation">)</span> <span class="token string">"74a3fbd0037d8c4c44137eb226451df5e5458446a768df424da0fd2a9938f7ba"</span>
5<span class="token punctuation">)</span> <span class="token string">"commands"</span>
6<span class="token punctuation">)</span> <span class="token string">"-@all +set +hget"</span>
7<span class="token punctuation">)</span> <span class="token string">"keys"</span>
8<span class="token punctuation">)</span> 1<span class="token punctuation">)</span> <span class="token string">"gmaya-shop:*"</span>
</code></pre>
<p><strong>刷新key的范围：</strong></p>
<pre class=" language-powershell"><code class="language-powershell">127<span class="token punctuation">.</span>0<span class="token punctuation">.</span>0<span class="token punctuation">.</span>1:6379> acl setuser gmayashopredis resetkeys ~gmaya:<span class="token operator">*</span>
OK
127<span class="token punctuation">.</span>0<span class="token punctuation">.</span>0<span class="token punctuation">.</span>1:6379> acl getuser gmayashopredis
1<span class="token punctuation">)</span> <span class="token string">"flags"</span>
2<span class="token punctuation">)</span> 1<span class="token punctuation">)</span> <span class="token string">"on"</span>
3<span class="token punctuation">)</span> <span class="token string">"passwords"</span>
4<span class="token punctuation">)</span> 1<span class="token punctuation">)</span> <span class="token string">"74a3fbd0037d8c4c44137eb226451df5e5458446a768df424da0fd2a9938f7ba"</span>
5<span class="token punctuation">)</span> <span class="token string">"commands"</span>
6<span class="token punctuation">)</span> <span class="token string">"-@all +set +hget"</span>
7<span class="token punctuation">)</span> <span class="token string">"keys"</span>
8<span class="token punctuation">)</span> 1<span class="token punctuation">)</span> <span class="token string">"gmaya:*"</span>
</code></pre>
<p><strong>直接添加key：</strong></p>
<pre class=" language-powershell"><code class="language-powershell">127<span class="token punctuation">.</span>0<span class="token punctuation">.</span>0<span class="token punctuation">.</span>1:6379> acl setuser gmayashopredis ~shop:<span class="token operator">*</span>
OK
127<span class="token punctuation">.</span>0<span class="token punctuation">.</span>0<span class="token punctuation">.</span>1:6379> acl getuser gmayashopredis
1<span class="token punctuation">)</span> <span class="token string">"flags"</span>
2<span class="token punctuation">)</span> 1<span class="token punctuation">)</span> <span class="token string">"on"</span>
3<span class="token punctuation">)</span> <span class="token string">"passwords"</span>
4<span class="token punctuation">)</span> 1<span class="token punctuation">)</span> <span class="token string">"74a3fbd0037d8c4c44137eb226451df5e5458446a768df424da0fd2a9938f7ba"</span>
5<span class="token punctuation">)</span> <span class="token string">"commands"</span>
6<span class="token punctuation">)</span> <span class="token string">"-@all +set +hget"</span>
7<span class="token punctuation">)</span> <span class="token string">"keys"</span>
8<span class="token punctuation">)</span> 1<span class="token punctuation">)</span> <span class="token string">"gmaya:*"</span>
   2<span class="token punctuation">)</span> <span class="token string">"shop:*"</span>
</code></pre>
<p><strong>添加密码减少密码</strong></p>
<p>添加密码<code>123456</code>，减少密码<code>gmayapassword</code>，一个用户允许多个密码同时存在</p>
<pre class=" language-powershell"><code class="language-powershell">127<span class="token punctuation">.</span>0<span class="token punctuation">.</span>0<span class="token punctuation">.</span>1:6379> acl setuser gmayashopredis >123456
OK
127<span class="token punctuation">.</span>0<span class="token punctuation">.</span>0<span class="token punctuation">.</span>1:6379> acl setuser gmayashopredis &lt;gmayapassword</code></pre>
<h2 id="多线程"><a href="#多线程" class="headerlink" title="多线程"></a>多线程</h2><p>这次<code>6.0</code>版本加入了多线程模块。只有两个配置参数：<br>默认都是注释掉的。也就是不开启多线程</p>
<pre class=" language-powershell"><code class="language-powershell"><span class="token comment" spellcheck="true"># io-threads 4 # 开启线程数</span>
<span class="token comment" spellcheck="true"># io-threads-do-reads no # 是否开启多线程</span></code></pre>
<p>通过下面的官方配置里面的介绍分析：</p>
<ul>
<li><code>Redis</code>主要是单线程的，但是也有一些特定的线程操作，比如断开链接、缓慢的<code>I/O</code>访问和其他在侧线程上执行的操作。</li>
<li>默认情况下，线程是<code>禁用</code>的，我们建议只在拥有<code>至少4</code>个或更多内核的机器上启用线程，而保留至少一个备用内核。使用<code>8个以上</code>的线程不太可能有太大的帮助。我们还建议仅当您确实存在性能问题时才使用线程<code>I/O</code>，因为<code>Redis</code>实例能够使用相当大的<code>CPU</code>时间百分比，否则使用此特性是没有意义的。</li>
<li>例如，如果你有<code>4</code>个内核，尝试使用<code>2</code>或<code>3</code>个<code>I/O</code>线程，如果你有<code>8</code>个内核，尝试使用<code>6</code>个线程。</li>
<li>通常多线程读取不会有太大帮助。</li>
</ul>
<h2 id="Redis6-0配置文件解读"><a href="#Redis6-0配置文件解读" class="headerlink" title="Redis6.0配置文件解读"></a>Redis6.0配置文件解读</h2><p>自己把<code>redis</code>配置文件拷贝出来一份，一行一行翻译一下。如果有不对的，希望指出来，虚心学习。</p>
<p><code>redis.config</code>文件：<br>版本号：<code>6.0.3</code><br><code>注意：</code>你可能要花很长时间来阅读这个配置。</p>
<p><code>TODO:</code>有几个重点的地方，我还没来得及深入研究，大致已经清楚，后期肯定会写的。最近辞职回老家河南找工作了。</p>
<ul>
<li><input disabled="" type="checkbox"> 主从复制</li>
<li><input disabled="" type="checkbox"> 哨兵（Sentinel）</li>
<li><input disabled="" type="checkbox"> Redis Cluster</li>
</ul>
<pre class=" language-java"><code class="language-java"># Redis configuration file example<span class="token punctuation">.</span>
#
# Note that in order to read the configuration file<span class="token punctuation">,</span> Redis must be
# started with the file path as first argument<span class="token operator">:</span>
# GMaya总结<span class="token operator">:</span> redis在启动的时候<span class="token punctuation">,</span>指定固定的配置文件启动。
# <span class="token punctuation">.</span>/redis<span class="token operator">-</span>server <span class="token operator">/</span>path<span class="token operator">/</span>to<span class="token operator">/</span>redis<span class="token punctuation">.</span>conf

# Note on units<span class="token operator">:</span> when memory size is needed<span class="token punctuation">,</span> it is possible to specify
# it in the usual form of 1k 5GB 4M and so forth<span class="token operator">:</span>
#
# 1k <span class="token operator">=</span><span class="token operator">></span> <span class="token number">1000</span> bytes
# 1kb <span class="token operator">=</span><span class="token operator">></span> <span class="token number">1024</span> bytes
# 1m <span class="token operator">=</span><span class="token operator">></span> <span class="token number">1000000</span> bytes
# 1mb <span class="token operator">=</span><span class="token operator">></span> <span class="token number">1024</span><span class="token operator">*</span><span class="token number">1024</span> bytes
# 1g <span class="token operator">=</span><span class="token operator">></span> <span class="token number">1000000000</span> bytes
# 1gb <span class="token operator">=</span><span class="token operator">></span> <span class="token number">1024</span><span class="token operator">*</span><span class="token number">1024</span><span class="token operator">*</span><span class="token number">1024</span> bytes
#
# units are <span class="token keyword">case</span> insensitive so 1GB 1Gb 1gB are all the same<span class="token punctuation">.</span>

################################## INCLUDES ###################################

# Include one or more other config files here<span class="token punctuation">.</span>  This is useful <span class="token keyword">if</span> you
# have a standard template that goes to all Redis servers but also need
# to customize a few per<span class="token operator">-</span>server settings<span class="token punctuation">.</span>  Include files can include
# other files<span class="token punctuation">,</span> so use <span class="token keyword">this</span> wisely<span class="token punctuation">.</span>
#
# Notice option <span class="token string">"include"</span> won't be rewritten by command <span class="token string">"CONFIG REWRITE"</span>
# from admin or Redis Sentinel<span class="token punctuation">.</span> Since Redis always uses the last processed
# line as value of a configuration directive<span class="token punctuation">,</span> you'd better put includes
# at the beginning of <span class="token keyword">this</span> file to avoid overwriting config change at runtime<span class="token punctuation">.</span>
#
# If instead you are interested in using includes to override configuration
# options<span class="token punctuation">,</span> it is better to use include as the last line<span class="token punctuation">.</span>
# 引入其它配置文件
# include <span class="token operator">/</span>path<span class="token operator">/</span>to<span class="token operator">/</span>local<span class="token punctuation">.</span>conf
# include <span class="token operator">/</span>path<span class="token operator">/</span>to<span class="token operator">/</span>other<span class="token punctuation">.</span>conf

################################## MODULES #####################################

# Load modules at startup<span class="token punctuation">.</span> If the server is not able to load modules
# it will abort<span class="token punctuation">.</span> It is possible to use multiple loadmodule directives<span class="token punctuation">.</span>
#
# loadmodule <span class="token operator">/</span>path<span class="token operator">/</span>to<span class="token operator">/</span>my_module<span class="token punctuation">.</span>so
# loadmodule <span class="token operator">/</span>path<span class="token operator">/</span>to<span class="token operator">/</span>other_module<span class="token punctuation">.</span>so

################################## NETWORK #####################################

# By <span class="token keyword">default</span><span class="token punctuation">,</span> <span class="token keyword">if</span> no <span class="token string">"bind"</span> configuration directive is specified<span class="token punctuation">,</span> Redis listens
# <span class="token keyword">for</span> connections from all the network interfaces available on the server<span class="token punctuation">.</span>
# It is possible to listen to just one or multiple selected interfaces using
# the <span class="token string">"bind"</span> configuration directive<span class="token punctuation">,</span> followed by one or more IP addresses<span class="token punctuation">.</span>
# 默认情况下，如果没有指定“bind”配置指令，则Redis侦听
# 对于来自服务器上可用的所有网络接口的连接。
# 可以只监听一个或多个选定的接口
# “bind”配置指令，后面跟着一个或多个IP地址。
# Examples<span class="token operator">:</span>
#
# bind <span class="token number">192.168</span><span class="token punctuation">.</span><span class="token number">1.100</span> <span class="token number">10.0</span><span class="token punctuation">.</span><span class="token number">0.1</span>
# bind <span class="token number">127.0</span><span class="token punctuation">.</span><span class="token number">0.1</span> <span class="token operator">:</span><span class="token operator">:</span><span class="token number">1</span>
#
# <span class="token operator">~</span><span class="token operator">~</span><span class="token operator">~</span> WARNING <span class="token operator">~</span><span class="token operator">~</span><span class="token operator">~</span> If the computer running Redis is directly exposed to the
# internet<span class="token punctuation">,</span> binding to all the interfaces is dangerous and will expose the
# instance to everybody on the internet<span class="token punctuation">.</span> So by <span class="token keyword">default</span> we uncomment the
# following bind directive<span class="token punctuation">,</span> that will force Redis to listen only into
# the IPv4 loopback <span class="token keyword">interface</span> <span class="token class-name">address</span> <span class="token punctuation">(</span><span class="token keyword">this</span> means Redis will be able to
# accept connections only from clients running into the same computer it
# is running<span class="token punctuation">)</span><span class="token punctuation">.</span>
# 如果运行Redis的计算机直接暴露于
# 绑定到所有接口是危险的，将会暴露
# 互联网上的每个人。默认情况下，我们取消注释
# 遵循绑定指令，这将迫使Redis只监听
# IPv4环回接口地址<span class="token punctuation">(</span>这意味着Redis将能够
# 只接受来自与it运行在同一台计算机上的客户机的连接
# 正在运行<span class="token punctuation">)</span>。
# IF YOU ARE SURE YOU WANT YOUR INSTANCE TO LISTEN TO ALL THE INTERFACES
# JUST COMMENT THE FOLLOWING LINE<span class="token punctuation">.</span>
# 如果您确定希望实例侦听所有接口，注释下面的行。
# <span class="token operator">~</span><span class="token operator">~</span><span class="token operator">~</span><span class="token operator">~</span><span class="token operator">~</span><span class="token operator">~</span><span class="token operator">~</span><span class="token operator">~</span><span class="token operator">~</span><span class="token operator">~</span><span class="token operator">~</span><span class="token operator">~</span><span class="token operator">~</span><span class="token operator">~</span><span class="token operator">~</span><span class="token operator">~</span><span class="token operator">~</span><span class="token operator">~</span><span class="token operator">~</span><span class="token operator">~</span><span class="token operator">~</span><span class="token operator">~</span><span class="token operator">~</span><span class="token operator">~</span><span class="token operator">~</span><span class="token operator">~</span><span class="token operator">~</span><span class="token operator">~</span><span class="token operator">~</span><span class="token operator">~</span><span class="token operator">~</span><span class="token operator">~</span><span class="token operator">~</span><span class="token operator">~</span><span class="token operator">~</span><span class="token operator">~</span><span class="token operator">~</span><span class="token operator">~</span><span class="token operator">~</span><span class="token operator">~</span><span class="token operator">~</span><span class="token operator">~</span><span class="token operator">~</span><span class="token operator">~</span><span class="token operator">~</span><span class="token operator">~</span><span class="token operator">~</span><span class="token operator">~</span><span class="token operator">~</span><span class="token operator">~</span><span class="token operator">~</span><span class="token operator">~</span><span class="token operator">~</span><span class="token operator">~</span><span class="token operator">~</span><span class="token operator">~</span><span class="token operator">~</span><span class="token operator">~</span><span class="token operator">~</span><span class="token operator">~</span><span class="token operator">~</span><span class="token operator">~</span><span class="token operator">~</span><span class="token operator">~</span><span class="token operator">~</span><span class="token operator">~</span><span class="token operator">~</span><span class="token operator">~</span><span class="token operator">~</span><span class="token operator">~</span><span class="token operator">~</span><span class="token operator">~</span>
bind <span class="token number">127.0</span><span class="token punctuation">.</span><span class="token number">0.1</span>

# Protected mode is a layer of security protection<span class="token punctuation">,</span> in order to avoid that
# Redis instances left open on the internet are accessed and exploited<span class="token punctuation">.</span>
# GMaya总结： 保护模式开启时，需配置`bind ip`或者设置访问密码。
# 保护模式是一种安全防护层，以避免这种情况的发生
# 在internet上打开的Redis实例被访问和利用。
# When <span class="token keyword">protected</span> mode is on and <span class="token keyword">if</span><span class="token operator">:</span>
# 当保护模式开启时，如果<span class="token operator">:</span>
# <span class="token number">1</span><span class="token punctuation">)</span> The server is not binding explicitly to a set of addresses using the
#    <span class="token string">"bind"</span> directive<span class="token punctuation">.</span>
# 服务器没有使用“bind”指令显式地绑定到一组地址。，也就是说bind没有指定远程ip
# <span class="token number">2</span><span class="token punctuation">)</span> No password is configured<span class="token punctuation">.</span>
# 没有配置密码。
# The server only accepts connections from clients connecting from the
# IPv4 and IPv6 loopback addresses <span class="token number">127.0</span><span class="token punctuation">.</span><span class="token number">0.1</span> and <span class="token operator">:</span><span class="token operator">:</span><span class="token number">1</span><span class="token punctuation">,</span> and from Unix domain
# sockets<span class="token punctuation">.</span>
# 服务器只接受从IPv4和IPv6环回地址<span class="token number">127.0</span><span class="token punctuation">.</span><span class="token number">0.1</span>和<span class="token operator">:</span><span class="token operator">:</span><span class="token number">1</span>，来自Unix域套接字。
# By <span class="token keyword">default</span> <span class="token keyword">protected</span> mode is enabled<span class="token punctuation">.</span> You should disable it only <span class="token keyword">if</span>
# you are sure you want clients from other hosts to connect to Redis
# even <span class="token keyword">if</span> no authentication is configured<span class="token punctuation">,</span> nor a specific set of interfaces
# are explicitly listed using the <span class="token string">"bind"</span> directive<span class="token punctuation">.</span>
# 默认情况下，受保护模式是启用的。您应该仅在以下情况下禁用它
# 您确定希望来自其他主机的客户端连接到Redis
# 即使没有配置任何身份验证，也没有一组特定的接口
# 使用“bind”指令显式列出。
<span class="token keyword">protected</span><span class="token operator">-</span>mode yes

# Accept connections on the specified port<span class="token punctuation">,</span> <span class="token keyword">default</span> is <span class="token function">6379</span> <span class="token punctuation">(</span>IANA #<span class="token number">815344</span><span class="token punctuation">)</span><span class="token punctuation">.</span>
# If port <span class="token number">0</span> is specified Redis will not listen on a TCP socket<span class="token punctuation">.</span>
# 接受指定端口上的连接，默认为<span class="token function">6379</span> <span class="token punctuation">(</span>IANA #<span class="token number">815344</span><span class="token punctuation">)</span>。
# 如果端口<span class="token number">0</span>被指定，Redis将不会监听TCP套接字。
port <span class="token number">6379</span>

# TCP <span class="token function">listen</span><span class="token punctuation">(</span><span class="token punctuation">)</span> backlog<span class="token punctuation">.</span>
# 此参数和`somaxconn`确定了`TCP`连接中已完成队列<span class="token punctuation">(</span>完成三次握手之后<span class="token punctuation">)</span>的长度。
# 取两者最小值。当高并发的时候，可以考虑增加`somaxconn`的值，然后增加`tcp<span class="token operator">-</span>backlog`。
# In high requests<span class="token operator">-</span>per<span class="token operator">-</span>second environments you need an high backlog in order
# to avoid slow clients connections issues<span class="token punctuation">.</span> Note that the Linux kernel
# will silently truncate it to the value of <span class="token operator">/</span>proc<span class="token operator">/</span>sys<span class="token operator">/</span>net<span class="token operator">/</span>core<span class="token operator">/</span>somaxconn so
# make sure to raise both the value of somaxconn and tcp_max_syn_backlog
# in order to get the desired effect<span class="token punctuation">.</span>
# 在每秒请求数很高的环境中，您需要按顺序进行高backlog
# 以避免慢速客户端连接问题。注意Linux内核
# 是否会静默地将其截断为<span class="token operator">/</span>proc<span class="token operator">/</span>sys<span class="token operator">/</span>net<span class="token operator">/</span>core<span class="token operator">/</span>somaxconn的值
# 确保同时提高somaxconn和tcp_max_syn_backlog的值
# 以达到预期的效果。
tcp<span class="token operator">-</span>backlog <span class="token number">511</span>

# Unix socket<span class="token punctuation">.</span>
#
# Specify the path <span class="token keyword">for</span> the Unix socket that will be used to listen <span class="token keyword">for</span>
# incoming connections<span class="token punctuation">.</span> There is no <span class="token keyword">default</span><span class="token punctuation">,</span> so Redis will not listen
# on a unix socket when not specified<span class="token punctuation">.</span>
#
# unixsocket <span class="token operator">/</span>tmp<span class="token operator">/</span>redis<span class="token punctuation">.</span>sock
# unixsocketperm <span class="token number">700</span>

# Close the connection after a client is idle <span class="token keyword">for</span> N <span class="token function">seconds</span> <span class="token punctuation">(</span><span class="token number">0</span> to disable<span class="token punctuation">)</span>
# 在客户端空闲N秒后关闭连接<span class="token punctuation">(</span><span class="token number">0</span>表示禁用<span class="token punctuation">)</span>
timeout <span class="token number">0</span>

# TCP keepalive<span class="token punctuation">.</span>
# 表示将周期性的使用SO_KEEPALIVE检测客户端是否还处于健康状态，避免服务器一直阻塞。
# If non<span class="token operator">-</span>zero<span class="token punctuation">,</span> use SO_KEEPALIVE to send TCP ACKs to clients in absence
# of communication<span class="token punctuation">.</span> This is useful <span class="token keyword">for</span> two reasons<span class="token operator">:</span>
# 如果非零，使用SO_KEEPALIVE在客户端不存在时发送TCP ack
# 的沟通。这样做有两个原因<span class="token operator">:</span>
# <span class="token number">1</span><span class="token punctuation">)</span> Detect dead peers<span class="token punctuation">.</span>
# 发现死去的客户端
# <span class="token number">2</span><span class="token punctuation">)</span> Take the connection alive from the point of view of network
#    equipment in the middle<span class="token punctuation">.</span>
# 从网络设备的角度来看，连接在中间是活的
# On Linux<span class="token punctuation">,</span> the specified <span class="token function">value</span> <span class="token punctuation">(</span>in seconds<span class="token punctuation">)</span> is the period used to send ACKs<span class="token punctuation">.</span>
# Note that to close the connection the <span class="token keyword">double</span> of the time is needed<span class="token punctuation">.</span>
# On other kernels the period depends on the kernel configuration<span class="token punctuation">.</span>
# 在Linux上，指定的值<span class="token punctuation">(</span>以秒为单位<span class="token punctuation">)</span>是用于发送ack的周期。
# 注意，关闭连接需要双倍的时间。
# 在其他内核上，周期取决于内核配置。
# A reasonable value <span class="token keyword">for</span> <span class="token keyword">this</span> option is <span class="token number">300</span> seconds<span class="token punctuation">,</span> which is the <span class="token keyword">new</span>
# Redis <span class="token keyword">default</span> starting with Redis <span class="token number">3.2</span><span class="token punctuation">.</span><span class="token number">1</span><span class="token punctuation">.</span>
# 这个选项的合理值是<span class="token number">300</span>秒，这是新的值
# Redis默认从Redis <span class="token number">3.2</span><span class="token punctuation">.</span><span class="token number">1</span>开始。
tcp<span class="token operator">-</span>keepalive <span class="token number">300</span>

################################# TLS<span class="token operator">/</span>SSL #####################################

# By <span class="token keyword">default</span><span class="token punctuation">,</span> TLS<span class="token operator">/</span>SSL is disabled<span class="token punctuation">.</span> To enable it<span class="token punctuation">,</span> the <span class="token string">"tls-port"</span> configuration
# directive can be used to define TLS<span class="token operator">-</span>listening ports<span class="token punctuation">.</span> To enable TLS on the
# <span class="token keyword">default</span> port<span class="token punctuation">,</span> use<span class="token operator">:</span>
#
# port <span class="token number">0</span>
# tls<span class="token operator">-</span>port <span class="token number">6379</span>

# Configure a X<span class="token number">.509</span> certificate and <span class="token keyword">private</span> key to use <span class="token keyword">for</span> authenticating the
# server to connected clients<span class="token punctuation">,</span> masters or cluster peers<span class="token punctuation">.</span>  These files should be
# PEM formatted<span class="token punctuation">.</span>
#
# tls<span class="token operator">-</span>cert<span class="token operator">-</span>file redis<span class="token punctuation">.</span>crt 
# tls<span class="token operator">-</span>key<span class="token operator">-</span>file redis<span class="token punctuation">.</span>key

# Configure a DH parameters file to enable Diffie<span class="token operator">-</span><span class="token function">Hellman</span> <span class="token punctuation">(</span>DH<span class="token punctuation">)</span> key exchange<span class="token operator">:</span>
#
# tls<span class="token operator">-</span>dh<span class="token operator">-</span>params<span class="token operator">-</span>file redis<span class="token punctuation">.</span>dh

# Configure a CA <span class="token function">certificate</span><span class="token punctuation">(</span>s<span class="token punctuation">)</span> bundle or directory to authenticate TLS<span class="token operator">/</span>SSL
# clients and peers<span class="token punctuation">.</span>  Redis requires an explicit configuration of at least one
# of these<span class="token punctuation">,</span> and will not implicitly use the system wide configuration<span class="token punctuation">.</span>
#
# tls<span class="token operator">-</span>ca<span class="token operator">-</span>cert<span class="token operator">-</span>file ca<span class="token punctuation">.</span>crt
# tls<span class="token operator">-</span>ca<span class="token operator">-</span>cert<span class="token operator">-</span>dir <span class="token operator">/</span>etc<span class="token operator">/</span>ssl<span class="token operator">/</span>certs

# By <span class="token keyword">default</span><span class="token punctuation">,</span> <span class="token function">clients</span> <span class="token punctuation">(</span>including replica servers<span class="token punctuation">)</span> on a TLS port are required
# to authenticate using valid client side certificates<span class="token punctuation">.</span>
#
# It is possible to disable authentication using <span class="token keyword">this</span> directive<span class="token punctuation">.</span>
#
# tls<span class="token operator">-</span>auth<span class="token operator">-</span>clients no

# By <span class="token keyword">default</span><span class="token punctuation">,</span> a Redis replica does not attempt to establish a TLS connection
# with its master<span class="token punctuation">.</span>
#
# Use the following directive to enable TLS on replication links<span class="token punctuation">.</span>
#
# tls<span class="token operator">-</span>replication yes

# By <span class="token keyword">default</span><span class="token punctuation">,</span> the Redis Cluster bus uses a plain TCP connection<span class="token punctuation">.</span> To enable
# TLS <span class="token keyword">for</span> the bus protocol<span class="token punctuation">,</span> use the following directive<span class="token operator">:</span>
#
# tls<span class="token operator">-</span>cluster yes
# and include <span class="token string">"TLSv1"</span><span class="token punctuation">,</span> <span class="token string">"TLSv1.1"</span><span class="token punctuation">,</span> <span class="token string">"TLSv1.2"</span><span class="token punctuation">,</span> <span class="token string">"TLSv1.3"</span> <span class="token punctuation">(</span>OpenSSL <span class="token operator">>=</span> <span class="token number">1.1</span><span class="token punctuation">.</span><span class="token number">1</span><span class="token punctuation">)</span> 
#
# tls<span class="token operator">-</span>protocols TLSv1<span class="token number">.2</span>

# Configure allowed ciphers<span class="token punctuation">.</span>  See the <span class="token function">ciphers</span><span class="token punctuation">(</span>1ssl<span class="token punctuation">)</span> manpage <span class="token keyword">for</span> more information
# about the syntax of <span class="token keyword">this</span> string<span class="token punctuation">.</span>
#
# Note<span class="token operator">:</span> <span class="token keyword">this</span> configuration applies only to <span class="token operator">&lt;=</span> TLSv1<span class="token number">.2</span><span class="token punctuation">.</span>
#
# tls<span class="token operator">-</span>ciphers DEFAULT<span class="token operator">:</span><span class="token operator">!</span>MEDIUM

# Configure allowed TLSv1<span class="token number">.3</span> ciphersuites<span class="token punctuation">.</span>  See the <span class="token function">ciphers</span><span class="token punctuation">(</span>1ssl<span class="token punctuation">)</span> manpage <span class="token keyword">for</span> more
# information about the syntax of <span class="token keyword">this</span> string<span class="token punctuation">,</span> and specifically <span class="token keyword">for</span> TLSv1<span class="token number">.3</span>
# ciphersuites<span class="token punctuation">.</span>
#
# tls<span class="token operator">-</span>ciphersuites TLS_CHACHA20_POLY1305_SHA256

# When choosing a cipher<span class="token punctuation">,</span> use the server's preference instead of the client
# preference<span class="token punctuation">.</span> By <span class="token keyword">default</span><span class="token punctuation">,</span> the server follows the client's preference<span class="token punctuation">.</span>
#
# tls<span class="token operator">-</span>prefer<span class="token operator">-</span>server<span class="token operator">-</span>ciphers yes

################################# GENERAL #####################################

# By <span class="token keyword">default</span> Redis does not run as a daemon<span class="token punctuation">.</span> Use <span class="token string">'yes'</span> <span class="token keyword">if</span> you need it<span class="token punctuation">.</span>
# Note that Redis will write a pid file in <span class="token operator">/</span>var<span class="token operator">/</span>run<span class="token operator">/</span>redis<span class="token punctuation">.</span>pid when daemonized<span class="token punctuation">.</span>
# 默认情况下，Redis不作为守护进程运行。如果你需要，使用“yes”。
# 请注意，Redis将在<span class="token operator">/</span>var<span class="token operator">/</span>run<span class="token operator">/</span> Redis中写入一个pid文件。监控pid。
daemonize yes

# If you run Redis from upstart or systemd<span class="token punctuation">,</span> Redis can interact with your
# supervision tree<span class="token punctuation">.</span> Options<span class="token operator">:</span>
# 如果你从upstart或systemd运行Redis<span class="token punctuation">,</span> Redis可以与你的管理树交互。选项<span class="token operator">:</span>
#   supervised no      <span class="token operator">-</span> no supervision interaction 没有监督互动
#   supervised upstart <span class="token operator">-</span> signal upstart by putting Redis into SIGSTOP mode
# 通过将Redis置于SIGSTOP模式来启动信号
#   supervised systemd <span class="token operator">-</span> signal systemd by writing READY<span class="token operator">=</span><span class="token number">1</span> to $NOTIFY_SOCKET
# signal systemd将READY <span class="token operator">=</span> <span class="token number">1</span>写入$ NOTIFY_SOCKET
#   supervised auto    <span class="token operator">-</span> detect upstart or systemd method based on
#                        UPSTART_JOB or NOTIFY_SOCKET environment variables
# 检测upstart或systemd方法基于 UPSTART_JOB或NOTIFY_SOCKET环境变量
# Note<span class="token operator">:</span> these supervision methods only signal <span class="token string">"process is ready."</span>
# 注意<span class="token operator">:</span>这些监督方法只表明“过程准备好了”。
#       They <span class="token keyword">do</span> not enable continuous liveness pings back to your supervisor<span class="token punctuation">.</span>
supervised no

# If a pid file is specified<span class="token punctuation">,</span> Redis writes it where specified at startup
# and removes it at exit<span class="token punctuation">.</span>
# 如果指定了pid文件，Redis会在启动时将其写入指定的位置
# 并在退出时删除它。
# When the server runs non daemonized<span class="token punctuation">,</span> no pid file is created <span class="token keyword">if</span> none is
# specified in the configuration<span class="token punctuation">.</span> When the server is daemonized<span class="token punctuation">,</span> the pid file
# is used even <span class="token keyword">if</span> not specified<span class="token punctuation">,</span> defaulting to <span class="token string">"/var/run/redis.pid"</span><span class="token punctuation">.</span>
# 当服务器运行非守护进程时，如果没有pid文件，则不创建pid文件
# 在配置中指定。当服务器以守护进程运行时，pid文件
# 即使未指定，默认也使用“<span class="token operator">/</span>var<span class="token operator">/</span>run<span class="token operator">/</span>redis<span class="token punctuation">.</span>pid”。
# Creating a pid file is best effort<span class="token operator">:</span> <span class="token keyword">if</span> Redis is not able to create it
# nothing bad happens<span class="token punctuation">,</span> the server will start and run normally<span class="token punctuation">.</span>
# 创建一个pid文件是最好的努力，如果Redis不能创建它
# 没有什么不好的事情发生，服务器将正常启动和运行。（最好创建它，但是不创建也没事。）
pidfile <span class="token operator">/</span>var<span class="token operator">/</span>run<span class="token operator">/</span>redis_6379<span class="token punctuation">.</span>pid

# Specify the server verbosity level<span class="token punctuation">.</span>
# 指定服务器详细日志级别。
# This can be one of<span class="token operator">:</span>
# <span class="token function">debug</span> <span class="token punctuation">(</span>a lot of information<span class="token punctuation">,</span> useful <span class="token keyword">for</span> development<span class="token operator">/</span>testing<span class="token punctuation">)</span>
# 大量的信息，对开发<span class="token operator">/</span>测试非常有用
# <span class="token function">verbose</span> <span class="token punctuation">(</span>many rarely useful info<span class="token punctuation">,</span> but not a mess like the debug level<span class="token punctuation">)</span>
# 很多很少有用的信息，但不像调试级别那么混乱
# <span class="token function">notice</span> <span class="token punctuation">(</span>moderately verbose<span class="token punctuation">,</span> what you want in production probably<span class="token punctuation">)</span>
# 有些冗长，这可能是您在生产环境中需要的
# <span class="token function">warning</span> <span class="token punctuation">(</span>only very important <span class="token operator">/</span> critical messages are logged<span class="token punctuation">)</span>
# 只记录非常重要<span class="token operator">/</span>关键的消息
loglevel notice

# Specify the log file name<span class="token punctuation">.</span> Also the empty string can be used to force
# Redis to log on the standard output<span class="token punctuation">.</span> Note that <span class="token keyword">if</span> you use standard
# output <span class="token keyword">for</span> logging but daemonize<span class="token punctuation">,</span> logs will be sent to <span class="token operator">/</span>dev<span class="token operator">/</span>null
# 指定日志文件名。此外，还可以使用空字符串强制Redis登录标准输出。
# 注意，如果使用标准输出进行日志记录，但是使用守护进程运行，那么日志将被发送到<span class="token operator">/</span>dev<span class="token operator">/</span>null
logfile <span class="token string">""</span>

# To enable logging to the system logger<span class="token punctuation">,</span> just set <span class="token string">'syslog-enabled'</span> to yes<span class="token punctuation">,</span>
# and optionally update the other syslog parameters to suit your needs<span class="token punctuation">.</span>
# 要启用系统日志记录器的日志功能，只需将<span class="token string">'syslog-enabled'</span>设置为yes，
# 并可选地更新其他syslog参数以满足您的需要。
# syslog<span class="token operator">-</span>enabled no

# Specify the syslog identity<span class="token punctuation">.</span>
# 指定syslog标识。
# syslog<span class="token operator">-</span>ident redis

# Specify the syslog facility<span class="token punctuation">.</span> Must be USER or between LOCAL0<span class="token operator">-</span>LOCAL7<span class="token punctuation">.</span>
# 指定syslog功能。必须是USER或介于LOCAL0<span class="token operator">-</span>LOCAL7之间。
# syslog<span class="token operator">-</span>facility local0

# Set the number of databases<span class="token punctuation">.</span> The <span class="token keyword">default</span> database is DB <span class="token number">0</span><span class="token punctuation">,</span> you can select
# a different one on a per<span class="token operator">-</span>connection basis using SELECT <span class="token operator">&lt;</span>dbid<span class="token operator">></span> where
# dbid is a number between <span class="token number">0</span> and <span class="token string">'databases'</span><span class="token operator">-</span><span class="token number">1</span>
# 设置数据库的数量。默认数据库是DB <span class="token number">0</span>，您可以选择
# 在每个连接的基础上使用SELECT <span class="token operator">&lt;</span>dbid<span class="token operator">></span>，其中
# dbid是一个介于<span class="token number">0</span>和‘databases’<span class="token operator">-</span><span class="token number">1</span>之间的数字。（也就是<span class="token number">0</span>到<span class="token number">15</span>）
databases <span class="token number">16</span>

# By <span class="token keyword">default</span> Redis shows an ASCII art logo only when started to log to the
# standard output and <span class="token keyword">if</span> the standard output is a TTY<span class="token punctuation">.</span> Basically <span class="token keyword">this</span> means
# that normally a logo is displayed only in interactive sessions<span class="token punctuation">.</span>
# 默认情况下，Redis只在开始登录时显示一个ASCII art徽标
# 标准输出，如果标准输出是TTY。基本上这意味着
# 标志通常只在交互式会话中显示。

# However it is possible to force the pre<span class="token operator">-</span><span class="token number">4.0</span> behavior and always show a
# ASCII art logo in startup logs by setting the following option to yes<span class="token punctuation">.</span>
# 然而，强制执行<span class="token number">4.0</span>之前的行为并总是显示a是可能的
# 通过将以下选项设置为yes，可以在启动日志中显示ASCII art徽标。
always<span class="token operator">-</span>show<span class="token operator">-</span>logo yes

################################ SNAPSHOTTING  ################################
# 持久化：RDB快照！！！！重点！
# Save the DB on disk<span class="token operator">:</span>
#    将数据库保存在磁盘上<span class="token operator">:</span>
#   save <span class="token operator">&lt;</span>seconds<span class="token operator">></span> <span class="token operator">&lt;</span>changes<span class="token operator">></span>
#
#   Will save the DB <span class="token keyword">if</span> both the given number of seconds and the given
#   number of write operations against the DB occurred<span class="token punctuation">.</span>
#    如果给定的秒数和给定的对该DB的写操作数同时发生，则将保存该DB。

#   In the example below the behaviour will be to save<span class="token operator">:</span>
#   在下面的例子中，行为将被保存<span class="token operator">:</span>
#   after <span class="token number">900</span> <span class="token function">sec</span> <span class="token punctuation">(</span><span class="token number">15</span> min<span class="token punctuation">)</span> <span class="token keyword">if</span> at least <span class="token number">1</span> key changed
#   在<span class="token number">900</span>秒<span class="token punctuation">(</span><span class="token number">15</span>分钟<span class="token punctuation">)</span>后，如果至少改变了一个键
#   after <span class="token number">300</span> <span class="token function">sec</span> <span class="token punctuation">(</span><span class="token number">5</span> min<span class="token punctuation">)</span> <span class="token keyword">if</span> at least <span class="token number">10</span> keys changed
#   <span class="token number">300</span>秒后<span class="token punctuation">(</span><span class="token number">5</span>分钟<span class="token punctuation">)</span>如果至少<span class="token number">10</span>个键改变
#   after <span class="token number">60</span> sec <span class="token keyword">if</span> at least <span class="token number">10000</span> keys changed
#   <span class="token number">60</span>秒后如果至少<span class="token number">10000</span>个键改变

#   Note<span class="token operator">:</span> you can disable saving completely by commenting out all <span class="token string">"save"</span> lines<span class="token punctuation">.</span>
#   注意<span class="token operator">:</span>您可以通过注释掉所有“保存”行来完全禁用保存。
#   It is also possible to remove all the previously configured save
#   points by adding a save directive with a single empty string argument
#   like in the following example<span class="token operator">:</span>
#   也可以删除以前配置的所有save
#   通过添加一个带有单个空字符串参数的save指令来获得
#   就像下面的例子<span class="token operator">:</span>
#   save <span class="token string">""</span>

save <span class="token number">900</span> <span class="token number">1</span>
save <span class="token number">300</span> <span class="token number">10</span>
save <span class="token number">60</span> <span class="token number">10000</span>

# By <span class="token keyword">default</span> Redis will stop accepting writes <span class="token keyword">if</span> RDB snapshots are enabled
# <span class="token punctuation">(</span>at least one save point<span class="token punctuation">)</span> and the latest background save failed<span class="token punctuation">.</span>
# This will make the user <span class="token function">aware</span> <span class="token punctuation">(</span>in a hard way<span class="token punctuation">)</span> that data is not persisting
# on disk properly<span class="token punctuation">,</span> otherwise chances are that no one will notice and some
# disaster will happen<span class="token punctuation">.</span>
# 默认情况下，如果启用了RDB快照<span class="token punctuation">,</span>
# <span class="token punctuation">(</span>至少一个保存点<span class="token punctuation">)</span>和最新的后台保存失败<span class="token punctuation">,</span>Redis将停止接受写操作<span class="token punctuation">.</span>
# 这将使用户<span class="token punctuation">(</span>以一种困难的方式<span class="token punctuation">)</span>意识到数据不是持久的
# 正确地存储在磁盘上，否则没有人会注意到灾难将会发生。

# If the background saving process will start working again Redis will
# automatically allow writes again<span class="token punctuation">.</span>
# 如果后台保存过程将再次开始工作，Redis将自动允许再次写入。

# However <span class="token keyword">if</span> you have setup your proper monitoring of the Redis server
# and persistence<span class="token punctuation">,</span> you may want to disable <span class="token keyword">this</span> feature so that Redis will
# <span class="token keyword">continue</span> to work as usual even <span class="token keyword">if</span> there are problems with disk<span class="token punctuation">,</span>
# permissions<span class="token punctuation">,</span> and so forth<span class="token punctuation">.</span>
# 但是，如果您已经设置了对Redis服务器的适当监视
# 和持久性，你可能想要禁用这个功能，这样Redis会
# 继续正常工作，即使有问题的磁盘，
# 权限等等。
# GMaya总结：如果存储数据（持久化）失败，则停止写入。
stop<span class="token operator">-</span>writes<span class="token operator">-</span>on<span class="token operator">-</span>bgsave<span class="token operator">-</span>error yes

# Compress string objects using LZF when dump <span class="token punctuation">.</span>rdb databases<span class="token operator">?</span>
# 在转储<span class="token punctuation">.</span>rdb数据库时使用LZF压缩字符串对象<span class="token operator">?</span>
# For <span class="token keyword">default</span> that<span class="token string">'s set to '</span>yes<span class="token string">' as it'</span>s almost always a win<span class="token punctuation">.</span>
# 默认情况下，它被设置为“yes”。
# If you want to save some CPU in the saving child set it to <span class="token string">'no'</span> but
# the dataset will likely be bigger <span class="token keyword">if</span> you have compressible values or keys<span class="token punctuation">.</span>
# GMaya总结：是否开启对rdb持久化文件的压缩
rdbcompression yes

# Since version <span class="token number">5</span> of RDB a CRC64 checksum is placed at the end of the file<span class="token punctuation">.</span>
# This makes the format more resistant to corruption but there is a performance
# hit to <span class="token function">pay</span> <span class="token punctuation">(</span>around <span class="token number">10</span><span class="token operator">%</span><span class="token punctuation">)</span> when saving and loading RDB files<span class="token punctuation">,</span> so you can disable it
# <span class="token keyword">for</span> maximum performances<span class="token punctuation">.</span>
# 是否CRC64校验rdb文件，会有一定的性能损失（大概<span class="token number">10</span><span class="token operator">%</span>）。
# RDB files created with checksum disabled have a checksum of zero that will
# tell the loading code to skip the check<span class="token punctuation">.</span>
# 禁用校验和创建的RDB文件的校验和为零
# 告诉加载代码跳过检查。
rdbchecksum yes

# The filename where to dump the DB
# rdb文件的名字。
dbfilename dump<span class="token punctuation">.</span>rdb

# Remove RDB files used by replication in instances without persistence
# enabled<span class="token punctuation">.</span> By <span class="token keyword">default</span> <span class="token keyword">this</span> option is disabled<span class="token punctuation">,</span> however there are environments
# where <span class="token keyword">for</span> regulations or other security concerns<span class="token punctuation">,</span> RDB files persisted on
# disk by masters in order to feed replicas<span class="token punctuation">,</span> or stored on disk by replicas
# in order to load them <span class="token keyword">for</span> the initial synchronization<span class="token punctuation">,</span> should be deleted
# ASAP<span class="token punctuation">.</span> Note that <span class="token keyword">this</span> option ONLY WORKS in instances that have both AOF
# and RDB persistence disabled<span class="token punctuation">,</span> otherwise is completely ignored<span class="token punctuation">.</span>
# 删除实例中复制使用的RDB文件，但不删除持久性
# 启用。默认情况下，这个选项是禁用的，但是有一些环境
# 对于法规或其他安全问题，RDB文件在哪里持久存在
# 主服务器通过磁盘来提供副本，或通过副本存储在磁盘上
# 为了加载它们进行初始同步，应该删除它们
# 尽快。注意，这个选项只在同时具有AOF的实例中起作用
# 并且禁用了RDB持久性，否则将完全忽略。

# An <span class="token function">alternative</span> <span class="token punctuation">(</span>and sometimes better<span class="token punctuation">)</span> way to obtain the same effect is
# to use diskless replication on both master and replicas instances<span class="token punctuation">.</span> However
# in the <span class="token keyword">case</span> of replicas<span class="token punctuation">,</span> diskless is not always an option<span class="token punctuation">.</span>
# 另一种<span class="token punctuation">(</span>有时是更好的<span class="token punctuation">)</span>达到同样效果的方法是
#在主实例和副本实例上使用无磁盘复制。然而
#在副本的情况下，无磁盘并不总是一个选择。
rdb<span class="token operator">-</span>del<span class="token operator">-</span>sync<span class="token operator">-</span>files no

# The working directory<span class="token punctuation">.</span>
# 数据库存放目录。
# The DB will be written inside <span class="token keyword">this</span> directory<span class="token punctuation">,</span> with the filename specified
# above using the <span class="token string">'dbfilename'</span> configuration directive<span class="token punctuation">.</span>
# DB将在此目录中写入，并指定文件名
# 上面使用<span class="token string">'dbfilename'</span>配置指令。
# The Append Only File will also be created inside <span class="token keyword">this</span> directory<span class="token punctuation">.</span>
# 仅追加文件也将在此目录中创建（AOF文件也在这个目录创建）
# Note that you must specify a directory here<span class="token punctuation">,</span> not a file name<span class="token punctuation">.</span>
# 注意，这里必须指定一个目录，而不是文件名。
dir <span class="token punctuation">.</span>/

################################# REPLICATION #################################

# Master<span class="token operator">-</span>Replica replication<span class="token punctuation">.</span> Use replicaof to make a Redis instance a copy of
# another Redis server<span class="token punctuation">.</span> A few things to understand ASAP about Redis replication<span class="token punctuation">.</span>
# 主从复制
#   <span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span>      <span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">-</span><span class="token operator">+</span>
#   <span class="token operator">|</span>      Master      <span class="token operator">|</span> <span class="token operator">--</span><span class="token operator">-</span><span class="token operator">></span> <span class="token operator">|</span>    Replica    <span class="token operator">|</span>
#   <span class="token operator">|</span> <span class="token punctuation">(</span>receive writes<span class="token punctuation">)</span> <span class="token operator">|</span>      <span class="token operator">|</span>  <span class="token punctuation">(</span>exact copy<span class="token punctuation">)</span> <span class="token operator">|</span>
#   <span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span>      <span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">-</span><span class="token operator">+</span>
#
# <span class="token number">1</span><span class="token punctuation">)</span> Redis replication is asynchronous<span class="token punctuation">,</span> but you can configure a master to
#    stop accepting writes <span class="token keyword">if</span> it appears to be not connected with at least
#    a given number of replicas<span class="token punctuation">.</span>
# Redis复制是异步的，但是您可以配置一个主服务器来停止接受写操作，如果它看起来至少没有连接到给定数量的副本。
# <span class="token number">2</span><span class="token punctuation">)</span> Redis replicas are able to perform a partial resynchronization with the
#    master <span class="token keyword">if</span> the replication link is lost <span class="token keyword">for</span> a relatively small amount of
#    time<span class="token punctuation">.</span> You may want to configure the replication backlog <span class="token function">size</span> <span class="token punctuation">(</span>see the next
#    sections of <span class="token keyword">this</span> file<span class="token punctuation">)</span> with a sensible value depending on your needs<span class="token punctuation">.</span>
# <span class="token number">3</span><span class="token punctuation">)</span> Replication is automatic and does not need user intervention<span class="token punctuation">.</span> After a
#    network partition replicas automatically <span class="token keyword">try</span> to reconnect to masters
#    and resynchronize with them<span class="token punctuation">.</span>
# GMaya总结：<span class="token number">5.0</span>及之后版本replicaof代替了slaveof<span class="token punctuation">.</span>
# 在这里配置属于永久配置，replicaof 主ip  主端口。只有从的需要配置，主的不需要
# replicaof <span class="token operator">&lt;</span>masterip<span class="token operator">></span> <span class="token operator">&lt;</span>masterport<span class="token operator">></span>

# If the master is password <span class="token keyword">protected</span> <span class="token punctuation">(</span>using the <span class="token string">"requirepass"</span> configuration
# directive below<span class="token punctuation">)</span> it is possible to tell the replica to authenticate before
# starting the replication synchronization process<span class="token punctuation">,</span> otherwise the master will
# refuse the replica request<span class="token punctuation">.</span>
# 如果主服务器是密码保护的<span class="token punctuation">(</span>使用下面的“requirepass”配置指令<span class="token punctuation">)</span>，可以在启动复制同步进程之前告诉副本进行身份验证，否则主服务器将拒绝副本请求。
# 也就是如果你的主设置了密码，这个地方需要写上主的密码，才能连接上
# masterauth <span class="token operator">&lt;</span>master<span class="token operator">-</span>password<span class="token operator">></span>
#
# However <span class="token keyword">this</span> is not enough <span class="token keyword">if</span> you are using Redis <span class="token function">ACLs</span> <span class="token punctuation">(</span><span class="token keyword">for</span> Redis version
# <span class="token number">6</span> or greater<span class="token punctuation">)</span><span class="token punctuation">,</span> and the <span class="token keyword">default</span> user is not capable of running the PSYNC
# command and<span class="token operator">/</span>or other commands needed <span class="token keyword">for</span> replication<span class="token punctuation">.</span> In <span class="token keyword">this</span> <span class="token keyword">case</span> it's
# better to configure a special user to use with replication<span class="token punctuation">,</span> and specify the
# masteruser configuration as such<span class="token operator">:</span>
# 但是，如果您使用的是Redis <span class="token function">acl</span><span class="token punctuation">(</span>适用于Redis版本<span class="token number">6</span>或更高版本<span class="token punctuation">)</span>，并且默认用户不能运行PSYNC命令和<span class="token operator">/</span>或复制所需的其他命令，那么这还不够。
# 在这种情况下，最好配置一个特殊用户与复制一起使用，并指定masteruser配置如下<span class="token operator">:</span>
# masteruser <span class="token operator">&lt;</span>username<span class="token operator">></span>
#
# When masteruser is specified<span class="token punctuation">,</span> the replica will authenticate against its
# master using the <span class="token keyword">new</span> <span class="token class-name">AUTH</span> form<span class="token operator">:</span> AUTH <span class="token operator">&lt;</span>username<span class="token operator">></span> <span class="token operator">&lt;</span>password<span class="token operator">></span><span class="token punctuation">.</span>

# When a replica loses its connection with the master<span class="token punctuation">,</span> or when the replication
# is still in progress<span class="token punctuation">,</span> the replica can act in two different ways<span class="token operator">:</span>
# 当副本失去与主副本的连接时，或者复制仍在进行时，副本可以以两种不同的方式执行操作<span class="token operator">:</span>
# <span class="token number">1</span><span class="token punctuation">)</span> <span class="token keyword">if</span> replica<span class="token operator">-</span>serve<span class="token operator">-</span>stale<span class="token operator">-</span>data is set to <span class="token string">'yes'</span> <span class="token punctuation">(</span>the <span class="token keyword">default</span><span class="token punctuation">)</span> the replica will
#    still reply to client requests<span class="token punctuation">,</span> possibly with out of date data<span class="token punctuation">,</span> or the
#    data set may just be empty <span class="token keyword">if</span> <span class="token keyword">this</span> is the first synchronization<span class="token punctuation">.</span>
#  如果replica<span class="token operator">-</span>serve<span class="token operator">-</span>stale<span class="token operator">-</span>data被设置为“yes”<span class="token punctuation">(</span>默认值<span class="token punctuation">)</span>，则副本将执行此操作
#  仍然响应客户端请求，可能是数据过期，或者如果这是第一次同步，那么数据集可能是空的。
# <span class="token number">2</span><span class="token punctuation">)</span> <span class="token keyword">if</span> replica<span class="token operator">-</span>serve<span class="token operator">-</span>stale<span class="token operator">-</span>data is set to <span class="token string">'no'</span> the replica will reply with
#    an error <span class="token string">"SYNC with master in progress"</span> to all the kind of commands
#    but to INFO<span class="token punctuation">,</span> replicaOF<span class="token punctuation">,</span> AUTH<span class="token punctuation">,</span> PING<span class="token punctuation">,</span> SHUTDOWN<span class="token punctuation">,</span> REPLCONF<span class="token punctuation">,</span> ROLE<span class="token punctuation">,</span> CONFIG<span class="token punctuation">,</span>
#    SUBSCRIBE<span class="token punctuation">,</span> UNSUBSCRIBE<span class="token punctuation">,</span> PSUBSCRIBE<span class="token punctuation">,</span> PUNSUBSCRIBE<span class="token punctuation">,</span> PUBLISH<span class="token punctuation">,</span> PUBSUB<span class="token punctuation">,</span>
#    COMMAND<span class="token punctuation">,</span> POST<span class="token punctuation">,</span> HOST<span class="token operator">:</span> and LATENCY<span class="token punctuation">.</span>
# 如果replica<span class="token operator">-</span>serve<span class="token operator">-</span>stale<span class="token operator">-</span>data被设置为“no”
# 除了INFO<span class="token punctuation">,</span> replicaOF<span class="token punctuation">,</span> AUTH<span class="token punctuation">,</span> PING<span class="token punctuation">,</span> SHUTDOWN<span class="token punctuation">,</span> REPLCONF<span class="token punctuation">,</span> ROLE<span class="token punctuation">,</span> CONFIG，订阅，取消订阅，PSUBSCRIBE<span class="token punctuation">,</span> PUNSUBSCRIBE，发布，PUBSUB，命令，发布，主机<span class="token operator">:</span>和延迟。
# 其他的都会返回“与主进程同步”错误
replica<span class="token operator">-</span>serve<span class="token operator">-</span>stale<span class="token operator">-</span>data yes

# You can configure a replica instance to accept writes or not<span class="token punctuation">.</span> Writing against
# a replica instance may be useful to store some ephemeral <span class="token function">data</span> <span class="token punctuation">(</span>because data
# written on a replica will be easily deleted after resync with the master<span class="token punctuation">)</span> but
# may also cause problems <span class="token keyword">if</span> clients are writing to it because of a
# misconfiguration<span class="token punctuation">.</span>
#
# Since Redis <span class="token number">2.6</span> by <span class="token keyword">default</span> replicas are read<span class="token operator">-</span>only<span class="token punctuation">.</span>
# 默认情况下Redis <span class="token number">2.6</span>的副本是只读的。
# Note<span class="token operator">:</span> read only replicas are not designed to be exposed to untrusted clients
# on the internet<span class="token punctuation">.</span> It's just a protection layer against misuse of the instance<span class="token punctuation">.</span>
# Still a read only replica exports by <span class="token keyword">default</span> all the administrative commands
# such as CONFIG<span class="token punctuation">,</span> DEBUG<span class="token punctuation">,</span> and so forth<span class="token punctuation">.</span> To a limited extent you can improve
# security of read only replicas using <span class="token string">'rename-command'</span> to shadow all the
# administrative <span class="token operator">/</span> dangerous commands<span class="token punctuation">.</span>
# 也就是从库只允许读，不允许写，读写分离啊
replica<span class="token operator">-</span>read<span class="token operator">-</span>only yes

# Replication SYNC strategy<span class="token operator">:</span> disk or socket<span class="token punctuation">.</span>
# 复制同步策略<span class="token operator">:</span>磁盘或套接字。
# New <span class="token class-name">replicas</span> and reconnecting replicas that are not able to <span class="token keyword">continue</span> the
# replication process just receiving differences<span class="token punctuation">,</span> need to <span class="token keyword">do</span> what is called a
# <span class="token string">"full synchronization"</span><span class="token punctuation">.</span> An RDB file is transmitted from the master to the
# replicas<span class="token punctuation">.</span>
#
# The transmission can happen in two different ways<span class="token operator">:</span>
#
# <span class="token number">1</span><span class="token punctuation">)</span> Disk<span class="token operator">-</span>backed<span class="token operator">:</span> The Redis master creates a <span class="token keyword">new</span> <span class="token class-name">process</span> that writes the RDB
#                 file on disk<span class="token punctuation">.</span> Later the file is transferred by the parent
#                 process to the replicas incrementally<span class="token punctuation">.</span>
# <span class="token number">2</span><span class="token punctuation">)</span> Diskless<span class="token operator">:</span> The Redis master creates a <span class="token keyword">new</span> <span class="token class-name">process</span> that directly writes the
#              RDB file to replica sockets<span class="token punctuation">,</span> without touching the disk at all<span class="token punctuation">.</span>
#
# With disk<span class="token operator">-</span>backed replication<span class="token punctuation">,</span> <span class="token keyword">while</span> the RDB file is generated<span class="token punctuation">,</span> more replicas
# can be queued and served with the RDB file as soon as the current child
# producing the RDB file finishes its work<span class="token punctuation">.</span> With diskless replication instead
# once the transfer starts<span class="token punctuation">,</span> <span class="token keyword">new</span> <span class="token class-name">replicas</span> arriving will be queued and a <span class="token keyword">new</span>
# transfer will start when the current one terminates<span class="token punctuation">.</span>
#
# When diskless replication is used<span class="token punctuation">,</span> the master waits a configurable amount of
# <span class="token function">time</span> <span class="token punctuation">(</span>in seconds<span class="token punctuation">)</span> before starting the transfer in the hope that multiple
# replicas will arrive and the transfer can be parallelized<span class="token punctuation">.</span>
#
# With slow disks and <span class="token function">fast</span> <span class="token punctuation">(</span>large bandwidth<span class="token punctuation">)</span> networks<span class="token punctuation">,</span> diskless replication
# works better<span class="token punctuation">.</span>
# 对于慢速磁盘和快速<span class="token punctuation">(</span>大带宽<span class="token punctuation">)</span>网络，无磁盘复制工作得更好。
# 主从数据复制是否使用无硬盘复制功能。
repl<span class="token operator">-</span>diskless<span class="token operator">-</span>sync no

# When diskless replication is enabled<span class="token punctuation">,</span> it is possible to configure the delay
# the server waits in order to spawn the child that transfers the RDB via socket
# to the replicas<span class="token punctuation">.</span>
# 当启用无磁盘复制时，可以配置服务器等待的延迟，以生成通过套接字传输RDB的子节点的副本。
#
# This is important since once the transfer starts<span class="token punctuation">,</span> it is not possible to serve
# <span class="token keyword">new</span> <span class="token class-name">replicas</span> arriving<span class="token punctuation">,</span> that will be queued <span class="token keyword">for</span> the next RDB transfer<span class="token punctuation">,</span> so the
# server waits a delay in order to let more replicas arrive<span class="token punctuation">.</span>
#
# The delay is specified in seconds<span class="token punctuation">,</span> and by <span class="token keyword">default</span> is <span class="token number">5</span> seconds<span class="token punctuation">.</span> To disable
# it entirely just set it to <span class="token number">0</span> seconds and the transfer will start ASAP<span class="token punctuation">.</span>
# diskless复制的延迟时间
repl<span class="token operator">-</span>diskless<span class="token operator">-</span>sync<span class="token operator">-</span>delay <span class="token number">5</span>

# <span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">-</span>
# WARNING<span class="token operator">:</span> RDB diskless load is experimental<span class="token punctuation">.</span> Since in <span class="token keyword">this</span> setup the replica
# does not immediately store an RDB on disk<span class="token punctuation">,</span> it may cause data loss during
# failovers<span class="token punctuation">.</span> RDB diskless load <span class="token operator">+</span> Redis modules not handling I<span class="token operator">/</span>O reads may also
# cause Redis to abort in <span class="token keyword">case</span> of I<span class="token operator">/</span>O errors during the initial synchronization
# stage with the master<span class="token punctuation">.</span> Use only <span class="token keyword">if</span> your <span class="token keyword">do</span> what you are doing<span class="token punctuation">.</span>
# <span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">-</span>
#
# Replica can load the RDB it reads from the replication link directly from the
# socket<span class="token punctuation">,</span> or store the RDB to a file and read that file after it was completely
# recived from the master<span class="token punctuation">.</span>
#
# In many cases the disk is slower than the network<span class="token punctuation">,</span> and storing and loading
# the RDB file may increase replication <span class="token function">time</span> <span class="token punctuation">(</span>and even increase the master's
# Copy on Write memory and salve buffers<span class="token punctuation">)</span><span class="token punctuation">.</span>
# However<span class="token punctuation">,</span> parsing the RDB file directly from the socket may mean that we have
# to flush the contents of the current database before the full rdb was
# received<span class="token punctuation">.</span> For <span class="token keyword">this</span> reason we have the following options<span class="token operator">:</span>
#
# <span class="token string">"disabled"</span>    <span class="token operator">-</span> Don't use diskless <span class="token function">load</span> <span class="token punctuation">(</span>store the rdb file to the disk first<span class="token punctuation">)</span> 
# 不要使用无磁盘加载<span class="token punctuation">(</span>首先将rdb文件存储到磁盘<span class="token punctuation">)</span>
# <span class="token string">"on-empty-db"</span> <span class="token operator">-</span> Use diskless load only when it is completely safe<span class="token punctuation">.</span>
# 只有在完全安全的情况下才使用无磁盘加载。
# <span class="token string">"swapdb"</span>      <span class="token operator">-</span> Keep a copy of the current db contents in RAM <span class="token keyword">while</span> parsing
#                 the data directly from the socket<span class="token punctuation">.</span> note that <span class="token keyword">this</span> requires
#                 sufficient memory<span class="token punctuation">,</span> <span class="token keyword">if</span> you don't have it<span class="token punctuation">,</span> you risk an OOM kill<span class="token punctuation">.</span>
repl<span class="token operator">-</span>diskless<span class="token operator">-</span>load disabled

# Replicas send PINGs to server in a predefined interval<span class="token punctuation">.</span> It's possible to
# change <span class="token keyword">this</span> interval with the repl_ping_replica_period option<span class="token punctuation">.</span> The <span class="token keyword">default</span>
# value is <span class="token number">10</span> seconds<span class="token punctuation">.</span>
#

# The following option sets the replication timeout <span class="token keyword">for</span><span class="token operator">:</span>
#
# <span class="token number">1</span><span class="token punctuation">)</span> Bulk transfer I<span class="token operator">/</span>O during SYNC<span class="token punctuation">,</span> from the point of view of replica<span class="token punctuation">.</span>
# <span class="token number">2</span><span class="token punctuation">)</span> Master timeout from the point of view of <span class="token function">replicas</span> <span class="token punctuation">(</span>data<span class="token punctuation">,</span> pings<span class="token punctuation">)</span><span class="token punctuation">.</span>
# <span class="token number">3</span><span class="token punctuation">)</span> Replica timeout from the point of view of <span class="token function">masters</span> <span class="token punctuation">(</span>REPLCONF ACK pings<span class="token punctuation">)</span><span class="token punctuation">.</span>
#
# It is important to make sure that <span class="token keyword">this</span> value is greater than the value
# specified <span class="token keyword">for</span> repl<span class="token operator">-</span>ping<span class="token operator">-</span>replica<span class="token operator">-</span>period otherwise a timeout will be detected
# every time there is low traffic between the master and the replica<span class="token punctuation">.</span>
# 复制连接超时时间。
# repl<span class="token operator">-</span>timeout <span class="token number">60</span>

# Disable TCP_NODELAY on the replica socket after SYNC<span class="token operator">?</span>
#
# If you select <span class="token string">"yes"</span> Redis will use a smaller number of TCP packets and
# less bandwidth to send data to replicas<span class="token punctuation">.</span> But <span class="token keyword">this</span> can add a delay <span class="token keyword">for</span>
# the data to appear on the replica side<span class="token punctuation">,</span> up to <span class="token number">40</span> milliseconds with
# Linux kernels using a <span class="token keyword">default</span> configuration<span class="token punctuation">.</span>
#
# If you select <span class="token string">"no"</span> the delay <span class="token keyword">for</span> data to appear on the replica side will
# be reduced but more bandwidth will be used <span class="token keyword">for</span> replication<span class="token punctuation">.</span>
#
# By <span class="token keyword">default</span> we optimize <span class="token keyword">for</span> low latency<span class="token punctuation">,</span> but in very high traffic conditions
# or when the master and replicas are many hops away<span class="token punctuation">,</span> turning <span class="token keyword">this</span> to <span class="token string">"yes"</span> may
# be a good idea<span class="token punctuation">.</span>
# 是否禁止复制tcp链接的tcp nodelay参数
repl<span class="token operator">-</span>disable<span class="token operator">-</span>tcp<span class="token operator">-</span>nodelay no

# Set the replication backlog size<span class="token punctuation">.</span> The backlog is a buffer that accumulates
# replica data when replicas are disconnected <span class="token keyword">for</span> some time<span class="token punctuation">,</span> so that when a
# replica wants to reconnect again<span class="token punctuation">,</span> often a full resync is not needed<span class="token punctuation">,</span> but a
# partial resync is enough<span class="token punctuation">,</span> just passing the portion of data the replica
# missed <span class="token keyword">while</span> disconnected<span class="token punctuation">.</span>
#
# The bigger the replication backlog<span class="token punctuation">,</span> the longer the time the replica can be
# disconnected and later be able to perform a partial resynchronization<span class="token punctuation">.</span>
# 复制待办事项列表越大，副本断开连接的时间就越长，并且以后能够执行部分重新同步。

# The backlog is only allocated once there is at least a replica connected<span class="token punctuation">.</span>
# 积压只在至少连接了一个副本时才分配。
# 复制缓冲区大小
# repl<span class="token operator">-</span>backlog<span class="token operator">-</span>size 1mb

# After a master has no longer connected replicas <span class="token keyword">for</span> some time<span class="token punctuation">,</span> the backlog
# will be freed<span class="token punctuation">.</span> The following option configures the amount of seconds that
# need to elapse<span class="token punctuation">,</span> starting from the time the last replica disconnected<span class="token punctuation">,</span> <span class="token keyword">for</span>
# the backlog buffer to be freed<span class="token punctuation">.</span>
#
# Note that replicas never free the backlog <span class="token keyword">for</span> timeout<span class="token punctuation">,</span> since they may be
# promoted to masters later<span class="token punctuation">,</span> and should be able to correctly "partially
# resynchronize" with the replicas<span class="token operator">:</span> hence they should always accumulate backlog<span class="token punctuation">.</span>
#
# A value of <span class="token number">0</span> means to never release the backlog<span class="token punctuation">.</span>
# <span class="token number">0</span>的值意味着永远不释放积压。

# master没有slave一段时间会释放复制缓冲区的内存，repl<span class="token operator">-</span>backlog<span class="token operator">-</span>ttl用来设置该时间长度。单位为秒。
# repl<span class="token operator">-</span>backlog<span class="token operator">-</span>ttl <span class="token number">3600</span>

# The replica priority is an integer number published by Redis in the INFO
# output<span class="token punctuation">.</span> It is used by Redis Sentinel in order to select a replica to promote
# into a master <span class="token keyword">if</span> the master is no longer working correctly<span class="token punctuation">.</span>
# 副本优先级是一个由Redis在信息中发布的整数输出。Redis Sentinel使用它来选择一个副本，以便在主服务器不再正常工作时将副本提升到主服务器。

# A replica with a low priority number is considered better <span class="token keyword">for</span> promotion<span class="token punctuation">,</span> so
# <span class="token keyword">for</span> instance <span class="token keyword">if</span> there are three replicas with priority <span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">,</span> <span class="token number">25</span> Sentinel
# will pick the one with priority <span class="token number">10</span><span class="token punctuation">,</span> that is the lowest<span class="token punctuation">.</span>
# 低优先级的副本被认为更适合升级，例如，如果有<span class="token number">3</span>个优先级为<span class="token number">10</span><span class="token punctuation">,</span><span class="token number">100</span>，<span class="token number">25</span>的副本，Sentinel将选择优先级为<span class="token number">10</span>的副本，这是最低的。
# However a special priority of <span class="token number">0</span> marks the replica as not able to perform the
# role of master<span class="token punctuation">,</span> so a replica with priority of <span class="token number">0</span> will never be selected by
# Redis Sentinel <span class="token keyword">for</span> promotion<span class="token punctuation">.</span>
# 但是一个特殊的优先级为<span class="token number">0</span>的副本将不能执行master的角色，所以一个优先级为<span class="token number">0</span>的副本将永远不会被Redis Sentinel选中进行升级。
#
# By <span class="token keyword">default</span> the priority is <span class="token number">100</span><span class="token punctuation">.</span>
# 默认情况下，优先级是<span class="token number">100</span>。
# 也就是当主机挂了，从机那个优先级低，那个就会被推选为主机。
replica<span class="token operator">-</span>priority <span class="token number">100</span>

# It is possible <span class="token keyword">for</span> a master to stop accepting writes <span class="token keyword">if</span> there are less than
# N replicas connected<span class="token punctuation">,</span> having a lag less or equal than M seconds<span class="token punctuation">.</span>
# 如果连接的副本少于N个，延迟小于或等于M秒，那么主机可能会停止接受写操作。
# The N replicas need to be in <span class="token string">"online"</span> state<span class="token punctuation">.</span>
# N个副本需要处于“在线”状态。
# The lag in seconds<span class="token punctuation">,</span> that must be <span class="token operator">&lt;=</span> the specified value<span class="token punctuation">,</span> is calculated from
# the last ping received from the replica<span class="token punctuation">,</span> that is usually sent every second<span class="token punctuation">.</span>
# N个副本以秒为单位的延迟<span class="token punctuation">(</span>必须<span class="token operator">&lt;=</span>指定的值<span class="token punctuation">)</span>是从副本接收的最后一个ping，通常每秒发送一次。需要处于“在线”状态。

# This option does not GUARANTEE that N replicas will accept the write<span class="token punctuation">,</span> but
# will limit the window of exposure <span class="token keyword">for</span> lost writes in <span class="token keyword">case</span> not enough replicas
# are available<span class="token punctuation">,</span> to the specified number of seconds<span class="token punctuation">.</span>
# 此选项不保证N个副本将接受写操作，但在没有足够的副本可用的情况下，将把丢失的写操作的曝光窗口限制在指定的秒数内。
# For example to require at least <span class="token number">3</span> replicas with a lag <span class="token operator">&lt;=</span> <span class="token number">10</span> seconds use<span class="token operator">:</span>
# 例如，需要至少<span class="token number">3</span>个 从机 延迟小于等于 <span class="token number">10</span>秒 才会写入
# min<span class="token operator">-</span>replicas<span class="token operator">-</span>to<span class="token operator">-</span>write <span class="token number">3</span>
# min<span class="token operator">-</span>replicas<span class="token operator">-</span>max<span class="token operator">-</span>lag <span class="token number">10</span>
#
# Setting one or the other to <span class="token number">0</span> disables the feature<span class="token punctuation">.</span>
# 将其中一个设置为<span class="token number">0</span>将禁用该特性。
# By <span class="token keyword">default</span> min<span class="token operator">-</span>replicas<span class="token operator">-</span>to<span class="token operator">-</span>write is set to <span class="token function">0</span> <span class="token punctuation">(</span>feature disabled<span class="token punctuation">)</span> and
# min<span class="token operator">-</span>replicas<span class="token operator">-</span>max<span class="token operator">-</span>lag is set to <span class="token number">10</span><span class="token punctuation">.</span>
# 默认情况下，最小复制写入设置为<span class="token function">0</span><span class="token punctuation">(</span>禁用特性<span class="token punctuation">)</span>
# 最小复制最大延迟设置为<span class="token number">10</span>。

# A Redis master is able to list the address and port of the attached
# replicas in different ways<span class="token punctuation">.</span> For example the <span class="token string">"INFO replication"</span> section
# offers <span class="token keyword">this</span> information<span class="token punctuation">,</span> which is used<span class="token punctuation">,</span> among other tools<span class="token punctuation">,</span> by
# Redis Sentinel in order to discover replica instances<span class="token punctuation">.</span>
# Redis主服务器能够以不同的方式列出所附副本的地址和端口。例如，“信息复制”部分提供了这些信息，Redis Sentinel使用这些信息和其他工具来发现副本实例。
# Another place where <span class="token keyword">this</span> info is available is in the output of the
# <span class="token string">"ROLE"</span> command of a master<span class="token punctuation">.</span>
#
# The listed IP and address normally reported by a replica is obtained
# in the following way<span class="token operator">:</span>
#
#   IP<span class="token operator">:</span> The address is auto detected by checking the peer address
#   of the socket used by the replica to connect with the master<span class="token punctuation">.</span>
#
#   Port<span class="token operator">:</span> The port is communicated by the replica during the replication
#   handshake<span class="token punctuation">,</span> and is normally the port that the replica is using to
#   listen <span class="token keyword">for</span> connections<span class="token punctuation">.</span>
#
# However when port forwarding or Network Address <span class="token function">Translation</span> <span class="token punctuation">(</span>NAT<span class="token punctuation">)</span> is
# used<span class="token punctuation">,</span> the replica may be actually reachable via different IP and port
# pairs<span class="token punctuation">.</span> The following two options can be used by a replica in order to
# report to its master a specific set of IP and port<span class="token punctuation">,</span> so that both INFO
# and ROLE will report those values<span class="token punctuation">.</span>
#
# There is no need to use both the options <span class="token keyword">if</span> you need to override just
# the port or the IP address<span class="token punctuation">.</span>
#
# replica<span class="token operator">-</span>announce<span class="token operator">-</span>ip <span class="token number">5.5</span><span class="token punctuation">.</span><span class="token number">5.5</span>
# replica<span class="token operator">-</span>announce<span class="token operator">-</span>port <span class="token number">1234</span>

############################### KEYS TRACKING #################################

# Redis <span class="token keyword">implements</span> <span class="token class-name">server</span> assisted support <span class="token keyword">for</span> client side caching of values<span class="token punctuation">.</span>
# This is implemented using an invalidation table that remembers<span class="token punctuation">,</span> using
# <span class="token number">16</span> millions of slots<span class="token punctuation">,</span> what clients may have certain subsets of keys<span class="token punctuation">.</span> In turn
# <span class="token keyword">this</span> is used in order to send invalidation messages to clients<span class="token punctuation">.</span> Please
# to understand more about the feature check <span class="token keyword">this</span> page<span class="token operator">:</span>
#
#   https<span class="token operator">:</span><span class="token operator">/</span><span class="token operator">/</span>redis<span class="token punctuation">.</span>io<span class="token operator">/</span>topics<span class="token operator">/</span>client<span class="token operator">-</span>side<span class="token operator">-</span>caching
#
# When tracking is enabled <span class="token keyword">for</span> a client<span class="token punctuation">,</span> all the read only queries are assumed
# to be cached<span class="token operator">:</span> <span class="token keyword">this</span> will force Redis to store information in the invalidation
# table<span class="token punctuation">.</span> When keys are modified<span class="token punctuation">,</span> such information is flushed away<span class="token punctuation">,</span> and
# invalidation messages are sent to the clients<span class="token punctuation">.</span> However <span class="token keyword">if</span> the workload is
# heavily dominated by reads<span class="token punctuation">,</span> Redis could use more and more memory in order
# to track the keys fetched by many clients<span class="token punctuation">.</span>
#
# For <span class="token keyword">this</span> reason it is possible to configure a maximum fill value <span class="token keyword">for</span> the
# invalidation table<span class="token punctuation">.</span> By <span class="token keyword">default</span> it is set to 1M of keys<span class="token punctuation">,</span> and once <span class="token keyword">this</span> limit
# is reached<span class="token punctuation">,</span> Redis will start to evict keys in the invalidation table
# even <span class="token keyword">if</span> they were not modified<span class="token punctuation">,</span> just to reclaim memory<span class="token operator">:</span> <span class="token keyword">this</span> will in turn
# force the clients to invalidate the cached values<span class="token punctuation">.</span> Basically the table
# maximum size is a trade off between the memory you want to spend server
# side to track information about who cached what<span class="token punctuation">,</span> and the ability of clients
# to retain cached objects in memory<span class="token punctuation">.</span>
#
# If you set the value to <span class="token number">0</span><span class="token punctuation">,</span> it means there are no limits<span class="token punctuation">,</span> and Redis will
# retain as many keys as needed in the invalidation table<span class="token punctuation">.</span>
# In the <span class="token string">"stats"</span> INFO section<span class="token punctuation">,</span> you can find information about the number of
# keys in the invalidation table at every given moment<span class="token punctuation">.</span>
#
# Note<span class="token operator">:</span> when key tracking is used in broadcasting mode<span class="token punctuation">,</span> no memory is used
# in the server side so <span class="token keyword">this</span> setting is useless<span class="token punctuation">.</span>
# 这个是有关客户端缓存的
# tracking<span class="token operator">-</span>table<span class="token operator">-</span>max<span class="token operator">-</span>keys <span class="token number">1000000</span>

################################## SECURITY ###################################
# 安全，在<span class="token number">6.0</span>版本之后，加入了用户名<span class="token operator">+</span>密码的设置，如果设置密码，用户名为默认。
# 新格式：AUTH <span class="token operator">&lt;</span>username<span class="token operator">></span> <span class="token operator">&lt;</span>password<span class="token operator">></span>  或者 旧格式：AUTH <span class="token operator">&lt;</span>password<span class="token operator">></span>
# Warning<span class="token operator">:</span> since Redis is pretty fast an outside user can <span class="token keyword">try</span> up to
# <span class="token number">1</span> million passwords per second against a modern box<span class="token punctuation">.</span> This means that you
# should use very strong passwords<span class="token punctuation">,</span> otherwise they will be very easy to <span class="token keyword">break</span><span class="token punctuation">.</span>
# Note that because the password is really a shared secret between the client
# and the server<span class="token punctuation">,</span> and should not be memorized by any human<span class="token punctuation">,</span> the password
# can be easily a <span class="token keyword">long</span> string from <span class="token operator">/</span>dev<span class="token operator">/</span>urandom or whatever<span class="token punctuation">,</span> so by using a
# <span class="token keyword">long</span> and unguessable password no brute force attack will be possible<span class="token punctuation">.</span>

# Redis ACL users are defined in the following format<span class="token operator">:</span>
#
#   user <span class="token operator">&lt;</span>username<span class="token operator">></span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span> acl rules <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
#
# For example<span class="token operator">:</span>
#
#   user worker <span class="token operator">+</span><span class="token annotation punctuation">@list</span> <span class="token operator">+</span><span class="token annotation punctuation">@connection</span> <span class="token operator">~</span>jobs<span class="token operator">:</span><span class="token operator">*</span> on <span class="token operator">></span>ffa9203c493aa99
#
# The special username <span class="token string">"default"</span> is used <span class="token keyword">for</span> <span class="token keyword">new</span> <span class="token class-name">connections<span class="token punctuation">.</span></span> If <span class="token keyword">this</span> user
# has the <span class="token string">"nopass"</span> rule<span class="token punctuation">,</span> then <span class="token keyword">new</span> <span class="token class-name">connections</span> will be immediately authenticated
# as the <span class="token string">"default"</span> user without the need of any password provided via the
# AUTH command<span class="token punctuation">.</span> Otherwise <span class="token keyword">if</span> the <span class="token string">"default"</span> user is not flagged with <span class="token string">"nopass"</span>
# the connections will start in not authenticated state<span class="token punctuation">,</span> and will require
# <span class="token function">AUTH</span> <span class="token punctuation">(</span>or the HELLO command AUTH option<span class="token punctuation">)</span> in order to be authenticated and
# start to work<span class="token punctuation">.</span>
#
# The ACL rules that describe what an user can <span class="token keyword">do</span> are the following<span class="token operator">:</span>
# 描述用户可以做什么的ACL规则如下所示
#  on           Enable the user<span class="token operator">:</span> it is possible to authenticate as <span class="token keyword">this</span> user<span class="token punctuation">.</span>启用用户<span class="token operator">:</span>可以作为此用户进行身份验证。
#  off          Disable the user<span class="token operator">:</span> it's no longer possible to authenticate 
#               with <span class="token keyword">this</span> user<span class="token punctuation">,</span> however the already authenticated connections
#               will still work<span class="token punctuation">.</span>
#  禁用该用户<span class="token operator">:</span>不再能够使用该用户进行身份验证，但是已验证的连接仍然可以工作。
#  <span class="token operator">+</span><span class="token operator">&lt;</span>command<span class="token operator">></span>   Allow the execution of that command 允许执行该命令，也就是添加用户命令权限，例：<span class="token operator">+</span>get <span class="token operator">+</span>set
#  <span class="token operator">-</span><span class="token operator">&lt;</span>command<span class="token operator">></span>   Disallow the execution of that command 不允许执行该命令
#  <span class="token operator">+</span>@<span class="token operator">&lt;</span>category<span class="token operator">></span> Allow the execution of all the commands in such category
#               with valid categories are like <span class="token annotation punctuation">@admin</span><span class="token punctuation">,</span> <span class="token annotation punctuation">@set</span><span class="token punctuation">,</span> <span class="token annotation punctuation">@sortedset</span><span class="token punctuation">,</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
#               and so forth<span class="token punctuation">,</span> see the full list in the server<span class="token punctuation">.</span>c file where
#               the Redis command table is described and defined<span class="token punctuation">.</span>
#               The special category <span class="token annotation punctuation">@all</span> means all the commands<span class="token punctuation">,</span> but currently
#               present in the server<span class="token punctuation">,</span> and that will be loaded in the future
#               via modules<span class="token punctuation">.</span>
#  <span class="token operator">+</span><span class="token operator">&lt;</span>command<span class="token operator">></span><span class="token operator">|</span>subcommand    Allow a specific subcommand of an otherwise
#                           disabled command<span class="token punctuation">.</span> Note that <span class="token keyword">this</span> form is not
#                           allowed as negative like <span class="token operator">-</span>DEBUG<span class="token operator">|</span>SEGFAULT<span class="token punctuation">,</span> but
#                           only additive starting with <span class="token string">"+"</span><span class="token punctuation">.</span>
#  allcommands  Alias <span class="token keyword">for</span> <span class="token operator">+</span><span class="token annotation punctuation">@all</span><span class="token punctuation">.</span> Note that it implies the ability to execute
#               all the future commands loaded via the modules system<span class="token punctuation">.</span>
#  nocommands   Alias <span class="token keyword">for</span> <span class="token operator">-</span><span class="token annotation punctuation">@all</span><span class="token punctuation">.</span>
#  <span class="token operator">~</span><span class="token operator">&lt;</span>pattern<span class="token operator">></span>   Add a pattern of keys that can be mentioned as part of
#               commands<span class="token punctuation">.</span> For instance <span class="token operator">~</span><span class="token operator">*</span> allows all the keys<span class="token punctuation">.</span> The pattern
#               is a glob<span class="token operator">-</span>style pattern like the one of KEYS<span class="token punctuation">.</span>
#               It is possible to specify multiple patterns<span class="token punctuation">.</span>
# 添加可作为命令的一部分提到的键的模式。例如<span class="token operator">~</span><span class="token operator">*</span>允许所有的键。模式是一个全局样式的模式，类似于键的模式。可以指定多个模式。
# GMaya总结：也就是允许访问那些key，例子：只允许访问<span class="token operator">~</span>gmaya<span class="token operator">:</span><span class="token operator">*</span>开头的key。如：gmaya<span class="token operator">:</span>userid， gmaya<span class="token operator">:</span>roleid
#  allkeys      Alias <span class="token keyword">for</span> <span class="token operator">~</span><span class="token operator">*</span> allkeys别名为<span class="token operator">~</span><span class="token operator">*</span>
#  resetkeys    Flush the list of allowed keys patterns<span class="token punctuation">.</span>刷新允许的键模式列表。
#  <span class="token operator">></span><span class="token operator">&lt;</span>password<span class="token operator">></span>  Add <span class="token keyword">this</span> passowrd to the list of valid password <span class="token keyword">for</span> the user<span class="token punctuation">.</span>
#               For example <span class="token operator">></span>mypass will add <span class="token string">"mypass"</span> to the list<span class="token punctuation">.</span>
#               This directive clears the <span class="token string">"nopass"</span> <span class="token function">flag</span> <span class="token punctuation">(</span>see later<span class="token punctuation">)</span><span class="token punctuation">.</span>
# 将这个passowrd添加到用户的有效密码列表中。例如，<span class="token operator">></span>mypass会将“mypass”添加到列表中。这个指令清除“nopass”标志<span class="token punctuation">(</span>参见后面<span class="token punctuation">)</span>。
#  <span class="token operator">&lt;&lt;</span>password<span class="token operator">></span>  Remove <span class="token keyword">this</span> password from the list of valid passwords<span class="token punctuation">.</span> 从有效密码列表中删除此密码。
#  nopass       All the set passwords of the user are removed<span class="token punctuation">,</span> and the user
#               is flagged as requiring no password<span class="token operator">:</span> it means that every
#               password will work against <span class="token keyword">this</span> user<span class="token punctuation">.</span> If <span class="token keyword">this</span> directive is
#               used <span class="token keyword">for</span> the <span class="token keyword">default</span> user<span class="token punctuation">,</span> every <span class="token keyword">new</span> <span class="token class-name">connection</span> will be
#               immediately authenticated with the <span class="token keyword">default</span> user without
#               any explicit AUTH command required<span class="token punctuation">.</span> Note that the <span class="token string">"resetpass"</span>
#               directive will clear <span class="token keyword">this</span> condition<span class="token punctuation">.</span>
# 删除用户的所有设置密码，并将用户标记为不需要密码<span class="token operator">:</span>这意味着每个密码都将对该用户起作用。如果此指令用于默认用户，
# 则每个新连接都将立即与默认用户进行身份验证，而不需要任何显式的AUTH命令。注意“resetpass”指令将清除这个条件。
#  resetpass    Flush the list of allowed passwords<span class="token punctuation">.</span> Moreover removes the
#               <span class="token string">"nopass"</span> status<span class="token punctuation">.</span> After <span class="token string">"resetpass"</span> the user has no associated
#               passwords and there is no way to authenticate without adding
#               some <span class="token function">password</span> <span class="token punctuation">(</span>or setting it as <span class="token string">"nopass"</span> later<span class="token punctuation">)</span><span class="token punctuation">.</span>\
# 刷新允许的密码列表。此外，删除“nopass”状态。在“resetpass”之后，用户没有相关联的密码，并且没有办法在不添加一些密码<span class="token punctuation">(</span>或稍后将其设置为“nopass”<span class="token punctuation">)</span>的情况下进行身份验证。
#  reset        Performs the following actions<span class="token operator">:</span> resetpass<span class="token punctuation">,</span> resetkeys<span class="token punctuation">,</span> off<span class="token punctuation">,</span>
#               <span class="token operator">-</span><span class="token annotation punctuation">@all</span><span class="token punctuation">.</span> The user returns to the same state it has immediately
#               after its creation<span class="token punctuation">.</span>
# 执行以下操作<span class="token operator">:</span>resetpass、resetkeys、off、<span class="token operator">-</span><span class="token annotation punctuation">@all</span>。用户在创建后立即返回到相同的状态。

# ACL rules can be specified in any order<span class="token operator">:</span> <span class="token keyword">for</span> instance you can start with
# passwords<span class="token punctuation">,</span> then flags<span class="token punctuation">,</span> or key patterns<span class="token punctuation">.</span> However note that the additive
# and subtractive rules will CHANGE MEANING depending on the ordering<span class="token punctuation">.</span>
# For instance see the following example<span class="token operator">:</span>
#
#   user alice on <span class="token operator">+</span><span class="token annotation punctuation">@all</span> <span class="token operator">-</span>DEBUG <span class="token operator">~</span><span class="token operator">*</span> <span class="token operator">></span>somepassword
#
# This will allow <span class="token string">"alice"</span> to use all the commands with the exception of the
# DEBUG command<span class="token punctuation">,</span> since <span class="token operator">+</span><span class="token annotation punctuation">@all</span> added all the commands to the set of the commands
# alice can use<span class="token punctuation">,</span> and later DEBUG was removed<span class="token punctuation">.</span> However <span class="token keyword">if</span> we invert the order
# of two ACL rules the result will be different<span class="token operator">:</span>
#
#   user alice on <span class="token operator">-</span>DEBUG <span class="token operator">+</span><span class="token annotation punctuation">@all</span> <span class="token operator">~</span><span class="token operator">*</span> <span class="token operator">></span>somepassword
#
# Now DEBUG was removed when alice had yet no commands in the set of allowed
# commands<span class="token punctuation">,</span> later all the commands are added<span class="token punctuation">,</span> so the user will be able to
# execute everything<span class="token punctuation">.</span>
#
# Basically ACL rules are processed left<span class="token operator">-</span>to<span class="token operator">-</span>right<span class="token punctuation">.</span>
#
# For more information about ACL configuration please refer to
# the Redis web site at https<span class="token operator">:</span><span class="token operator">/</span><span class="token operator">/</span>redis<span class="token punctuation">.</span>io<span class="token operator">/</span>topics<span class="token operator">/</span>acl

# ACL LOG
#
# The ACL Log tracks failed commands and authentication events associated
# with ACLs<span class="token punctuation">.</span> The ACL Log is useful to troubleshoot failed commands blocked 
# by ACLs<span class="token punctuation">.</span> The ACL Log is stored in and consumes memory<span class="token punctuation">.</span> There is no limit
# to its length<span class="token punctuation">.</span>You can reclaim memory with ACL LOG RESET or set a maximum
# length below<span class="token punctuation">.</span>
acllog<span class="token operator">-</span>max<span class="token operator">-</span>len <span class="token number">128</span>

# Using an external ACL file
# 使用外部ACL文件
# Instead of configuring users here in <span class="token keyword">this</span> file<span class="token punctuation">,</span> it is possible to use
# a stand<span class="token operator">-</span>alone file just listing users<span class="token punctuation">.</span> The two methods cannot be mixed<span class="token operator">:</span>
# <span class="token keyword">if</span> you configure users here and at the same time you activate the exteranl
# ACL file<span class="token punctuation">,</span> the server will refuse to start<span class="token punctuation">.</span>
# 不需要在这个文件中配置用户，可以使用一个单独的文件来列出用户。这两种方法不能混合使用<span class="token operator">:</span>如果在这里配置用户，同时激活exteranl ACL文件，服务器将拒绝启动。
# The format of the external ACL user file is exactly the same as the
# format that is used inside redis<span class="token punctuation">.</span>conf to describe users<span class="token punctuation">.</span>
# 外部ACL用户文件的格式与在redis<span class="token punctuation">.</span>conf中用于描述用户的格式完全相同。
# aclfile <span class="token operator">/</span>etc<span class="token operator">/</span>redis<span class="token operator">/</span>users<span class="token punctuation">.</span>acl

# IMPORTANT NOTE<span class="token operator">:</span> starting with Redis <span class="token number">6</span> <span class="token string">"requirepass"</span> is just a compatiblity
# layer on top of the <span class="token keyword">new</span> <span class="token class-name">ACL</span> system<span class="token punctuation">.</span> The option effect will be just setting
# the password <span class="token keyword">for</span> the <span class="token keyword">default</span> user<span class="token punctuation">.</span> Clients will still authenticate using
# AUTH <span class="token operator">&lt;</span>password<span class="token operator">></span> as usually<span class="token punctuation">,</span> or more explicitly with AUTH <span class="token keyword">default</span> <span class="token operator">&lt;</span>password<span class="token operator">></span>
# <span class="token keyword">if</span> they follow the <span class="token keyword">new</span> <span class="token class-name">protocol</span><span class="token operator">:</span> both will work<span class="token punctuation">.</span>
# 密码，如果使用redis需要密码，在这里设置
# requirepass foobared

# Command <span class="token function">renaming</span> <span class="token punctuation">(</span>DEPRECATED<span class="token punctuation">)</span><span class="token punctuation">.</span>
# 命令重命名<span class="token punctuation">(</span>弃用<span class="token punctuation">)</span>。
# <span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span>
# WARNING<span class="token operator">:</span> avoid using <span class="token keyword">this</span> option <span class="token keyword">if</span> possible<span class="token punctuation">.</span> Instead use ACLs to remove
# commands from the <span class="token keyword">default</span> user<span class="token punctuation">,</span> and put them only in some admin user you
# create <span class="token keyword">for</span> administrative purposes<span class="token punctuation">.</span>
# <span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span>
#
# It is possible to change the name of dangerous commands in a shared
# environment<span class="token punctuation">.</span> For instance the CONFIG command may be renamed into something
# hard to guess so that it will still be available <span class="token keyword">for</span> internal<span class="token operator">-</span>use tools
# but not available <span class="token keyword">for</span> general clients<span class="token punctuation">.</span>
#
# Example<span class="token operator">:</span>
#
# rename<span class="token operator">-</span>command CONFIG b840fc02d524045429941cc15f59e41cb7be6c52
#
# It is also possible to completely kill a command by renaming it into
# an empty string<span class="token operator">:</span>
#
# rename<span class="token operator">-</span>command CONFIG <span class="token string">""</span>
#
# Please note that changing the name of commands that are logged into the
# AOF file or transmitted to replicas may cause problems<span class="token punctuation">.</span>

################################### CLIENTS ####################################

# Set the max number of connected clients at the same time<span class="token punctuation">.</span> By <span class="token keyword">default</span>
# <span class="token keyword">this</span> limit is set to <span class="token number">10000</span> clients<span class="token punctuation">,</span> however <span class="token keyword">if</span> the Redis server is not
# able to configure the process file limit to allow <span class="token keyword">for</span> the specified limit
# the max number of allowed clients is set to the current file limit
# minus <span class="token function">32</span> <span class="token punctuation">(</span>as Redis reserves a few file descriptors <span class="token keyword">for</span> internal uses<span class="token punctuation">)</span><span class="token punctuation">.</span>
# 同时设置最大连接客户端数量。默认情况下这个限制设置为<span class="token number">10000</span>个客户<span class="token punctuation">,</span>
# 但是如果复述<span class="token punctuation">,</span>服务器不能配置过程文件限制允许指定限制允许的最大数量的客户设置为（当前文件限制<span class="token operator">-</span> <span class="token number">32</span>）<span class="token punctuation">(</span>redis本身会用到<span class="token number">32</span>左右的连接<span class="token punctuation">,</span>储备一些为内部使用文件描述符<span class="token punctuation">)</span>。
# Once the limit is reached Redis will close all the <span class="token keyword">new</span> <span class="token class-name">connections</span> sending
# an error <span class="token string">'max number of clients reached'</span><span class="token punctuation">.</span>
# 一旦达到限制，Redis将关闭所有新连接，发送一个错误“达到的客户端最大数量”。
# maxclients <span class="token number">10000</span>

############################## MEMORY MANAGEMENT ################################
# 内存管理
# Set a memory usage limit to the specified amount of bytes<span class="token punctuation">.</span>
# When the memory limit is reached Redis will <span class="token keyword">try</span> to remove keys
# according to the eviction policy <span class="token function">selected</span> <span class="token punctuation">(</span>see maxmemory<span class="token operator">-</span>policy<span class="token punctuation">)</span><span class="token punctuation">.</span>
#
# If Redis can't remove keys according to the policy<span class="token punctuation">,</span> or <span class="token keyword">if</span> the policy is
# set to <span class="token string">'noeviction'</span><span class="token punctuation">,</span> Redis will start to reply with errors to commands
# that would use more memory<span class="token punctuation">,</span> like SET<span class="token punctuation">,</span> LPUSH<span class="token punctuation">,</span> and so on<span class="token punctuation">,</span> and will <span class="token keyword">continue</span>
# to reply to read<span class="token operator">-</span>only commands like GET<span class="token punctuation">.</span>
#
# This option is usually useful when using Redis as an LRU or LFU cache<span class="token punctuation">,</span> or to
# set a hard memory limit <span class="token keyword">for</span> an <span class="token function">instance</span> <span class="token punctuation">(</span>using the <span class="token string">'noeviction'</span> policy<span class="token punctuation">)</span><span class="token punctuation">.</span>
#
# WARNING<span class="token operator">:</span> If you have replicas attached to an instance with maxmemory on<span class="token punctuation">,</span>
# the size of the output buffers needed to feed the replicas are subtracted
# from the used memory count<span class="token punctuation">,</span> so that network problems <span class="token operator">/</span> resyncs will
# not trigger a loop where keys are evicted<span class="token punctuation">,</span> and in turn the output
# buffer of replicas is full with DELs of keys evicted triggering the deletion
# of more keys<span class="token punctuation">,</span> and so forth until the database is completely emptied<span class="token punctuation">.</span>
#
# In <span class="token keyword">short</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span> <span class="token keyword">if</span> you have replicas attached it is suggested that you set a lower
# limit <span class="token keyword">for</span> maxmemory so that there is some free RAM on the system <span class="token keyword">for</span> replica
# output <span class="token function">buffers</span> <span class="token punctuation">(</span>but <span class="token keyword">this</span> is not needed <span class="token keyword">if</span> the policy is <span class="token string">'noeviction'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>
# 指定Redis最大内存限制
# maxmemory <span class="token operator">&lt;</span>bytes<span class="token operator">></span>

# MAXMEMORY POLICY<span class="token operator">:</span> how Redis will select what to remove when maxmemory
# is reached<span class="token punctuation">.</span> You can select one from the following behaviors<span class="token operator">:</span>
# 当内存使用达到最大值时，redis使用的清除策略。
# <span class="token keyword">volatile</span><span class="token operator">-</span>lru <span class="token operator">-</span><span class="token operator">></span> Evict using approximated LRU<span class="token punctuation">,</span> only keys with an expire set<span class="token punctuation">.</span> 使用近似LRU，仅使用具有过期设置的键。
# allkeys<span class="token operator">-</span>lru <span class="token operator">-</span><span class="token operator">></span> Evict any key using approximated LRU<span class="token punctuation">.</span> 使用近似LRU退出任何key。
# <span class="token keyword">volatile</span><span class="token operator">-</span>lfu <span class="token operator">-</span><span class="token operator">></span> Evict using approximated LFU<span class="token punctuation">,</span> only keys with an expire set<span class="token punctuation">.</span> 使用近似的LFU，仅使用具有过期集的键。
# allkeys<span class="token operator">-</span>lfu <span class="token operator">-</span><span class="token operator">></span> Evict any key using approximated LFU<span class="token punctuation">.</span> 使用近似的LFU退出任何键。
# <span class="token keyword">volatile</span><span class="token operator">-</span>random <span class="token operator">-</span><span class="token operator">></span> Remove a random key having an expire set<span class="token punctuation">.</span> 删除具有过期集的随机key
# allkeys<span class="token operator">-</span>random <span class="token operator">-</span><span class="token operator">></span> Remove a random key<span class="token punctuation">,</span> any key<span class="token punctuation">.</span> 删除一个随机key，任何key。
# <span class="token keyword">volatile</span><span class="token operator">-</span>ttl <span class="token operator">-</span><span class="token operator">></span> Remove the key with the nearest expire <span class="token function">time</span> <span class="token punctuation">(</span>minor TTL<span class="token punctuation">)</span> 删除具有最近过期时间的密钥<span class="token punctuation">(</span>次要TTL<span class="token punctuation">)</span>
# noeviction <span class="token operator">-</span><span class="token operator">></span> Don't evict anything<span class="token punctuation">,</span> just <span class="token keyword">return</span> an error on write operations<span class="token punctuation">.</span> 不删除任何内容，只在写操作时返回一个错误。
#
# LRU means Least Recently Used # LRU的意思是最近最少使用的
# LFU means Least Frequently Used # LFU的意思是最不常用的
#
# Both LRU<span class="token punctuation">,</span> LFU and <span class="token keyword">volatile</span><span class="token operator">-</span>ttl are implemented using approximated
# randomized algorithms<span class="token punctuation">.</span>
# LRU、LFU和<span class="token keyword">volatile</span><span class="token operator">-</span>ttl都是使用近似随机算法实现的。
#
# Note<span class="token operator">:</span> with any of the above policies<span class="token punctuation">,</span> Redis will <span class="token keyword">return</span> an error on write
#       operations<span class="token punctuation">,</span> when there are no suitable keys <span class="token keyword">for</span> eviction<span class="token punctuation">.</span>
#
#       At the date of writing these commands are<span class="token operator">:</span> set setnx setex append
#       incr decr rpush lpush rpushx lpushx linsert lset rpoplpush sadd
#       sinter sinterstore sunion sunionstore sdiff sdiffstore zadd zincrby
#       zunionstore zinterstore hset hsetnx hmset hincrby incrby decrby
#       getset mset msetnx exec sort
#
# The <span class="token keyword">default</span> is<span class="token operator">:</span>
#
# maxmemory<span class="token operator">-</span>policy noeviction

# LRU<span class="token punctuation">,</span> LFU and minimal TTL algorithms are not precise algorithms but approximated
# <span class="token function">algorithms</span> <span class="token punctuation">(</span>in order to save memory<span class="token punctuation">)</span><span class="token punctuation">,</span> so you can tune it <span class="token keyword">for</span> speed or
# accuracy<span class="token punctuation">.</span> For <span class="token keyword">default</span> Redis will check five keys and pick the one that was
# used less recently<span class="token punctuation">,</span> you can change the sample size using the following
# configuration directive<span class="token punctuation">.</span>
# LRU、LFU和最小TTL算法并不是精确的算法，而是近似的算法<span class="token punctuation">(</span>为了节省内存<span class="token punctuation">)</span>，因此您可以对其进行调优以获得速度或精度。
# 对于默认情况，Redis将检查五个键并选择最近较少使用的键，您可以使用以下配置指令更改样本大小。
#
# The <span class="token keyword">default</span> of <span class="token number">5</span> produces good enough results<span class="token punctuation">.</span> <span class="token number">10</span> Approximates very closely
# <span class="token boolean">true</span> LRU but costs more CPU<span class="token punctuation">.</span> <span class="token number">3</span> is faster but not very accurate<span class="token punctuation">.</span>
# 默认的<span class="token number">5</span>产生足够好的结果。<span class="token number">10</span>非常接近真实的LRU，但是消耗更多的CPU。<span class="token number">3</span>更快，但不是很准确。
# maxmemory<span class="token operator">-</span>samples <span class="token number">5</span>

# Starting from Redis <span class="token number">5</span><span class="token punctuation">,</span> by <span class="token keyword">default</span> a replica will ignore its maxmemory setting
# <span class="token punctuation">(</span>unless it is promoted to master after a failover or manually<span class="token punctuation">)</span><span class="token punctuation">.</span> It means
# that the eviction of keys will be just handled by the master<span class="token punctuation">,</span> sending the
# DEL commands to the replica as keys evict in the master side<span class="token punctuation">.</span>
# 从Redis <span class="token number">5</span>开始，在默认情况下，副本将忽略它的maxmemory设置<span class="token punctuation">(</span>除非在故障转移后或手动将其提升为master<span class="token punctuation">)</span>。
# 这意味着键的回收将只由主进程处理，当主进程中的键被回收时，将DEL命令发送到副本。
# This behavior ensures that masters and replicas stay consistent<span class="token punctuation">,</span> and is usually
# what you want<span class="token punctuation">,</span> however <span class="token keyword">if</span> your replica is writable<span class="token punctuation">,</span> or you want the replica
# to have a different memory setting<span class="token punctuation">,</span> and you are sure all the writes performed
# to the replica are idempotent<span class="token punctuation">,</span> then you may change <span class="token keyword">this</span> <span class="token keyword">default</span> <span class="token punctuation">(</span>but be sure
# to understand what you are doing<span class="token punctuation">)</span><span class="token punctuation">.</span>
#
# Note that since the replica by <span class="token keyword">default</span> does not evict<span class="token punctuation">,</span> it may end using more
# memory than the one set via <span class="token function">maxmemory</span> <span class="token punctuation">(</span>there are certain buffers that may
# be larger on the replica<span class="token punctuation">,</span> or data structures may sometimes take more memory
# and so forth<span class="token punctuation">)</span><span class="token punctuation">.</span> So make sure you monitor your replicas and make sure they
# have enough memory to never hit a real out<span class="token operator">-</span>of<span class="token operator">-</span>memory condition before the
# master hits the configured maxmemory setting<span class="token punctuation">.</span>
# 注意，由于副本在默认情况下不会被逐出，因此它最终使用的内存可能比通过maxmemory设置的内存多<span class="token punctuation">(</span>在副本上有一些缓冲区可能更大，或者数据结构有时会占用更多内存，等等<span class="token punctuation">)</span>。
# 因此，请确保您监控您的副本，并确保他们有足够的内存，从来没有遇到真正的内存不足的情况之前master点击已配置的maxmemory设置。
# replica<span class="token operator">-</span>ignore<span class="token operator">-</span>maxmemory yes

# Redis reclaims expired keys in two ways<span class="token operator">:</span> upon access when those keys are
# found to be expired<span class="token punctuation">,</span> and also in background<span class="token punctuation">,</span> in what is called the
# <span class="token string">"active expire key"</span><span class="token punctuation">.</span> The key space is slowly and interactively scanned
# looking <span class="token keyword">for</span> expired keys to reclaim<span class="token punctuation">,</span> so that it is possible to free memory
# of keys that are expired and will never be accessed again in a <span class="token keyword">short</span> time<span class="token punctuation">.</span>
# Redis以两种方式回收过期的密钥<span class="token operator">:</span>在访问时发现这些密钥已经过期，在后台，也称为“活动过期密钥”。
# 对密钥空间进行缓慢而交互式的扫描，寻找过期的密钥进行回收，以便释放过期的密钥的内存，这些密钥在短时间内永远不会被再次访问。
# The <span class="token keyword">default</span> effort of the expire cycle will <span class="token keyword">try</span> to avoid having more than
# ten percent of expired keys still in memory<span class="token punctuation">,</span> and will <span class="token keyword">try</span> to avoid consuming
# more than <span class="token number">25</span><span class="token operator">%</span> of total memory and to add latency to the system<span class="token punctuation">.</span> However
# it is possible to increase the expire <span class="token string">"effort"</span> that is normally set to
# <span class="token string">"1"</span><span class="token punctuation">,</span> to a greater value<span class="token punctuation">,</span> up to the value <span class="token string">"10"</span><span class="token punctuation">.</span> At its maximum value the
# system will use more CPU<span class="token punctuation">,</span> longer <span class="token function">cycles</span> <span class="token punctuation">(</span>and technically may introduce
# more latency<span class="token punctuation">)</span><span class="token punctuation">,</span> and will tollerate less already expired keys still present
# in the system<span class="token punctuation">.</span> It's a tradeoff betweeen memory<span class="token punctuation">,</span> CPU and latecy<span class="token punctuation">.</span>
# 过期周期的默认工作将尝试避免在内存中保留超过<span class="token number">10</span><span class="token operator">%</span>的过期密钥，并尝试避免消耗超过<span class="token number">25</span><span class="token operator">%</span>的总内存并增加系统延迟。但是，可以将过期的“工作”<span class="token punctuation">(</span>通常设置为“<span class="token number">1</span>”<span class="token punctuation">)</span>增加到更大的值，直到值“<span class="token number">10</span>”。
# 在其最大值时，系统将使用更多的CPU，更长的周期<span class="token punctuation">(</span>技术上可能引入更多的延迟<span class="token punctuation">)</span>，并且将减少系统中仍然存在的过期密钥。这是内存、CPU和延迟之间的权衡。
# active<span class="token operator">-</span>expire<span class="token operator">-</span>effort <span class="token number">1</span>

############################# LAZY FREEING ####################################
# 延迟加载
# Redis has two primitives to delete keys<span class="token punctuation">.</span> One is called DEL and is a blocking
# deletion of the object<span class="token punctuation">.</span> It means that the server stops processing <span class="token keyword">new</span> <span class="token class-name">commands</span>
# in order to reclaim all the memory associated with an object in a synchronous
# way<span class="token punctuation">.</span> If the key deleted is associated with a small object<span class="token punctuation">,</span> the time needed
# in order to execute the DEL command is very small and comparable to most other
# <span class="token function">O</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span> or <span class="token function">O</span><span class="token punctuation">(</span>log_N<span class="token punctuation">)</span> commands in Redis<span class="token punctuation">.</span> However <span class="token keyword">if</span> the key is associated with an
# aggregated value containing millions of elements<span class="token punctuation">,</span> the server can block <span class="token keyword">for</span>
# a <span class="token keyword">long</span> <span class="token function">time</span> <span class="token punctuation">(</span>even seconds<span class="token punctuation">)</span> in order to complete the operation<span class="token punctuation">.</span>
# Redis有两个原语来删除键。一个是DEL，是对象的阻塞删除。它意味着服务器停止处理新命令，以便以同步方式回收与对象关联的所有内存。
# 如果删除的键与一个小对象相关联，那么执行DEL命令所需的时间非常短，可以与Redis中的大多数其他<span class="token function">O</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>或<span class="token function">O</span><span class="token punctuation">(</span>log_N<span class="token punctuation">)</span>命令相媲美。
# 但是，如果键与包含数百万个元素的聚合值相关联，服务器可能会阻塞很长时间<span class="token punctuation">(</span>甚至几秒钟<span class="token punctuation">)</span>以完成操作。
# For the above reasons Redis also offers non blocking deletion primitives
# such as <span class="token function">UNLINK</span> <span class="token punctuation">(</span>non blocking DEL<span class="token punctuation">)</span> and the ASYNC option of FLUSHALL and
# FLUSHDB commands<span class="token punctuation">,</span> in order to reclaim memory in background<span class="token punctuation">.</span> Those commands
# are executed in constant time<span class="token punctuation">.</span> Another thread will incrementally free the
# object in the background as fast as possible<span class="token punctuation">.</span>
#
# DEL<span class="token punctuation">,</span> UNLINK and ASYNC option of FLUSHALL and FLUSHDB are user<span class="token operator">-</span>controlled<span class="token punctuation">.</span>
# It's up to the design of the application to understand when it is a good
# idea to use one or the other<span class="token punctuation">.</span> However the Redis server sometimes has to
# delete keys or flush the whole database as a side effect of other operations<span class="token punctuation">.</span>
# Specifically Redis deletes objects independently of a user call in the
# following scenarios<span class="token operator">:</span>
#
# <span class="token number">1</span><span class="token punctuation">)</span> On eviction<span class="token punctuation">,</span> because of the maxmemory and maxmemory policy configurations<span class="token punctuation">,</span>
#    in order to make room <span class="token keyword">for</span> <span class="token keyword">new</span> <span class="token class-name">data</span><span class="token punctuation">,</span> without going over the specified
#    memory limit<span class="token punctuation">.</span>
# <span class="token number">2</span><span class="token punctuation">)</span> Because of expire<span class="token operator">:</span> when a key with an associated time to <span class="token function">live</span> <span class="token punctuation">(</span>see the
#    EXPIRE command<span class="token punctuation">)</span> must be deleted from memory<span class="token punctuation">.</span>
# <span class="token number">3</span><span class="token punctuation">)</span> Because of a side effect of a command that stores data on a key that may
#    already exist<span class="token punctuation">.</span> For example the RENAME command may delete the old key
#    content when it is replaced with another one<span class="token punctuation">.</span> Similarly SUNIONSTORE
#    or SORT with STORE option may delete existing keys<span class="token punctuation">.</span> The SET command
#    itself removes any old content of the specified key in order to replace
#    it with the specified string<span class="token punctuation">.</span>
# 因为将数据存储在可能已经存在的键上的命令的副作用。例如，重命名命令可以删除替换为其他键内容的旧键内容。
# 类似地，SUNIONSTORE或使用STORE选项排序可以删除现有密钥。SET命令本身删除指定键的任何旧内容，以便用指定的字符串替换它。
# <span class="token number">4</span><span class="token punctuation">)</span> During replication<span class="token punctuation">,</span> when a replica performs a full resynchronization with
#    its master<span class="token punctuation">,</span> the content of the whole database is removed in order to
#    load the RDB file just transferred<span class="token punctuation">.</span>
# 在复制期间，当一个副本执行与其主副本的完全重新同步时，将删除整个数据库的内容，以便加载刚刚传输的RDB文件。
#
# In all the above cases the <span class="token keyword">default</span> is to delete objects in a blocking way<span class="token punctuation">,</span>
# like <span class="token keyword">if</span> DEL was called<span class="token punctuation">.</span> However you can configure each <span class="token keyword">case</span> specifically
# in order to instead release memory in a non<span class="token operator">-</span>blocking way like <span class="token keyword">if</span> UNLINK
# was called<span class="token punctuation">,</span> using the following configuration directives<span class="token punctuation">.</span>
# 在上述所有情况下，默认情况是以阻塞的方式删除对象，就像调用DEL一样。
# 但是，您可以专门配置每种情况，以便以非阻塞的方式释放内存，就像调用UNLINK一样，使用以下配置指令。

lazyfree<span class="token operator">-</span>lazy<span class="token operator">-</span>eviction no
# 是否开启基于lazyfree的驱逐功能 yes，表示开启。no，默认值，表示不开启。
lazyfree<span class="token operator">-</span>lazy<span class="token operator">-</span>expire no
# 是否开启基于lazyfree的过期key删除功能，
lazyfree<span class="token operator">-</span>lazy<span class="token operator">-</span>server<span class="token operator">-</span>del no
# RENAME、SUNIONSTORE等命令是否基于lazyfree异步删除数据
replica<span class="token operator">-</span>lazy<span class="token operator">-</span>flush no

# It is also possible<span class="token punctuation">,</span> <span class="token keyword">for</span> the <span class="token keyword">case</span> when to replace the user code DEL calls
# with UNLINK calls is not easy<span class="token punctuation">,</span> to modify the <span class="token keyword">default</span> behavior of the DEL
# command to act exactly like UNLINK<span class="token punctuation">,</span> using the following configuration
# 在用UNLINK调用替换DEL调用的用户代码不容易的情况下，也可以使用以下配置修改DEL命令的默认行为，使其行为与UNLINK完全一样
# directive<span class="token operator">:</span>
# 执行DEL命令时是否基于lazyfree异步删除数据
lazyfree<span class="token operator">-</span>lazy<span class="token operator">-</span>user<span class="token operator">-</span>del no

################################ THREADED I<span class="token operator">/</span>O #################################
# 多线程 
# Redis is mostly single threaded<span class="token punctuation">,</span> however there are certain threaded
# operations such as UNLINK<span class="token punctuation">,</span> slow I<span class="token operator">/</span>O accesses and other things that are
# performed on side threads<span class="token punctuation">.</span>
# Redis主要是单线程的，但是也有一些特定的线程操作，比如断开链接、缓慢的I<span class="token operator">/</span>O访问和其他在侧线程上执行的操作。
# Now it is also possible to handle Redis clients socket reads and writes
# in different I<span class="token operator">/</span>O threads<span class="token punctuation">.</span> Since especially writing is so slow<span class="token punctuation">,</span> normally
# Redis users use pipelining in order to speedup the Redis performances per
# core<span class="token punctuation">,</span> and spawn multiple instances in order to scale more<span class="token punctuation">.</span> Using I<span class="token operator">/</span>O
# threads it is possible to easily speedup two times Redis without resorting
# to pipelining nor sharding of the instance<span class="token punctuation">.</span>
#
# By <span class="token keyword">default</span> threading is disabled<span class="token punctuation">,</span> we suggest enabling it only in machines
# that have at least <span class="token number">4</span> or more cores<span class="token punctuation">,</span> leaving at least one spare core<span class="token punctuation">.</span>
# Using more than <span class="token number">8</span> threads is unlikely to help much<span class="token punctuation">.</span> We also recommend using
# threaded I<span class="token operator">/</span>O only <span class="token keyword">if</span> you actually have performance problems<span class="token punctuation">,</span> with Redis
# instances being able to use a quite big percentage of CPU time<span class="token punctuation">,</span> otherwise
# there is no point in using <span class="token keyword">this</span> feature<span class="token punctuation">.</span>
# 默认情况下，线程是禁用的，我们建议只在拥有至少<span class="token number">4</span>个或更多内核的机器上启用线程，而保留至少一个备用内核。使用<span class="token number">8</span>个以上的线程不太可能有太大的帮助。
# 我们还建议仅当您确实存在性能问题时才使用线程I<span class="token operator">/</span>O，因为Redis实例能够使用相当大的CPU时间百分比，否则使用此特性是没有意义的。
# So <span class="token keyword">for</span> instance <span class="token keyword">if</span> you have a four cores boxes<span class="token punctuation">,</span> <span class="token keyword">try</span> to use <span class="token number">2</span> or <span class="token number">3</span> I<span class="token operator">/</span>O
# threads<span class="token punctuation">,</span> <span class="token keyword">if</span> you have a <span class="token number">8</span> cores<span class="token punctuation">,</span> <span class="token keyword">try</span> to use <span class="token number">6</span> threads<span class="token punctuation">.</span> In order to
# enable I<span class="token operator">/</span>O threads use the following configuration directive<span class="token operator">:</span>
# 例如，如果你有<span class="token number">4</span>个内核，尝试使用<span class="token number">2</span>或<span class="token number">3</span>个I<span class="token operator">/</span>O线程，如果你有<span class="token number">8</span>个内核，尝试使用<span class="token number">6</span>个线程。为了启用I<span class="token operator">/</span>O线程使用以下配置指令<span class="token operator">:</span>
# io<span class="token operator">-</span>threads <span class="token number">4</span>
#
# Setting io<span class="token operator">-</span>threads to <span class="token number">1</span> will just use the main thread as usually<span class="token punctuation">.</span>
# When I<span class="token operator">/</span>O threads are enabled<span class="token punctuation">,</span> we only use threads <span class="token keyword">for</span> writes<span class="token punctuation">,</span> that is
# to thread the <span class="token function">write</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span> syscall and transfer the client buffers to the
# socket<span class="token punctuation">.</span> However it is also possible to enable threading of reads and
# protocol parsing using the following configuration directive<span class="token punctuation">,</span> by setting
# it to yes<span class="token operator">:</span>
# 将io线程设置为<span class="token number">1</span>只会像往常一样使用主线程。当启用I<span class="token operator">/</span>O线程时，我们只使用线程进行写操作，
# 即线程写系统调用并将客户端缓冲区传输到套接字。然而，也可以启用线程读取和协议解析使用以下配置指令，通过设置为yes<span class="token operator">:</span>
#
# io<span class="token operator">-</span>threads<span class="token operator">-</span><span class="token keyword">do</span><span class="token operator">-</span>reads no
#
# Usually threading reads doesn't help much<span class="token punctuation">.</span>
# 通常线程读取不会有太大帮助。哈哈，也就是百分之八十的人用不到这个玩意儿。
# NOTE <span class="token number">1</span><span class="token operator">:</span> This configuration directive cannot be changed at runtime via
# CONFIG SET<span class="token punctuation">.</span> Aso <span class="token keyword">this</span> feature currently does not work when SSL is
# enabled<span class="token punctuation">.</span>
# 这个配置指令不能在运行时通过配置集进行更改。当启用SSL时，此功能当前无法工作。
# NOTE <span class="token number">2</span><span class="token operator">:</span> If you want to test the Redis speedup using redis<span class="token operator">-</span>benchmark<span class="token punctuation">,</span> make
# sure you also run the benchmark itself in threaded mode<span class="token punctuation">,</span> using the
# <span class="token operator">--</span>threads option to match the number of Redis theads<span class="token punctuation">,</span> otherwise you'll not
# be able to notice the improvements<span class="token punctuation">.</span>
# 如果您想使用Redis <span class="token operator">-</span>benchmark测试Redis加速，请确保您也在线程模式下运行基准测试本身，使用——threads选项来匹配Redis头的数量，否则您将无法注意到这些改进。

############################## APPEND ONLY MODE ###############################
# 追加模式
# By <span class="token keyword">default</span> Redis asynchronously dumps the dataset on disk<span class="token punctuation">.</span> This mode is
# good enough in many applications<span class="token punctuation">,</span> but an issue with the Redis process or
# a power outage may result into a few minutes of writes <span class="token function">lost</span> <span class="token punctuation">(</span>depending on
# the configured save points<span class="token punctuation">)</span><span class="token punctuation">.</span>
# 默认情况下，Redis异步地将数据转储到磁盘上。这种模式在许多应用程序中已经足够好了，但是Redis进程或断电可能会导致几分钟的写丢失<span class="token punctuation">(</span>取决于配置的保存点<span class="token punctuation">)</span>。
# The Append Only File is an alternative persistence mode that provides
# much better durability<span class="token punctuation">.</span> For instance using the <span class="token keyword">default</span> data fsync policy
# <span class="token punctuation">(</span>see later in the config file<span class="token punctuation">)</span> Redis can lose just one second of writes in a
# dramatic event like a server power outage<span class="token punctuation">,</span> or a single write <span class="token keyword">if</span> something
# wrong with the Redis process itself happens<span class="token punctuation">,</span> but the operating system is
# still running correctly<span class="token punctuation">.</span>
# Append Only文件是另一种持久性模式，它提供了更好的持久性。
# 例如使用默认数据fsync策略配置文件中<span class="token punctuation">(</span>见后<span class="token punctuation">)</span>复述<span class="token punctuation">,</span>可以失去只是一秒的写在一个戏剧性的事件像一个服务器断电<span class="token punctuation">,</span>或一个写如果复述过程本身出了问题<span class="token punctuation">,</span>但正确操作系统仍在运行。
#
# AOF and RDB persistence can be enabled at the same time without problems<span class="token punctuation">.</span>
# If the AOF is enabled on startup Redis will load the AOF<span class="token punctuation">,</span> that is the file
# with the better durability guarantees<span class="token punctuation">.</span>
# 可以同时启用AOF和RDB持久性，不会出现问题。如果启动时启用了AOF，则Redis将加载AOF，这是具有更好持久性保证的文件。
# Please check http<span class="token operator">:</span><span class="token operator">/</span><span class="token operator">/</span>redis<span class="token punctuation">.</span>io<span class="token operator">/</span>topics<span class="token operator">/</span>persistence <span class="token keyword">for</span> more information<span class="token punctuation">.</span>
# 是否开启aof持久化。默认不开启
appendonly no

# The name of the append only <span class="token function">file</span> <span class="token punctuation">(</span><span class="token keyword">default</span><span class="token operator">:</span> <span class="token string">"appendonly.aof"</span><span class="token punctuation">)</span>
# 仅追加文件的名称<span class="token punctuation">(</span>默认<span class="token operator">:</span>“appendonly<span class="token punctuation">.</span>aof”<span class="token punctuation">)</span>
appendfilename <span class="token string">"appendonly.aof"</span>

# The <span class="token function">fsync</span><span class="token punctuation">(</span><span class="token punctuation">)</span> call tells the Operating System to actually write data on disk
# instead of waiting <span class="token keyword">for</span> more data in the output buffer<span class="token punctuation">.</span> Some OS will really flush
# data on disk<span class="token punctuation">,</span> some other OS will just <span class="token keyword">try</span> to <span class="token keyword">do</span> it ASAP<span class="token punctuation">.</span>
# <span class="token function">fsync</span><span class="token punctuation">(</span><span class="token punctuation">)</span>调用告诉操作系统实际在磁盘上写入数据，而不是等待输出缓冲区中的更多数据。一些操作系统会真正地刷新磁盘上的数据，而另一些操作系统只是试图尽快完成。
# Redis supports three different modes<span class="token operator">:</span>
# Redis支持三种不同的模式<span class="token operator">:</span>
# no<span class="token operator">:</span> don't fsync<span class="token punctuation">,</span> just let the OS flush the data when it wants<span class="token punctuation">.</span> Faster<span class="token punctuation">.</span>
# 从不fsync，只需将数据交给操作系统即可。更快，更不安全的方法。通常，Linux使用此配置每<span class="token number">30</span>秒刷新一次数据，但这取决于内核的精确调整。
# always<span class="token operator">:</span> fsync after every write to the append only log<span class="token punctuation">.</span> Slow<span class="token punctuation">,</span> Safest<span class="token punctuation">.</span>
# fsync每次将新命令附加到AOF时。非常非常慢，非常安全。
# everysec<span class="token operator">:</span> fsync only one time every second<span class="token punctuation">.</span> Compromise<span class="token punctuation">.</span>
# fsync每秒。速度足够快（在<span class="token number">2.4</span>中可能与快照速度一样快），如果发生灾难，您可能会丢失<span class="token number">1</span>秒的数据。
#
# The <span class="token keyword">default</span> is <span class="token string">"everysec"</span><span class="token punctuation">,</span> as that's usually the right compromise between
# speed and data safety<span class="token punctuation">.</span> It's up to you to understand <span class="token keyword">if</span> you can relax <span class="token keyword">this</span> to
# <span class="token string">"no"</span> that will let the operating system flush the output buffer when
# it wants<span class="token punctuation">,</span> <span class="token keyword">for</span> better <span class="token function">performances</span> <span class="token punctuation">(</span>but <span class="token keyword">if</span> you can live with the idea of
# some data loss consider the <span class="token keyword">default</span> persistence mode that's snapshotting<span class="token punctuation">)</span><span class="token punctuation">,</span>
# or on the contrary<span class="token punctuation">,</span> use <span class="token string">"always"</span> that's very slow but a bit safer than
# everysec<span class="token punctuation">.</span>
# 默认值是“everysec”，因为这通常是速度和数据安全性之间的正确折衷。由你理解如果你能放松这个“不”字<span class="token punctuation">,</span>让操作系统刷新输出缓冲区时<span class="token punctuation">,</span>
# 为了更好的表现<span class="token punctuation">(</span>但是如果你可以忍受一些数据丢失的想法考虑默认快照的持久性模式<span class="token punctuation">)</span><span class="token punctuation">,</span>或相反<span class="token punctuation">,</span>使用“总是”非常缓慢但比everysec更安全一点。
# More details please check the following article<span class="token operator">:</span>
# http<span class="token operator">:</span><span class="token operator">/</span><span class="token operator">/</span>antirez<span class="token punctuation">.</span>com<span class="token operator">/</span>post<span class="token operator">/</span>redis<span class="token operator">-</span>persistence<span class="token operator">-</span>demystified<span class="token punctuation">.</span>html
#
# If unsure<span class="token punctuation">,</span> use <span class="token string">"everysec"</span><span class="token punctuation">.</span>
# 如果不确定，使用“everysec”。
# appendfsync always
appendfsync everysec
# appendfsync no

# When the AOF fsync policy is set to always or everysec<span class="token punctuation">,</span> and a background
# saving <span class="token function">process</span> <span class="token punctuation">(</span>a background save or AOF log background rewriting<span class="token punctuation">)</span> is
# performing a lot of I<span class="token operator">/</span>O against the disk<span class="token punctuation">,</span> in some Linux configurations
# Redis may block too <span class="token keyword">long</span> on the <span class="token function">fsync</span><span class="token punctuation">(</span><span class="token punctuation">)</span> call<span class="token punctuation">.</span> Note that there is no fix <span class="token keyword">for</span>
# <span class="token keyword">this</span> currently<span class="token punctuation">,</span> as even performing fsync in a different thread will block
# our synchronous <span class="token function">write</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span> call<span class="token punctuation">.</span>
#
# In order to mitigate <span class="token keyword">this</span> problem it's possible to use the following option
# that will prevent <span class="token function">fsync</span><span class="token punctuation">(</span><span class="token punctuation">)</span> from being called in the main process <span class="token keyword">while</span> a
# BGSAVE or BGREWRITEAOF is in progress<span class="token punctuation">.</span>
#
# This means that <span class="token keyword">while</span> another child is saving<span class="token punctuation">,</span> the durability of Redis is
# the same as <span class="token string">"appendfsync none"</span><span class="token punctuation">.</span> In practical terms<span class="token punctuation">,</span> <span class="token keyword">this</span> means that it is
# possible to lose up to <span class="token number">30</span> seconds of log in the worst <span class="token function">scenario</span> <span class="token punctuation">(</span>with the
# <span class="token keyword">default</span> Linux settings<span class="token punctuation">)</span><span class="token punctuation">.</span>
#
# If you have latency problems turn <span class="token keyword">this</span> to <span class="token string">"yes"</span><span class="token punctuation">.</span> Otherwise leave it as
# <span class="token string">"no"</span> that is the safest pick from the point of view of durability<span class="token punctuation">.</span>
# 如果你有延迟问题，将此选项变为“yes”。否则，从耐久性的角度来看，“no”是最安全的选择。
no<span class="token operator">-</span>appendfsync<span class="token operator">-</span>on<span class="token operator">-</span>rewrite no

# Automatic rewrite of the append only file<span class="token punctuation">.</span>
# 自动重写仅追加文件。
# Redis is able to automatically rewrite the log file implicitly calling
# BGREWRITEAOF when the AOF log size grows by the specified percentage<span class="token punctuation">.</span>
# Redis能够在日志大小按指定百分比增长时自动重写隐式调用BGREWRITEAOF的日志文件。
# This is how it works<span class="token operator">:</span> Redis remembers the size of the AOF file after the
# latest <span class="token function">rewrite</span> <span class="token punctuation">(</span><span class="token keyword">if</span> no rewrite has happened since the restart<span class="token punctuation">,</span> the size of
# the AOF at startup is used<span class="token punctuation">)</span><span class="token punctuation">.</span>
# 它是这样工作的<span class="token operator">:</span>Redis记住了最近一次重写后的AOF文件的大小<span class="token punctuation">(</span>如果重新启动后没有发生重写，则使用启动时的AOF大小<span class="token punctuation">)</span>。
#
# This base size is compared to the current size<span class="token punctuation">.</span> If the current size is
# bigger than the specified percentage<span class="token punctuation">,</span> the rewrite is triggered<span class="token punctuation">.</span> Also
# you need to specify a minimal size <span class="token keyword">for</span> the AOF file to be rewritten<span class="token punctuation">,</span> <span class="token keyword">this</span>
# is useful to avoid rewriting the AOF file even <span class="token keyword">if</span> the percentage increase
# is reached but it is still pretty small<span class="token punctuation">.</span>
# 这个基本大小与当前大小进行比较。如果当前大小大于指定的百分比，则会触发重写。
# 此外，您还需要为要重写的AOF文件指定最小的大小，这对于避免重写AOF文件非常有用，即使百分比会增加到达，但它仍然是相当小的。
# Specify a percentage of zero in order to disable the automatic AOF
# rewrite feature<span class="token punctuation">.</span>
# 指定零的百分比，以禁用自动AOF重写特性。
# 当文件超过上次rewrite的百分之百的时候就会重写。
# 对于下面的我是这样认为的：
# 当前AOF文件大小超过上一次重写的AOF文件大小的百分之多少才会重写
# 即为：当文件超过64mb开启重写，如果超过<span class="token number">64</span>的百分之百，也就是超过<span class="token number">64</span><span class="token operator">*</span><span class="token number">2</span><span class="token operator">=</span><span class="token number">128</span>的时候再次重写。

auto<span class="token operator">-</span>aof<span class="token operator">-</span>rewrite<span class="token operator">-</span>percentage <span class="token number">100</span>
auto<span class="token operator">-</span>aof<span class="token operator">-</span>rewrite<span class="token operator">-</span>min<span class="token operator">-</span>size 64mb

# An AOF file may be found to be truncated at the end during the Redis
# startup process<span class="token punctuation">,</span> when the AOF data gets loaded back into memory<span class="token punctuation">.</span>
# This may happen when the system where Redis is running
# crashes<span class="token punctuation">,</span> especially when an ext4 filesystem is mounted without the
# data<span class="token operator">=</span>ordered <span class="token function">option</span> <span class="token punctuation">(</span>however <span class="token keyword">this</span> can't happen when Redis itself
# crashes or aborts but the operating system still works correctly<span class="token punctuation">)</span><span class="token punctuation">.</span>
#
# Redis can either exit with an error when <span class="token keyword">this</span> happens<span class="token punctuation">,</span> or load as much
# data as <span class="token function">possible</span> <span class="token punctuation">(</span>the <span class="token keyword">default</span> now<span class="token punctuation">)</span> and start <span class="token keyword">if</span> the AOF file is found
# to be truncated at the end<span class="token punctuation">.</span> The following option controls <span class="token keyword">this</span> behavior<span class="token punctuation">.</span>
#
# If aof<span class="token operator">-</span>load<span class="token operator">-</span>truncated is set to yes<span class="token punctuation">,</span> a truncated AOF file is loaded and
# the Redis server starts emitting a log to inform the user of the event<span class="token punctuation">.</span>
# Otherwise <span class="token keyword">if</span> the option is set to no<span class="token punctuation">,</span> the server aborts with an error
# and refuses to start<span class="token punctuation">.</span> When the option is set to no<span class="token punctuation">,</span> the user requires
# to fix the AOF file using the <span class="token string">"redis-check-aof"</span> utility before to restart
# the server<span class="token punctuation">.</span>
#
# Note that <span class="token keyword">if</span> the AOF file will be found to be corrupted in the middle
# the server will still exit with an error<span class="token punctuation">.</span> This option only applies when
# Redis will <span class="token keyword">try</span> to read more data from the AOF file but not enough bytes
# will be found<span class="token punctuation">.</span>
# 注意，如果AOF文件在中间被破坏，服务器仍然会带着错误退出。这个选项只适用于当Redis试图从AOF文件读取更多的数据，但没有足够的字节将被发现。
# redis在启动时可以加载被截断的AOF文件
aof<span class="token operator">-</span>load<span class="token operator">-</span>truncated yes

# When rewriting the AOF file<span class="token punctuation">,</span> Redis is able to use an RDB preamble in the
# AOF file <span class="token keyword">for</span> faster rewrites and recoveries<span class="token punctuation">.</span> When <span class="token keyword">this</span> option is turned
# on the rewritten AOF file is composed of two different stanzas<span class="token operator">:</span>
# 当重写AOF文件时，Redis能够在AOF文件中使用一个RDB序言，以便更快地重写和恢复。当这个选项打开时，重写的AOF文件由两个不同的节组成<span class="token operator">:</span>
#   <span class="token punctuation">[</span>RDB file<span class="token punctuation">]</span><span class="token punctuation">[</span>AOF tail<span class="token punctuation">]</span>
#
# When loading Redis recognizes that the AOF file starts with the <span class="token string">"REDIS"</span>
# string and loads the prefixed RDB file<span class="token punctuation">,</span> and continues loading the AOF
# tail<span class="token punctuation">.</span>
# 当加载Redis时，它识别出AOF文件以“Redis”字符串开始并加载前缀RDB文件，然后继续加载AOF尾部。
aof<span class="token operator">-</span>use<span class="token operator">-</span>rdb<span class="token operator">-</span>preamble yes

################################ LUA SCRIPTING  ###############################
# LUA脚本
# Max execution time of a Lua script in milliseconds<span class="token punctuation">.</span>
# Lua脚本的最大执行时间<span class="token punctuation">(</span>以毫秒为单位<span class="token punctuation">)</span>

# If the maximum execution time is reached Redis will log that a script is
# still in execution after the maximum allowed time and will start to
# reply to queries with an error<span class="token punctuation">.</span>
# 如果达到最大执行时间，Redis将记录脚本在最大允许时间之后仍在执行，并开始用错误回复查询。
# When a <span class="token keyword">long</span> running script exceeds the maximum execution time only the
# SCRIPT KILL and SHUTDOWN NOSAVE commands are available<span class="token punctuation">.</span> The first can be
# used to stop a script that did not yet called write commands<span class="token punctuation">.</span> The second
# is the only way to shut down the server in the <span class="token keyword">case</span> a write command was
# already issued by the script but the user doesn't want to wait <span class="token keyword">for</span> the natural
# termination of the script<span class="token punctuation">.</span>
#
# Set it to <span class="token number">0</span> or a negative value <span class="token keyword">for</span> unlimited execution without warnings<span class="token punctuation">.</span>
# 将其设置为<span class="token number">0</span>或负值，以便在没有警告的情况下无限执行。
lua<span class="token operator">-</span>time<span class="token operator">-</span>limit <span class="token number">5000</span>

################################ REDIS CLUSTER  ###############################
# 分布式集群配置
# Normal Redis instances can't be part of a Redis Cluster<span class="token punctuation">;</span> only nodes that are
# started as cluster nodes can<span class="token punctuation">.</span> In order to start a Redis instance as a
# cluster node enable the cluster support uncommenting the following<span class="token operator">:</span>
# 正常的Redis实例不能成为Redis集群的一部分<span class="token punctuation">;</span>只有作为集群节点启动的节点可以。为了启动一个Redis实例作为一个集群节点启用集群支持取消注释如下<span class="token operator">:</span>
# cluster<span class="token operator">-</span>enabled yes

# Every cluster node has a cluster configuration file<span class="token punctuation">.</span> This file is not
# intended to be edited by hand<span class="token punctuation">.</span> It is created and updated by Redis nodes<span class="token punctuation">.</span>
# Every Redis Cluster node requires a different cluster configuration file<span class="token punctuation">.</span>
# Make sure that instances running in the same system <span class="token keyword">do</span> not have
# overlapping cluster configuration file names<span class="token punctuation">.</span>
# 每个集群节点都有一个集群配置文件。此文件不打算手工编辑。它由Redis节点创建和更新。
# 每个Redis集群节点都需要一个不同的集群配置文件。确保在同一系统中运行的实例没有重叠的集群配置文件名。
# cluster<span class="token operator">-</span>config<span class="token operator">-</span>file nodes<span class="token operator">-</span><span class="token number">6379</span><span class="token punctuation">.</span>conf

# Cluster node timeout is the amount of milliseconds a node must be unreachable
# <span class="token keyword">for</span> it to be considered in failure state<span class="token punctuation">.</span>
# 群集节点超时是节点必须不可达的毫秒数，以便将其视为故障状态。
# Most other internal time limits are multiple of the node timeout<span class="token punctuation">.</span>
# 大多数其他内部时间限制是多个节点超时。
# cluster<span class="token operator">-</span>node<span class="token operator">-</span>timeout <span class="token number">15000</span>

# A replica of a failing master will avoid to start a failover <span class="token keyword">if</span> its data
# looks too old<span class="token punctuation">.</span>
# 如果数据看起来太旧，失败主服务器的副本将避免启动故障转移。
# There is no simple way <span class="token keyword">for</span> a replica to actually have an exact measure of
# its <span class="token string">"data age"</span><span class="token punctuation">,</span> so the following two checks are performed<span class="token operator">:</span>
#
# <span class="token number">1</span><span class="token punctuation">)</span> If there are multiple replicas able to failover<span class="token punctuation">,</span> they exchange messages
#    in order to <span class="token keyword">try</span> to give an advantage to the replica with the best
#    replication <span class="token function">offset</span> <span class="token punctuation">(</span>more data from the master processed<span class="token punctuation">)</span><span class="token punctuation">.</span>
#    Replicas will <span class="token keyword">try</span> to get their rank by offset<span class="token punctuation">,</span> and apply to the start
#    of the failover a delay proportional to their rank<span class="token punctuation">.</span>
#
# <span class="token number">2</span><span class="token punctuation">)</span> Every single replica computes the time of the last interaction with
#    its master<span class="token punctuation">.</span> This can be the last ping or command <span class="token function">received</span> <span class="token punctuation">(</span><span class="token keyword">if</span> the master
#    is still in the <span class="token string">"connected"</span> state<span class="token punctuation">)</span><span class="token punctuation">,</span> or the time that elapsed since the
#    disconnection with the <span class="token function">master</span> <span class="token punctuation">(</span><span class="token keyword">if</span> the replication link is currently down<span class="token punctuation">)</span><span class="token punctuation">.</span>
#    If the last interaction is too old<span class="token punctuation">,</span> the replica will not <span class="token keyword">try</span> to failover
#    at all<span class="token punctuation">.</span>
#
# The point <span class="token string">"2"</span> can be tuned by user<span class="token punctuation">.</span> Specifically a replica will not perform
# the failover <span class="token keyword">if</span><span class="token punctuation">,</span> since the last interaction with the master<span class="token punctuation">,</span> the time
# elapsed is greater than<span class="token operator">:</span>
#
#   <span class="token punctuation">(</span>node<span class="token operator">-</span>timeout <span class="token operator">*</span> replica<span class="token operator">-</span>validity<span class="token operator">-</span>factor<span class="token punctuation">)</span> <span class="token operator">+</span> repl<span class="token operator">-</span>ping<span class="token operator">-</span>replica<span class="token operator">-</span>period
#
# So <span class="token keyword">for</span> example <span class="token keyword">if</span> node<span class="token operator">-</span>timeout is <span class="token number">30</span> seconds<span class="token punctuation">,</span> and the replica<span class="token operator">-</span>validity<span class="token operator">-</span>factor
# is <span class="token number">10</span><span class="token punctuation">,</span> and assuming a <span class="token keyword">default</span> repl<span class="token operator">-</span>ping<span class="token operator">-</span>replica<span class="token operator">-</span>period of <span class="token number">10</span> seconds<span class="token punctuation">,</span> the
# replica will not <span class="token keyword">try</span> to failover <span class="token keyword">if</span> it was not able to talk with the master
# <span class="token keyword">for</span> longer than <span class="token number">310</span> seconds<span class="token punctuation">.</span>
#
# A large replica<span class="token operator">-</span>validity<span class="token operator">-</span>factor may allow replicas with too old data to failover
# a master<span class="token punctuation">,</span> <span class="token keyword">while</span> a too small value may prevent the cluster from being able to
# elect a replica at all<span class="token punctuation">.</span>
#
# For maximum availability<span class="token punctuation">,</span> it is possible to set the replica<span class="token operator">-</span>validity<span class="token operator">-</span>factor
# to a value of <span class="token number">0</span><span class="token punctuation">,</span> which means<span class="token punctuation">,</span> that replicas will always <span class="token keyword">try</span> to failover the
# master regardless of the last time they interacted with the master<span class="token punctuation">.</span>
# <span class="token punctuation">(</span>However they'll always <span class="token keyword">try</span> to apply a delay proportional to their
# offset rank<span class="token punctuation">)</span><span class="token punctuation">.</span>
#
# Zero is the only value able to guarantee that when all the partitions heal
# the cluster will always be able to <span class="token keyword">continue</span><span class="token punctuation">.</span>
#
# cluster<span class="token operator">-</span>replica<span class="token operator">-</span>validity<span class="token operator">-</span>factor <span class="token number">10</span>

# Cluster replicas are able to migrate to orphaned masters<span class="token punctuation">,</span> that are masters
# that are left without working replicas<span class="token punctuation">.</span> This improves the cluster ability
# to resist to failures as otherwise an orphaned master can't be failed over
# in <span class="token keyword">case</span> of failure <span class="token keyword">if</span> it has no working replicas<span class="token punctuation">.</span>
#
# Replicas migrate to orphaned masters only <span class="token keyword">if</span> there are still at least a
# given number of other working replicas <span class="token keyword">for</span> their old master<span class="token punctuation">.</span> This number
# is the <span class="token string">"migration barrier"</span><span class="token punctuation">.</span> A migration barrier of <span class="token number">1</span> means that a replica
# will migrate only <span class="token keyword">if</span> there is at least <span class="token number">1</span> other working replica <span class="token keyword">for</span> its master
# and so forth<span class="token punctuation">.</span> It usually reflects the number of replicas you want <span class="token keyword">for</span> every
# master in your cluster<span class="token punctuation">.</span>
#
# Default is <span class="token function">1</span> <span class="token punctuation">(</span>replicas migrate only <span class="token keyword">if</span> their masters remain with at least
# one replica<span class="token punctuation">)</span><span class="token punctuation">.</span> To disable migration just set it to a very large value<span class="token punctuation">.</span>
# A value of <span class="token number">0</span> can be set but is useful only <span class="token keyword">for</span> debugging and dangerous
# in production<span class="token punctuation">.</span>
#
# cluster<span class="token operator">-</span>migration<span class="token operator">-</span>barrier <span class="token number">1</span>

# By <span class="token keyword">default</span> Redis Cluster nodes stop accepting queries <span class="token keyword">if</span> they detect there
# is at least an hash slot <span class="token function">uncovered</span> <span class="token punctuation">(</span>no available node is serving it<span class="token punctuation">)</span><span class="token punctuation">.</span>
# This way <span class="token keyword">if</span> the cluster is partially <span class="token function">down</span> <span class="token punctuation">(</span><span class="token keyword">for</span> example a range of hash slots
# are no longer covered<span class="token punctuation">)</span> all the cluster becomes<span class="token punctuation">,</span> eventually<span class="token punctuation">,</span> unavailable<span class="token punctuation">.</span>
# It automatically returns available as soon as all the slots are covered again<span class="token punctuation">.</span>
#
# However sometimes you want the subset of the cluster which is working<span class="token punctuation">,</span>
# to <span class="token keyword">continue</span> to accept queries <span class="token keyword">for</span> the part of the key space that is still
# covered<span class="token punctuation">.</span> In order to <span class="token keyword">do</span> so<span class="token punctuation">,</span> just set the cluster<span class="token operator">-</span>require<span class="token operator">-</span>full<span class="token operator">-</span>coverage
# option to no<span class="token punctuation">.</span>
#
# cluster<span class="token operator">-</span>require<span class="token operator">-</span>full<span class="token operator">-</span>coverage yes

# This option<span class="token punctuation">,</span> when set to yes<span class="token punctuation">,</span> prevents replicas from trying to failover its
# master during master failures<span class="token punctuation">.</span> However the master can still perform a
# manual failover<span class="token punctuation">,</span> <span class="token keyword">if</span> forced to <span class="token keyword">do</span> so<span class="token punctuation">.</span>
#
# This is useful in different scenarios<span class="token punctuation">,</span> especially in the <span class="token keyword">case</span> of multiple
# data center operations<span class="token punctuation">,</span> where we want one side to never be promoted <span class="token keyword">if</span> not
# in the <span class="token keyword">case</span> of a total DC failure<span class="token punctuation">.</span>
#
# cluster<span class="token operator">-</span>replica<span class="token operator">-</span>no<span class="token operator">-</span>failover no

# This option<span class="token punctuation">,</span> when set to yes<span class="token punctuation">,</span> allows nodes to serve read traffic <span class="token keyword">while</span> the
# the cluster is in a down state<span class="token punctuation">,</span> as <span class="token keyword">long</span> as it believes it owns the slots<span class="token punctuation">.</span> 
#
# This is useful <span class="token keyword">for</span> two cases<span class="token punctuation">.</span>  The first <span class="token keyword">case</span> is <span class="token keyword">for</span> when an application 
# doesn't require consistency of data during node failures or network partitions<span class="token punctuation">.</span>
# One example of <span class="token keyword">this</span> is a cache<span class="token punctuation">,</span> where as <span class="token keyword">long</span> as the node has the data it
# should be able to serve it<span class="token punctuation">.</span> 
#
# The second use <span class="token keyword">case</span> is <span class="token keyword">for</span> configurations that don't meet the recommended  
# three shards but want to enable cluster mode and scale later<span class="token punctuation">.</span> A 
# master outage in a <span class="token number">1</span> or <span class="token number">2</span> shard configuration causes a read<span class="token operator">/</span>write outage to the
# entire cluster without <span class="token keyword">this</span> option set<span class="token punctuation">,</span> with it set there is only a write outage<span class="token punctuation">.</span>
# Without a quorum of masters<span class="token punctuation">,</span> slot ownership will not change automatically<span class="token punctuation">.</span> 
#
# cluster<span class="token operator">-</span>allow<span class="token operator">-</span>reads<span class="token operator">-</span>when<span class="token operator">-</span>down no

# In order to setup your cluster make sure to read the documentation
# available at http<span class="token operator">:</span><span class="token operator">/</span><span class="token operator">/</span>redis<span class="token punctuation">.</span>io web site<span class="token punctuation">.</span>

########################## CLUSTER DOCKER<span class="token operator">/</span>NAT support  ########################

# In certain deployments<span class="token punctuation">,</span> Redis Cluster nodes address discovery fails<span class="token punctuation">,</span> because
# addresses are NAT<span class="token operator">-</span>ted or because ports are <span class="token function">forwarded</span> <span class="token punctuation">(</span>the typical <span class="token keyword">case</span> is
# Docker and other containers<span class="token punctuation">)</span><span class="token punctuation">.</span>
#
# In order to make Redis Cluster working in such environments<span class="token punctuation">,</span> a <span class="token keyword">static</span>
# configuration where each node knows its <span class="token keyword">public</span> address is needed<span class="token punctuation">.</span> The
# following two options are used <span class="token keyword">for</span> <span class="token keyword">this</span> scope<span class="token punctuation">,</span> and are<span class="token operator">:</span>
#
# <span class="token operator">*</span> cluster<span class="token operator">-</span>announce<span class="token operator">-</span>ip
# <span class="token operator">*</span> cluster<span class="token operator">-</span>announce<span class="token operator">-</span>port
# <span class="token operator">*</span> cluster<span class="token operator">-</span>announce<span class="token operator">-</span>bus<span class="token operator">-</span>port
#
# Each instruct the node about its address<span class="token punctuation">,</span> client port<span class="token punctuation">,</span> and cluster message
# bus port<span class="token punctuation">.</span> The information is then published in the header of the bus packets
# so that other nodes will be able to correctly map the address of the node
# publishing the information<span class="token punctuation">.</span>
#
# If the above options are not used<span class="token punctuation">,</span> the normal Redis Cluster auto<span class="token operator">-</span>detection
# will be used instead<span class="token punctuation">.</span>
#
# Note that when remapped<span class="token punctuation">,</span> the bus port may not be at the fixed offset of
# clients port <span class="token operator">+</span> <span class="token number">10000</span><span class="token punctuation">,</span> so you can specify any port and bus<span class="token operator">-</span>port depending
# on how they get remapped<span class="token punctuation">.</span> If the bus<span class="token operator">-</span>port is not set<span class="token punctuation">,</span> a fixed offset of
# <span class="token number">10000</span> will be used as usually<span class="token punctuation">.</span>
#
# Example<span class="token operator">:</span>
#
# cluster<span class="token operator">-</span>announce<span class="token operator">-</span>ip <span class="token number">10.1</span><span class="token punctuation">.</span><span class="token number">1.5</span>
# cluster<span class="token operator">-</span>announce<span class="token operator">-</span>port <span class="token number">6379</span>
# cluster<span class="token operator">-</span>announce<span class="token operator">-</span>bus<span class="token operator">-</span>port <span class="token number">6380</span>

################################## SLOW LOG ###################################

# The Redis Slow Log is a system to log queries that exceeded a specified
# execution time<span class="token punctuation">.</span> The execution time does not include the I<span class="token operator">/</span>O operations
# like talking with the client<span class="token punctuation">,</span> sending the reply and so forth<span class="token punctuation">,</span>
# but just the time needed to actually execute the <span class="token function">command</span> <span class="token punctuation">(</span><span class="token keyword">this</span> is the only
# stage of command execution where the thread is blocked and can not serve
# other requests in the meantime<span class="token punctuation">)</span><span class="token punctuation">.</span>
# Redis慢日志是一个记录超过指定执行时间的查询的系统。执行时间不包括I <span class="token operator">/</span> O操作<span class="token punctuation">,</span>比如与客户端<span class="token punctuation">,</span>发送应答等等<span class="token punctuation">,</span>
# 但就实际执行命令所需的时间<span class="token punctuation">(</span>这是唯一阶段命令执行的线程被阻塞<span class="token punctuation">,</span>不能同时处理其他请求<span class="token punctuation">)</span>。
# You can configure the slow log with two parameters<span class="token operator">:</span> one tells Redis
# what is the execution time<span class="token punctuation">,</span> in microseconds<span class="token punctuation">,</span> to exceed in order <span class="token keyword">for</span> the
# command to get logged<span class="token punctuation">,</span> and the other parameter is the length of the
# slow log<span class="token punctuation">.</span> When a <span class="token keyword">new</span> <span class="token class-name">command</span> is logged the oldest one is removed from the
# queue of logged commands<span class="token punctuation">.</span>
# 您可以使用两个参数配置慢日志<span class="token operator">:</span>一个参数告诉Redis命令的执行时间<span class="token punctuation">(</span>以微秒为单位<span class="token punctuation">)</span>超过了多少，
# 以便记录命令，另一个参数是慢日志的长度。当记录一个新命令时，将从记录的命令队列中删除最旧的命令。
# The following time is expressed in microseconds<span class="token punctuation">,</span> so <span class="token number">1000000</span> is equivalent
# to one second<span class="token punctuation">.</span> Note that a negative number disables the slow log<span class="token punctuation">,</span> <span class="token keyword">while</span>
# a value of zero forces the logging of every command<span class="token punctuation">.</span>
# 下面的时间用微秒表示，所以<span class="token number">1000000</span>等于<span class="token number">1</span>秒。注意，负数会禁用慢日志，而值<span class="token number">0</span>则强制对每个命令进行日志记录。
slowlog<span class="token operator">-</span>log<span class="token operator">-</span>slower<span class="token operator">-</span>than <span class="token number">10000</span>

# There is no limit to <span class="token keyword">this</span> length<span class="token punctuation">.</span> Just be aware that it will consume memory<span class="token punctuation">.</span>
# You can reclaim memory used by the slow log with SLOWLOG RESET<span class="token punctuation">.</span>
# 这个长度没有限制。请注意，它会消耗内存。您可以通过重新设置慢日志来回收慢日志使用的内存。
slowlog<span class="token operator">-</span>max<span class="token operator">-</span>len <span class="token number">128</span>

################################ LATENCY MONITOR ##############################

# The Redis latency monitoring subsystem samples different operations
# at runtime in order to collect data related to possible sources of
# latency of a Redis instance<span class="token punctuation">.</span>
# Redis延迟监视子系统在运行时采样不同的操作，以便收集与Redis实例的潜在延迟源相关的数据。
# Via the LATENCY command <span class="token keyword">this</span> information is available to the user that can
# print graphs and obtain reports<span class="token punctuation">.</span>
# 通过LATENCY命令，可以将此信息提供给能够打印图形和获取报告的用户。
# The system only logs operations that were performed in a time equal or
# greater than the amount of milliseconds specified via the
# latency<span class="token operator">-</span>monitor<span class="token operator">-</span>threshold configuration directive<span class="token punctuation">.</span> When its value is set
# to zero<span class="token punctuation">,</span> the latency monitor is turned off<span class="token punctuation">.</span>
# 系统只记录在等于或大于通过延迟监视阈值配置指令指定的毫秒数的时间内执行的操作。当其值设置为零时，延迟监控器将被关闭。
# By <span class="token keyword">default</span> latency monitoring is disabled since it is mostly not needed
# <span class="token keyword">if</span> you don't have latency issues<span class="token punctuation">,</span> and collecting data has a performance
# impact<span class="token punctuation">,</span> that <span class="token keyword">while</span> very small<span class="token punctuation">,</span> can be measured under big load<span class="token punctuation">.</span> Latency
# monitoring can easily be enabled at runtime using the command
# <span class="token string">"CONFIG SET latency-monitor-threshold &lt;milliseconds>"</span> <span class="token keyword">if</span> needed<span class="token punctuation">.</span>
# 默认情况下，延迟监视是禁用的，因为如果没有延迟问题，那么基本上不需要延迟监视，而且收集数据对性能有影响，虽然非常小，但是可以在大负载下测量。
# 如果需要，可以在运行时使用“latency<span class="token operator">-</span>monitor<span class="token operator">-</span>threshold <span class="token operator">&lt;</span>milliseconds<span class="token operator">></span>”命令轻松启用延迟监视
# 延时监控的采样时间阈值（最小值）。单位毫秒
latency<span class="token operator">-</span>monitor<span class="token operator">-</span>threshold <span class="token number">0</span>

############################# EVENT NOTIFICATION ##############################
# 事件通知
# Redis can notify Pub<span class="token operator">/</span>Sub clients about events happening in the key space<span class="token punctuation">.</span>
# This feature is documented at http<span class="token operator">:</span><span class="token operator">/</span><span class="token operator">/</span>redis<span class="token punctuation">.</span>io<span class="token operator">/</span>topics<span class="token operator">/</span>notifications
#
# For instance <span class="token keyword">if</span> keyspace events notification is enabled<span class="token punctuation">,</span> and a client
# performs a DEL operation on key <span class="token string">"foo"</span> stored in the Database <span class="token number">0</span><span class="token punctuation">,</span> two
# messages will be published via Pub<span class="token operator">/</span>Sub<span class="token operator">:</span>
#
# PUBLISH __keyspace<span class="token annotation punctuation">@0__</span><span class="token operator">:</span>foo del
# PUBLISH __keyevent<span class="token annotation punctuation">@0__</span><span class="token operator">:</span>del foo
#
# It is possible to select the events that Redis will notify among a set
# of classes<span class="token punctuation">.</span> Every <span class="token keyword">class</span> <span class="token class-name">is</span> identified by a single character<span class="token operator">:</span>
#
#  K     Keyspace events<span class="token punctuation">,</span> published with __keyspace@<span class="token operator">&lt;</span>db<span class="token operator">></span>__ prefix<span class="token punctuation">.</span>
#  E     Keyevent events<span class="token punctuation">,</span> published with __keyevent@<span class="token operator">&lt;</span>db<span class="token operator">></span>__ prefix<span class="token punctuation">.</span>
#  g     Generic <span class="token function">commands</span> <span class="token punctuation">(</span>non<span class="token operator">-</span>type specific<span class="token punctuation">)</span> like DEL<span class="token punctuation">,</span> EXPIRE<span class="token punctuation">,</span> RENAME<span class="token punctuation">,</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
#  $     String commands
#  l     List commands
#  s     Set commands
#  h     Hash commands
#  z     Sorted set commands
#  x     Expired <span class="token function">events</span> <span class="token punctuation">(</span>events generated every time a key expires<span class="token punctuation">)</span>
#  e     Evicted <span class="token function">events</span> <span class="token punctuation">(</span>events generated when a key is evicted <span class="token keyword">for</span> maxmemory<span class="token punctuation">)</span>
#  t     Stream commands
#  m     Key<span class="token operator">-</span>miss <span class="token function">events</span> <span class="token punctuation">(</span>Note<span class="token operator">:</span> It is not included in the <span class="token string">'A'</span> <span class="token keyword">class</span><span class="token punctuation">)</span>
#  A     Alias <span class="token keyword">for</span> g$lshzxet<span class="token punctuation">,</span> so that the <span class="token string">"AKE"</span> string means all the events
#        <span class="token punctuation">(</span>Except key<span class="token operator">-</span>miss events which are excluded from <span class="token string">'A'</span> due to their
#         unique nature<span class="token punctuation">)</span><span class="token punctuation">.</span>
#
#  The <span class="token string">"notify-keyspace-events"</span> takes as argument a string that is composed
#  of zero or multiple characters<span class="token punctuation">.</span> The empty string means that notifications
#  are disabled<span class="token punctuation">.</span>
#
#  Example<span class="token operator">:</span> to enable list and generic events<span class="token punctuation">,</span> from the point of view of the
#           event name<span class="token punctuation">,</span> use<span class="token operator">:</span>
#
#  notify<span class="token operator">-</span>keyspace<span class="token operator">-</span>events Elg
#
#  Example <span class="token number">2</span><span class="token operator">:</span> to get the stream of the expired keys subscribing to channel
#             name __keyevent<span class="token annotation punctuation">@0__</span><span class="token operator">:</span>expired use<span class="token operator">:</span>
#
#  notify<span class="token operator">-</span>keyspace<span class="token operator">-</span>events Ex
#
#  By <span class="token keyword">default</span> all notifications are disabled because most users don't need
#  <span class="token keyword">this</span> feature and the feature has some overhead<span class="token punctuation">.</span> Note that <span class="token keyword">if</span> you don't
#  specify at least one of K or E<span class="token punctuation">,</span> no events will be delivered<span class="token punctuation">.</span>
# 键空间通知，配置该参数后客户端可以通过Redis的订阅与发布功能，来接收那些以某种方式改动了Redis数据集的事件。
notify<span class="token operator">-</span>keyspace<span class="token operator">-</span>events <span class="token string">""</span>

############################### GOPHER SERVER #################################

# Redis contains an implementation of the Gopher protocol<span class="token punctuation">,</span> as specified in
# the RFC <span class="token function">1436</span> <span class="token punctuation">(</span>https<span class="token operator">:</span><span class="token operator">/</span><span class="token operator">/</span>www<span class="token punctuation">.</span>ietf<span class="token punctuation">.</span>org<span class="token operator">/</span>rfc<span class="token operator">/</span>rfc1436<span class="token punctuation">.</span>txt<span class="token punctuation">)</span><span class="token punctuation">.</span>
#
# The Gopher protocol was very popular in the late '90s<span class="token punctuation">.</span> It is an alternative
# to the web<span class="token punctuation">,</span> and the implementation both server and client side is so simple
# that the Redis server has just <span class="token number">100</span> lines of code in order to implement <span class="token keyword">this</span>
# support<span class="token punctuation">.</span>
#
# What <span class="token keyword">do</span> you <span class="token keyword">do</span> with Gopher nowadays<span class="token operator">?</span> Well Gopher never <span class="token operator">*</span>really<span class="token operator">*</span> died<span class="token punctuation">,</span> and
# lately there is a movement in order <span class="token keyword">for</span> the Gopher more hierarchical content
# composed of just plain text documents to be resurrected<span class="token punctuation">.</span> Some want a simpler
# internet<span class="token punctuation">,</span> others believe that the mainstream internet became too much
# controlled<span class="token punctuation">,</span> and it's cool to create an alternative space <span class="token keyword">for</span> people that
# want a bit of fresh air<span class="token punctuation">.</span>
#
# Anyway <span class="token keyword">for</span> the 10nth birthday of the Redis<span class="token punctuation">,</span> we gave it the Gopher protocol
# as a gift<span class="token punctuation">.</span>
#
# <span class="token operator">--</span><span class="token operator">-</span> HOW IT WORKS<span class="token operator">?</span> <span class="token operator">--</span><span class="token operator">-</span>
#
# The Redis Gopher support uses the inline protocol of Redis<span class="token punctuation">,</span> and specifically
# two kind of inline requests that were anyway illegal<span class="token operator">:</span> an empty request
# or any request that starts with <span class="token string">"/"</span> <span class="token punctuation">(</span>there are no Redis commands starting
# with such a slash<span class="token punctuation">)</span><span class="token punctuation">.</span> Normal RESP2<span class="token operator">/</span>RESP3 requests are completely out of the
# path of the Gopher protocol implementation and are served as usually as well<span class="token punctuation">.</span>
#
# If you open a connection to Redis when Gopher is enabled and send it
# a string like <span class="token string">"/foo"</span><span class="token punctuation">,</span> <span class="token keyword">if</span> there is a key named <span class="token string">"/foo"</span> it is served via the
# Gopher protocol<span class="token punctuation">.</span>
#
# In order to create a real Gopher <span class="token string">"hole"</span> <span class="token punctuation">(</span>the name of a Gopher site in Gopher
# talking<span class="token punctuation">)</span><span class="token punctuation">,</span> you likely need a script like the following<span class="token operator">:</span>
#
#   https<span class="token operator">:</span><span class="token operator">/</span><span class="token operator">/</span>github<span class="token punctuation">.</span>com<span class="token operator">/</span>antirez<span class="token operator">/</span>gopher2redis
#
# <span class="token operator">--</span><span class="token operator">-</span> SECURITY WARNING <span class="token operator">--</span><span class="token operator">-</span>
#
# If you plan to put Redis on the internet in a publicly accessible address
# to server Gopher pages MAKE SURE TO SET A PASSWORD to the instance<span class="token punctuation">.</span>
# Once a password is set<span class="token operator">:</span>
#
#   <span class="token number">1</span><span class="token punctuation">.</span> The Gopher <span class="token function">server</span> <span class="token punctuation">(</span>when enabled<span class="token punctuation">,</span> not by <span class="token keyword">default</span><span class="token punctuation">)</span> will still serve
#      content via Gopher<span class="token punctuation">.</span>
#   <span class="token number">2</span><span class="token punctuation">.</span> However other commands cannot be called before the client will
#      authenticate<span class="token punctuation">.</span>
#
# So use the <span class="token string">'requirepass'</span> option to protect your instance<span class="token punctuation">.</span>
#
# To enable Gopher support uncomment the following line and set
# the option from <span class="token function">no</span> <span class="token punctuation">(</span>the <span class="token keyword">default</span><span class="token punctuation">)</span> to yes<span class="token punctuation">.</span>
#
# gopher<span class="token operator">-</span>enabled no

############################### ADVANCED CONFIG ###############################
# 高级配置
# Hashes are encoded using a memory efficient data structure when they have a
# small number of entries<span class="token punctuation">,</span> and the biggest entry does not exceed a given
# threshold<span class="token punctuation">.</span> These thresholds can be configured using the following directives<span class="token punctuation">.</span>
# 当有少量条目且最大条目不超过给定阈值时，使用内存有效数据结构对哈希进行编码。可以使用以下指令配置这些阈值。
hash<span class="token operator">-</span>max<span class="token operator">-</span>ziplist<span class="token operator">-</span>entries <span class="token number">512</span>
hash<span class="token operator">-</span>max<span class="token operator">-</span>ziplist<span class="token operator">-</span>value <span class="token number">64</span>

# Lists are also encoded in a special way to save a lot of space<span class="token punctuation">.</span>
# The number of entries allowed per internal list node can be specified
# as a fixed maximum size or a maximum number of elements<span class="token punctuation">.</span>
# For a fixed maximum size<span class="token punctuation">,</span> use <span class="token operator">-</span><span class="token number">5</span> through <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> meaning<span class="token operator">:</span>
# <span class="token operator">-</span><span class="token number">5</span><span class="token operator">:</span> max size<span class="token operator">:</span> <span class="token number">64</span> Kb  <span class="token operator">&lt;</span><span class="token operator">--</span> not recommended <span class="token keyword">for</span> normal workloads
# <span class="token operator">-</span><span class="token number">4</span><span class="token operator">:</span> max size<span class="token operator">:</span> <span class="token number">32</span> Kb  <span class="token operator">&lt;</span><span class="token operator">--</span> not recommended
# <span class="token operator">-</span><span class="token number">3</span><span class="token operator">:</span> max size<span class="token operator">:</span> <span class="token number">16</span> Kb  <span class="token operator">&lt;</span><span class="token operator">--</span> probably not recommended
# <span class="token operator">-</span><span class="token number">2</span><span class="token operator">:</span> max size<span class="token operator">:</span> <span class="token number">8</span> Kb   <span class="token operator">&lt;</span><span class="token operator">--</span> good
# <span class="token operator">-</span><span class="token number">1</span><span class="token operator">:</span> max size<span class="token operator">:</span> <span class="token number">4</span> Kb   <span class="token operator">&lt;</span><span class="token operator">--</span> good
# Positive numbers mean store up to _exactly_ that number of elements
# per list node<span class="token punctuation">.</span>
# The highest performing option is usually <span class="token operator">-</span><span class="token function">2</span> <span class="token punctuation">(</span><span class="token number">8</span> Kb size<span class="token punctuation">)</span> or <span class="token operator">-</span><span class="token function">1</span> <span class="token punctuation">(</span><span class="token number">4</span> Kb size<span class="token punctuation">)</span><span class="token punctuation">,</span>
# but <span class="token keyword">if</span> your use <span class="token keyword">case</span> is unique<span class="token punctuation">,</span> adjust the settings as necessary<span class="token punctuation">.</span>
list<span class="token operator">-</span>max<span class="token operator">-</span>ziplist<span class="token operator">-</span>size <span class="token operator">-</span><span class="token number">2</span>

# Lists may also be compressed<span class="token punctuation">.</span>
# Compress depth is the number of quicklist ziplist nodes from <span class="token operator">*</span>each<span class="token operator">*</span> side of
# the list to <span class="token operator">*</span>exclude<span class="token operator">*</span> from compression<span class="token punctuation">.</span>  The head and tail of the list
# are always uncompressed <span class="token keyword">for</span> fast push<span class="token operator">/</span>pop operations<span class="token punctuation">.</span>  Settings are<span class="token operator">:</span>
# <span class="token number">0</span><span class="token operator">:</span> disable all list compression
# <span class="token number">1</span><span class="token operator">:</span> depth <span class="token number">1</span> means "don't start compressing until after <span class="token number">1</span> node into the list<span class="token punctuation">,</span>
#    going from either the head or tail"
#    So<span class="token operator">:</span> <span class="token punctuation">[</span>head<span class="token punctuation">]</span><span class="token operator">-</span><span class="token operator">></span>node<span class="token operator">-</span><span class="token operator">></span>node<span class="token operator">-</span><span class="token operator">></span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>-<span class="token operator">></span>node<span class="token operator">-</span><span class="token operator">></span><span class="token punctuation">[</span>tail<span class="token punctuation">]</span>
#    <span class="token punctuation">[</span>head<span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span>tail<span class="token punctuation">]</span> will always be uncompressed<span class="token punctuation">;</span> inner nodes will compress<span class="token punctuation">.</span>
# <span class="token number">2</span><span class="token operator">:</span> <span class="token punctuation">[</span>head<span class="token punctuation">]</span><span class="token operator">-</span><span class="token operator">></span><span class="token punctuation">[</span>next<span class="token punctuation">]</span><span class="token operator">-</span><span class="token operator">></span>node<span class="token operator">-</span><span class="token operator">></span>node<span class="token operator">-</span><span class="token operator">></span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>-<span class="token operator">></span>node<span class="token operator">-</span><span class="token operator">></span><span class="token punctuation">[</span>prev<span class="token punctuation">]</span><span class="token operator">-</span><span class="token operator">></span><span class="token punctuation">[</span>tail<span class="token punctuation">]</span>
#    <span class="token number">2</span> here means<span class="token operator">:</span> don't compress head or head<span class="token operator">-</span><span class="token operator">></span>next or tail<span class="token operator">-</span><span class="token operator">></span>prev or tail<span class="token punctuation">,</span>
#    but compress all nodes between them<span class="token punctuation">.</span>
# <span class="token number">3</span><span class="token operator">:</span> <span class="token punctuation">[</span>head<span class="token punctuation">]</span><span class="token operator">-</span><span class="token operator">></span><span class="token punctuation">[</span>next<span class="token punctuation">]</span><span class="token operator">-</span><span class="token operator">></span><span class="token punctuation">[</span>next<span class="token punctuation">]</span><span class="token operator">-</span><span class="token operator">></span>node<span class="token operator">-</span><span class="token operator">></span>node<span class="token operator">-</span><span class="token operator">></span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>-<span class="token operator">></span>node<span class="token operator">-</span><span class="token operator">></span><span class="token punctuation">[</span>prev<span class="token punctuation">]</span><span class="token operator">-</span><span class="token operator">></span><span class="token punctuation">[</span>prev<span class="token punctuation">]</span><span class="token operator">-</span><span class="token operator">></span><span class="token punctuation">[</span>tail<span class="token punctuation">]</span>
# etc<span class="token punctuation">.</span>
list<span class="token operator">-</span>compress<span class="token operator">-</span>depth <span class="token number">0</span>

# Sets have a special encoding in just one <span class="token keyword">case</span><span class="token operator">:</span> when a set is composed
# of just strings that happen to be integers in radix <span class="token number">10</span> in the range
# of <span class="token number">64</span> bit signed integers<span class="token punctuation">.</span>
# The following configuration setting sets the limit in the size of the
# set in order to use <span class="token keyword">this</span> special memory saving encoding<span class="token punctuation">.</span>
set<span class="token operator">-</span>max<span class="token operator">-</span>intset<span class="token operator">-</span>entries <span class="token number">512</span>

# Similarly to hashes and lists<span class="token punctuation">,</span> sorted sets are also specially encoded in
# order to save a lot of space<span class="token punctuation">.</span> This encoding is only used when the length and
# elements of a sorted set are below the following limits<span class="token operator">:</span>
zset<span class="token operator">-</span>max<span class="token operator">-</span>ziplist<span class="token operator">-</span>entries <span class="token number">128</span>
zset<span class="token operator">-</span>max<span class="token operator">-</span>ziplist<span class="token operator">-</span>value <span class="token number">64</span>

# HyperLogLog sparse representation bytes limit<span class="token punctuation">.</span> The limit includes the
# <span class="token number">16</span> bytes header<span class="token punctuation">.</span> When an HyperLogLog using the sparse representation crosses
# <span class="token keyword">this</span> limit<span class="token punctuation">,</span> it is converted into the dense representation<span class="token punctuation">.</span>
#
# A value greater than <span class="token number">16000</span> is totally useless<span class="token punctuation">,</span> since at that point the
# dense representation is more memory efficient<span class="token punctuation">.</span>
#
# The suggested value is <span class="token operator">~</span> <span class="token number">3000</span> in order to have the benefits of
# the space efficient encoding without slowing down too much PFADD<span class="token punctuation">,</span>
# which is <span class="token function">O</span><span class="token punctuation">(</span>N<span class="token punctuation">)</span> with the sparse encoding<span class="token punctuation">.</span> The value can be raised to
# <span class="token operator">~</span> <span class="token number">10000</span> when CPU is not a concern<span class="token punctuation">,</span> but space is<span class="token punctuation">,</span> and the data set is
# composed of many HyperLogLogs with cardinality in the <span class="token number">0</span> <span class="token operator">-</span> <span class="token number">15000</span> range<span class="token punctuation">.</span>
hll<span class="token operator">-</span>sparse<span class="token operator">-</span>max<span class="token operator">-</span>bytes <span class="token number">3000</span>

# Streams macro node max size <span class="token operator">/</span> items<span class="token punctuation">.</span> The stream data structure is a radix
# tree of big nodes that encode multiple items inside<span class="token punctuation">.</span> Using <span class="token keyword">this</span> configuration
# it is possible to configure how big a single node can be in bytes<span class="token punctuation">,</span> and the
# maximum number of items it may contain before switching to a <span class="token keyword">new</span> <span class="token class-name">node</span> when
# appending <span class="token keyword">new</span> <span class="token class-name">stream</span> entries<span class="token punctuation">.</span> If any of the following settings are set to
# zero<span class="token punctuation">,</span> the limit is ignored<span class="token punctuation">,</span> so <span class="token keyword">for</span> instance it is possible to set just a
# max entires limit by setting max<span class="token operator">-</span>bytes to <span class="token number">0</span> and max<span class="token operator">-</span>entries to the desired
# value<span class="token punctuation">.</span>
stream<span class="token operator">-</span>node<span class="token operator">-</span>max<span class="token operator">-</span>bytes <span class="token number">4096</span>
stream<span class="token operator">-</span>node<span class="token operator">-</span>max<span class="token operator">-</span>entries <span class="token number">100</span>

# Active rehashing uses <span class="token number">1</span> millisecond every <span class="token number">100</span> milliseconds of CPU time in
# order to help rehashing the main Redis hash <span class="token function">table</span> <span class="token punctuation">(</span>the one mapping top<span class="token operator">-</span>level
# keys to values<span class="token punctuation">)</span><span class="token punctuation">.</span> The hash table implementation Redis <span class="token function">uses</span> <span class="token punctuation">(</span>see dict<span class="token punctuation">.</span>c<span class="token punctuation">)</span>
# performs a lazy rehashing<span class="token operator">:</span> the more operation you run into a hash table
# that is rehashing<span class="token punctuation">,</span> the more rehashing <span class="token string">"steps"</span> are performed<span class="token punctuation">,</span> so <span class="token keyword">if</span> the
# server is idle the rehashing is never complete and some more memory is used
# by the hash table<span class="token punctuation">.</span>
#
# The <span class="token keyword">default</span> is to use <span class="token keyword">this</span> millisecond <span class="token number">10</span> times every second in order to
# actively rehash the main dictionaries<span class="token punctuation">,</span> freeing memory when possible<span class="token punctuation">.</span>
#
# If unsure<span class="token operator">:</span>
# use <span class="token string">"activerehashing no"</span> <span class="token keyword">if</span> you have hard latency requirements and it is
# not a good thing in your environment that Redis can reply from time to time
# to queries with <span class="token number">2</span> milliseconds delay<span class="token punctuation">.</span>
# 当你的使用场景中，有非常严格的实时性需要，不能够接受Redis时不时的对请求有<span class="token number">2</span>毫秒的延迟的话，把这项配置为no

# use <span class="token string">"activerehashing yes"</span> <span class="token keyword">if</span> you don't have such hard requirements but
# want to free memory asap when possible<span class="token punctuation">.</span>
# 如果没有这么严格的实时性要求，可以设置为yes，以便能够尽可能快的释放内存
activerehashing yes

# The client output buffer limits can be used to force disconnection of clients
# that are not reading data from the server fast enough <span class="token keyword">for</span> some <span class="token function">reason</span> <span class="token punctuation">(</span>a
# common reason is that a Pub<span class="token operator">/</span>Sub client can't consume messages as fast as the
# publisher can produce them<span class="token punctuation">)</span><span class="token punctuation">.</span>
#
# The limit can be set differently <span class="token keyword">for</span> the three different classes of clients<span class="token operator">:</span>
#
# normal <span class="token operator">-</span><span class="token operator">></span> normal clients including MONITOR clients
# replica  <span class="token operator">-</span><span class="token operator">></span> replica clients
# pubsub <span class="token operator">-</span><span class="token operator">></span> clients subscribed to at least one pubsub channel or pattern
#
# The syntax of every client<span class="token operator">-</span>output<span class="token operator">-</span>buffer<span class="token operator">-</span>limit directive is the following<span class="token operator">:</span>
#
# client<span class="token operator">-</span>output<span class="token operator">-</span>buffer<span class="token operator">-</span>limit <span class="token operator">&lt;</span><span class="token keyword">class</span><span class="token operator">></span> <span class="token operator">&lt;</span>hard limit<span class="token operator">></span> <span class="token operator">&lt;</span>soft limit<span class="token operator">></span> <span class="token operator">&lt;</span>soft seconds<span class="token operator">></span>
#
# A client is immediately disconnected once the hard limit is reached<span class="token punctuation">,</span> or <span class="token keyword">if</span>
# the soft limit is reached and remains reached <span class="token keyword">for</span> the specified number of
# <span class="token function">seconds</span> <span class="token punctuation">(</span>continuously<span class="token punctuation">)</span><span class="token punctuation">.</span>
# So <span class="token keyword">for</span> instance <span class="token keyword">if</span> the hard limit is <span class="token number">32</span> megabytes and the soft limit is
# <span class="token number">16</span> megabytes <span class="token operator">/</span> <span class="token number">10</span> seconds<span class="token punctuation">,</span> the client will get disconnected immediately
# <span class="token keyword">if</span> the size of the output buffers reach <span class="token number">32</span> megabytes<span class="token punctuation">,</span> but will also get
# disconnected <span class="token keyword">if</span> the client reaches <span class="token number">16</span> megabytes and continuously overcomes
# the limit <span class="token keyword">for</span> <span class="token number">10</span> seconds<span class="token punctuation">.</span>
#
# By <span class="token keyword">default</span> normal clients are not limited because they don't receive data
# without <span class="token function">asking</span> <span class="token punctuation">(</span>in a push way<span class="token punctuation">)</span><span class="token punctuation">,</span> but just after a request<span class="token punctuation">,</span> so only
# asynchronous clients may create a scenario where data is requested faster
# than it can read<span class="token punctuation">.</span>
#
# Instead there is a <span class="token keyword">default</span> limit <span class="token keyword">for</span> pubsub and replica clients<span class="token punctuation">,</span> since
# subscribers and replicas receive data in a push fashion<span class="token punctuation">.</span>
#
# Both the hard or the soft limit can be disabled by setting them to zero<span class="token punctuation">.</span>
client<span class="token operator">-</span>output<span class="token operator">-</span>buffer<span class="token operator">-</span>limit normal <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span>
client<span class="token operator">-</span>output<span class="token operator">-</span>buffer<span class="token operator">-</span>limit replica 256mb 64mb <span class="token number">60</span>
client<span class="token operator">-</span>output<span class="token operator">-</span>buffer<span class="token operator">-</span>limit pubsub 32mb 8mb <span class="token number">60</span>

# Client query buffers accumulate <span class="token keyword">new</span> <span class="token class-name">commands<span class="token punctuation">.</span></span> They are limited to a fixed
# amount by <span class="token keyword">default</span> in order to avoid that a protocol <span class="token function">desynchronization</span> <span class="token punctuation">(</span><span class="token keyword">for</span>
# instance due to a bug in the client<span class="token punctuation">)</span> will lead to unbound memory usage in
# the query buffer<span class="token punctuation">.</span> However you can configure it here <span class="token keyword">if</span> you have very special
# needs<span class="token punctuation">,</span> such us huge multi<span class="token operator">/</span>exec requests or alike<span class="token punctuation">.</span>
#
# client<span class="token operator">-</span>query<span class="token operator">-</span>buffer<span class="token operator">-</span>limit 1gb

# In the Redis protocol<span class="token punctuation">,</span> bulk requests<span class="token punctuation">,</span> that are<span class="token punctuation">,</span> elements representing single
# strings<span class="token punctuation">,</span> are normally limited ot <span class="token number">512</span> mb<span class="token punctuation">.</span> However you can change <span class="token keyword">this</span> limit
# here<span class="token punctuation">.</span>
#
# proto<span class="token operator">-</span>max<span class="token operator">-</span>bulk<span class="token operator">-</span>len 512mb

# Redis calls an internal function to perform many background tasks<span class="token punctuation">,</span> like
# closing connections of clients in timeout<span class="token punctuation">,</span> purging expired keys that are
# never requested<span class="token punctuation">,</span> and so forth<span class="token punctuation">.</span>
#
# Not all tasks are performed with the same frequency<span class="token punctuation">,</span> but Redis checks <span class="token keyword">for</span>
# tasks to perform according to the specified <span class="token string">"hz"</span> value<span class="token punctuation">.</span>
#
# By <span class="token keyword">default</span> <span class="token string">"hz"</span> is set to <span class="token number">10</span><span class="token punctuation">.</span> Raising the value will use more CPU when
# Redis is idle<span class="token punctuation">,</span> but at the same time will make Redis more responsive when
# there are many keys expiring at the same time<span class="token punctuation">,</span> and timeouts may be
# handled with more precision<span class="token punctuation">.</span>
#
# The range is between <span class="token number">1</span> and <span class="token number">500</span><span class="token punctuation">,</span> however a value over <span class="token number">100</span> is usually not
# a good idea<span class="token punctuation">.</span> Most users should use the <span class="token keyword">default</span> of <span class="token number">10</span> and raise <span class="token keyword">this</span> up to
# <span class="token number">100</span> only in environments where very low latency is required<span class="token punctuation">.</span>
hz <span class="token number">10</span>

# Normally it is useful to have an HZ value which is proportional to the
# number of clients connected<span class="token punctuation">.</span> This is useful in order<span class="token punctuation">,</span> <span class="token keyword">for</span> instance<span class="token punctuation">,</span> to
# avoid too many clients are processed <span class="token keyword">for</span> each background task invocation
# in order to avoid latency spikes<span class="token punctuation">.</span>
#
# Since the <span class="token keyword">default</span> HZ value by <span class="token keyword">default</span> is conservatively set to <span class="token number">10</span><span class="token punctuation">,</span> Redis
# offers<span class="token punctuation">,</span> and enables by <span class="token keyword">default</span><span class="token punctuation">,</span> the ability to use an adaptive HZ value
# which will temporary raise when there are many connected clients<span class="token punctuation">.</span>
#
# When dynamic HZ is enabled<span class="token punctuation">,</span> the actual configured HZ will be used
# as a baseline<span class="token punctuation">,</span> but multiples of the configured HZ value will be actually
# used as needed once more clients are connected<span class="token punctuation">.</span> In <span class="token keyword">this</span> way an idle
# instance will use very little CPU time <span class="token keyword">while</span> a busy instance will be
# more responsive<span class="token punctuation">.</span>
dynamic<span class="token operator">-</span>hz yes

# When a child rewrites the AOF file<span class="token punctuation">,</span> <span class="token keyword">if</span> the following option is enabled
# the file will be fsync<span class="token operator">-</span>ed every <span class="token number">32</span> MB of data generated<span class="token punctuation">.</span> This is useful
# in order to commit the file to the disk more incrementally and avoid
# big latency spikes<span class="token punctuation">.</span>
aof<span class="token operator">-</span>rewrite<span class="token operator">-</span>incremental<span class="token operator">-</span>fsync yes

# When redis saves RDB file<span class="token punctuation">,</span> <span class="token keyword">if</span> the following option is enabled
# the file will be fsync<span class="token operator">-</span>ed every <span class="token number">32</span> MB of data generated<span class="token punctuation">.</span> This is useful
# in order to commit the file to the disk more incrementally and avoid
# big latency spikes<span class="token punctuation">.</span>
rdb<span class="token operator">-</span>save<span class="token operator">-</span>incremental<span class="token operator">-</span>fsync yes

# Redis LFU <span class="token function">eviction</span> <span class="token punctuation">(</span>see maxmemory setting<span class="token punctuation">)</span> can be tuned<span class="token punctuation">.</span> However it is a good
# idea to start with the <span class="token keyword">default</span> settings and only change them after investigating
# how to improve the performances and how the keys LFU change over time<span class="token punctuation">,</span> which
# is possible to inspect via the OBJECT FREQ command<span class="token punctuation">.</span>
#
# There are two tunable parameters in the Redis LFU implementation<span class="token operator">:</span> the
# counter logarithm factor and the counter decay time<span class="token punctuation">.</span> It is important to
# understand what the two parameters mean before changing them<span class="token punctuation">.</span>
#
# The LFU counter is just <span class="token number">8</span> bits per key<span class="token punctuation">,</span> it's maximum value is <span class="token number">255</span><span class="token punctuation">,</span> so Redis
# uses a probabilistic increment with logarithmic behavior<span class="token punctuation">.</span> Given the value
# of the old counter<span class="token punctuation">,</span> when a key is accessed<span class="token punctuation">,</span> the counter is incremented in
# <span class="token keyword">this</span> way<span class="token operator">:</span>
#
# <span class="token number">1</span><span class="token punctuation">.</span> A random number R between <span class="token number">0</span> and <span class="token number">1</span> is extracted<span class="token punctuation">.</span>
# <span class="token number">2</span><span class="token punctuation">.</span> A probability P is calculated as <span class="token number">1</span><span class="token operator">/</span><span class="token punctuation">(</span>old_value<span class="token operator">*</span>lfu_log_factor<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>
# <span class="token number">3</span><span class="token punctuation">.</span> The counter is incremented only <span class="token keyword">if</span> R <span class="token operator">&lt;</span> P<span class="token punctuation">.</span>
#
# The <span class="token keyword">default</span> lfu<span class="token operator">-</span>log<span class="token operator">-</span>factor is <span class="token number">10</span><span class="token punctuation">.</span> This is a table of how the frequency
# counter changes with a different number of accesses with different
# logarithmic factors<span class="token operator">:</span>
#
# <span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span>
# <span class="token operator">|</span> factor <span class="token operator">|</span> <span class="token number">100</span> hits   <span class="token operator">|</span> <span class="token number">1000</span> hits  <span class="token operator">|</span> 100K hits  <span class="token operator">|</span> 1M hits    <span class="token operator">|</span> 10M hits   <span class="token operator">|</span>
# <span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span>
# <span class="token operator">|</span> <span class="token number">0</span>      <span class="token operator">|</span> <span class="token number">104</span>        <span class="token operator">|</span> <span class="token number">255</span>        <span class="token operator">|</span> <span class="token number">255</span>        <span class="token operator">|</span> <span class="token number">255</span>        <span class="token operator">|</span> <span class="token number">255</span>        <span class="token operator">|</span>
# <span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span>
# <span class="token operator">|</span> <span class="token number">1</span>      <span class="token operator">|</span> <span class="token number">18</span>         <span class="token operator">|</span> <span class="token number">49</span>         <span class="token operator">|</span> <span class="token number">255</span>        <span class="token operator">|</span> <span class="token number">255</span>        <span class="token operator">|</span> <span class="token number">255</span>        <span class="token operator">|</span>
# <span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span>
# <span class="token operator">|</span> <span class="token number">10</span>     <span class="token operator">|</span> <span class="token number">10</span>         <span class="token operator">|</span> <span class="token number">18</span>         <span class="token operator">|</span> <span class="token number">142</span>        <span class="token operator">|</span> <span class="token number">255</span>        <span class="token operator">|</span> <span class="token number">255</span>        <span class="token operator">|</span>
# <span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span>
# <span class="token operator">|</span> <span class="token number">100</span>    <span class="token operator">|</span> <span class="token number">8</span>          <span class="token operator">|</span> <span class="token number">11</span>         <span class="token operator">|</span> <span class="token number">49</span>         <span class="token operator">|</span> <span class="token number">143</span>        <span class="token operator">|</span> <span class="token number">255</span>        <span class="token operator">|</span>
# <span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">+</span>
#
# NOTE<span class="token operator">:</span> The above table was obtained by running the following commands<span class="token operator">:</span>
#
#   redis<span class="token operator">-</span>benchmark <span class="token operator">-</span>n <span class="token number">1000000</span> incr foo
#   redis<span class="token operator">-</span>cli object freq foo
#
# NOTE <span class="token number">2</span><span class="token operator">:</span> The counter initial value is <span class="token number">5</span> in order to give <span class="token keyword">new</span> <span class="token class-name">objects</span> a chance
# to accumulate hits<span class="token punctuation">.</span>
#
# The counter decay time is the time<span class="token punctuation">,</span> in minutes<span class="token punctuation">,</span> that must elapse in order
# <span class="token keyword">for</span> the key counter to be divided by <span class="token function">two</span> <span class="token punctuation">(</span>or decremented <span class="token keyword">if</span> it has a value
# less <span class="token operator">&lt;=</span> <span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">.</span>
# 计数器衰减时间是键计数器除以<span class="token function">2</span><span class="token punctuation">(</span>如果值小于<span class="token operator">&lt;=</span> <span class="token number">10</span>，则衰减<span class="token punctuation">)</span>所必须经过的时间<span class="token punctuation">(</span>以分钟为单位<span class="token punctuation">)</span>。
# The <span class="token keyword">default</span> value <span class="token keyword">for</span> the lfu<span class="token operator">-</span>decay<span class="token operator">-</span>time is <span class="token number">1</span><span class="token punctuation">.</span> A Special value of <span class="token number">0</span> means to
# decay the counter every time it happens to be scanned<span class="token punctuation">.</span>
# lfu<span class="token operator">-</span>decay<span class="token operator">-</span>time的默认值是<span class="token number">1</span>。一个特殊的值<span class="token number">0</span>表示在每次扫描计数器时对其进行衰减。
# lfu<span class="token operator">-</span>log<span class="token operator">-</span>factor <span class="token number">10</span>
# lfu<span class="token operator">-</span>decay<span class="token operator">-</span>time <span class="token number">1</span>

########################### ACTIVE DEFRAGMENTATION #######################
#
# What is active defragmentation<span class="token operator">?</span>
# <span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">-</span>
#
# <span class="token function">Active</span> <span class="token punctuation">(</span>online<span class="token punctuation">)</span> defragmentation allows a Redis server to compact the
# spaces left between small allocations and deallocations of data in memory<span class="token punctuation">,</span>
# thus allowing to reclaim back memory<span class="token punctuation">.</span>
#
# Fragmentation is a natural process that happens with every <span class="token function">allocator</span> <span class="token punctuation">(</span>but
# less so with Jemalloc<span class="token punctuation">,</span> fortunately<span class="token punctuation">)</span> and certain workloads<span class="token punctuation">.</span> Normally a server
# restart is needed in order to lower the fragmentation<span class="token punctuation">,</span> or at least to flush
# away all the data and create it again<span class="token punctuation">.</span> However thanks to <span class="token keyword">this</span> feature
# implemented by Oran Agra <span class="token keyword">for</span> Redis <span class="token number">4.0</span> <span class="token keyword">this</span> process can happen at runtime
# in an <span class="token string">"hot"</span> way<span class="token punctuation">,</span> <span class="token keyword">while</span> the server is running<span class="token punctuation">.</span>
#
# Basically when the fragmentation is over a certain <span class="token function">level</span> <span class="token punctuation">(</span>see the
# configuration options below<span class="token punctuation">)</span> Redis will start to create <span class="token keyword">new</span> <span class="token class-name">copies</span> of the
# values in contiguous memory regions by exploiting certain specific Jemalloc
# <span class="token function">features</span> <span class="token punctuation">(</span>in order to understand <span class="token keyword">if</span> an allocation is causing fragmentation
# and to allocate it in a better place<span class="token punctuation">)</span><span class="token punctuation">,</span> and at the same time<span class="token punctuation">,</span> will release the
# old copies of the data<span class="token punctuation">.</span> This process<span class="token punctuation">,</span> repeated incrementally <span class="token keyword">for</span> all the keys
# will cause the fragmentation to drop back to normal values<span class="token punctuation">.</span>
#
# Important things to understand<span class="token operator">:</span>
#
# <span class="token number">1</span><span class="token punctuation">.</span> This feature is disabled by <span class="token keyword">default</span><span class="token punctuation">,</span> and only works <span class="token keyword">if</span> you compiled Redis
#    to use the copy of Jemalloc we ship with the source code of Redis<span class="token punctuation">.</span>
#    This is the <span class="token keyword">default</span> with Linux builds<span class="token punctuation">.</span>
#
# <span class="token number">2</span><span class="token punctuation">.</span> You never need to enable <span class="token keyword">this</span> feature <span class="token keyword">if</span> you don't have fragmentation
#    issues<span class="token punctuation">.</span>
#
# <span class="token number">3</span><span class="token punctuation">.</span> Once you experience fragmentation<span class="token punctuation">,</span> you can enable <span class="token keyword">this</span> feature when
#    needed with the command <span class="token string">"CONFIG SET activedefrag yes"</span><span class="token punctuation">.</span>
#
# The configuration parameters are able to fine tune the behavior of the
# defragmentation process<span class="token punctuation">.</span> If you are not sure about what they mean it is
# a good idea to leave the defaults untouched<span class="token punctuation">.</span>

# Enabled active defragmentation
# activedefrag no

# Minimum amount of fragmentation waste to start active defrag
# active<span class="token operator">-</span>defrag<span class="token operator">-</span>ignore<span class="token operator">-</span>bytes 100mb

# Minimum percentage of fragmentation to start active defrag
# active<span class="token operator">-</span>defrag<span class="token operator">-</span>threshold<span class="token operator">-</span>lower <span class="token number">10</span>

# Maximum percentage of fragmentation at which we use maximum effort
# active<span class="token operator">-</span>defrag<span class="token operator">-</span>threshold<span class="token operator">-</span>upper <span class="token number">100</span>

# Minimal effort <span class="token keyword">for</span> defrag in CPU percentage<span class="token punctuation">,</span> to be used when the lower
# threshold is reached
# active<span class="token operator">-</span>defrag<span class="token operator">-</span>cycle<span class="token operator">-</span>min <span class="token number">1</span>

# Maximal effort <span class="token keyword">for</span> defrag in CPU percentage<span class="token punctuation">,</span> to be used when the upper
# threshold is reached
# active<span class="token operator">-</span>defrag<span class="token operator">-</span>cycle<span class="token operator">-</span>max <span class="token number">25</span>

# Maximum number of set<span class="token operator">/</span>hash<span class="token operator">/</span>zset<span class="token operator">/</span>list fields that will be processed from
# the main dictionary scan
# active<span class="token operator">-</span>defrag<span class="token operator">-</span>max<span class="token operator">-</span>scan<span class="token operator">-</span>fields <span class="token number">1000</span>

# Jemalloc background thread <span class="token keyword">for</span> purging will be enabled by <span class="token keyword">default</span>
jemalloc<span class="token operator">-</span>bg<span class="token operator">-</span>thread yes

# It is possible to pin different threads and processes of Redis to specific
# CPUs in your system<span class="token punctuation">,</span> in order to maximize the performances of the server<span class="token punctuation">.</span>
# This is useful both in order to pin different Redis threads in different
# CPUs<span class="token punctuation">,</span> but also in order to make sure that multiple Redis instances running
# in the same host will be pinned to different CPUs<span class="token punctuation">.</span>
#
# Normally you can <span class="token keyword">do</span> <span class="token keyword">this</span> using the <span class="token string">"taskset"</span> command<span class="token punctuation">,</span> however it is also
# possible to <span class="token keyword">this</span> via Redis configuration directly<span class="token punctuation">,</span> both in Linux and FreeBSD<span class="token punctuation">.</span>
#
# You can pin the server<span class="token operator">/</span>IO threads<span class="token punctuation">,</span> bio threads<span class="token punctuation">,</span> aof rewrite child process<span class="token punctuation">,</span> and
# the bgsave child process<span class="token punctuation">.</span> The syntax to specify the cpu list is the same as
# the taskset command<span class="token operator">:</span>
#
# Set redis server<span class="token operator">/</span>io threads to cpu affinity <span class="token number">0</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">6</span><span class="token operator">:</span>
# server_cpulist <span class="token number">0</span><span class="token operator">-</span><span class="token number">7</span><span class="token operator">:</span><span class="token number">2</span>
#
# Set bio threads to cpu affinity <span class="token number">1</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token operator">:</span>
# bio_cpulist <span class="token number">1</span><span class="token punctuation">,</span><span class="token number">3</span>
#
# Set aof rewrite child process to cpu affinity <span class="token number">8</span><span class="token punctuation">,</span><span class="token number">9</span><span class="token punctuation">,</span><span class="token number">10</span><span class="token punctuation">,</span><span class="token number">11</span><span class="token operator">:</span>
# aof_rewrite_cpulist <span class="token number">8</span><span class="token operator">-</span><span class="token number">11</span>
#
# Set bgsave child process to cpu affinity <span class="token number">1</span><span class="token punctuation">,</span><span class="token number">10</span><span class="token punctuation">,</span><span class="token number">11</span>
# bgsave_cpulist <span class="token number">1</span><span class="token punctuation">,</span><span class="token number">10</span><span class="token operator">-</span><span class="token number">11</span>
</code></pre>

            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        文章作者:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/about" rel="external nofollow noreferrer">GMaya</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        文章链接:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://gmaya.top/2020/20200522/">https://gmaya.top/2020/20200522/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        版权声明:
                    </i>
                </span>
                <span class="reprint-info">
                    本博客所有文章除特別声明外，均采用
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    许可协议。转载请注明来源
                    <a href="/about" target="_blank">GMaya</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/tags/Redis/">
                                    <span class="chip bg-color">Redis</span>
                                </a>
                            
                                <a href="/tags/%E6%96%B0%E7%89%B9%E6%80%A7/">
                                    <span class="chip bg-color">新特性</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/libs/share/css/share.min.css">
<div id="article-share">

    

    

</div>

                </div>
            </div>
            
                <style>
    #reward {
        margin: 40px 0;
        text-align: center;
    }

    #reward .reward-link {
        font-size: 1.4rem;
        line-height: 38px;
    }

    #reward .btn-floating:hover {
        box-shadow: 0 6px 12px rgba(0, 0, 0, 0.2), 0 5px 15px rgba(0, 0, 0, 0.2);
    }

    #rewardModal {
        width: 320px;
        height: 350px;
    }

    #rewardModal .reward-title {
        margin: 15px auto;
        padding-bottom: 5px;
    }

    #rewardModal .modal-content {
        padding: 10px;
    }

    #rewardModal .close {
        position: absolute;
        right: 15px;
        top: 15px;
        color: rgba(0, 0, 0, 0.5);
        font-size: 1.3rem;
        line-height: 20px;
        cursor: pointer;
    }

    #rewardModal .close:hover {
        color: #ef5350;
        transform: scale(1.3);
        -moz-transform:scale(1.3);
        -webkit-transform:scale(1.3);
        -o-transform:scale(1.3);
    }

    #rewardModal .reward-tabs {
        margin: 0 auto;
        width: 210px;
    }

    .reward-tabs .tabs {
        height: 38px;
        margin: 10px auto;
        padding-left: 0;
    }

    .reward-content ul {
        padding-left: 0 !important;
    }

    .reward-tabs .tabs .tab {
        height: 38px;
        line-height: 38px;
    }

    .reward-tabs .tab a {
        color: #fff;
        background-color: #ccc;
    }

    .reward-tabs .tab a:hover {
        background-color: #ccc;
        color: #fff;
    }

    .reward-tabs .wechat-tab .active {
        color: #fff !important;
        background-color: #22AB38 !important;
    }

    .reward-tabs .alipay-tab .active {
        color: #fff !important;
        background-color: #019FE8 !important;
    }

    .reward-tabs .reward-img {
        width: 210px;
        height: 210px;
    }
</style>

<div id="reward">
    <a href="#rewardModal" class="reward-link modal-trigger btn-floating btn-medium waves-effect waves-light red">赏</a>

    <!-- Modal Structure -->
    <div id="rewardModal" class="modal">
        <div class="modal-content">
            <a class="close modal-close"><i class="fas fa-times"></i></a>
            <h4 class="reward-title">请作者喝杯奶茶吧ヾﾉ≧∀≦)o</h4>
            <div class="reward-content">
                <div class="reward-tabs">
                    <ul class="tabs row">
                        <li class="tab col s6 alipay-tab waves-effect waves-light"><a href="#alipay">支付宝</a></li>
                        <li class="tab col s6 wechat-tab waves-effect waves-light"><a href="#wechat">微 信</a></li>
                    </ul>
                    <div id="alipay">
                        <img src="/medias/reward/AliPayQR.jpg" class="reward-img" alt="支付宝打赏二维码">
                    </div>
                    <div id="wechat">
                        <img src="/medias/reward/WeChatQR.png" class="reward-img" alt="微信打赏二维码">
                    </div>
                </div>
            </div>
        </div>
    </div>
</div>

<script>
    $(function () {
        $('.tabs').tabs();
    });
</script>

            
        </div>
    </div>

    

    

    

    
    <div class="livere-card card" data-aos="fade-up">
    <!-- 来必力City版安装代码 -->
    <div id="lv-container" class="card-content" data-id="city" data-uid="MTAyMC80ODA4Ni8yNDU4Mw==">
        <script type="text/javascript">
            (function (d, s) {
                let j, e = d.getElementsByTagName(s)[0];
                if (typeof LivereTower === 'function') {
                    return;
                }

                j = d.createElement(s);
                j.src = 'https://cdn-city.livere.com/js/embed.dist.js';
                j.async = true;

                e.parentNode.insertBefore(j, e);
            })(document, 'script');
        </script>
        <noscript>为正常使用来必力评论功能请激活JavaScript。</noscript>
    </div>
    <!-- City版安装代码已完成 -->
</div>
    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="far fa-dot-circle"></i>&nbsp;本篇
            </div>
            <div class="card">
                <a href="/2020/20200522/">
                    <div class="card-image">
                        
                        <img src="https://s1.wailian.download/2020/05/22/ReichenbachFalls_ZH-CN7578535270_1920x1080.jpg" class="responsive-img" alt="手撕Redis6.0">
                        
                        <span class="card-title">手撕Redis6.0</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            简介
Redis 是完全开源免费的，遵守BSD协议，是一个高性能的key-value数据库。性能极高： Redis能读的速度是110000次/s,写的速度是81000次/s 。

安装Linux下安装Redis。去年好像写过一次。。。传送门
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2020-05-22
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/Redis/" class="post-category">
                                    Redis
                                </a>
                            
                            
                        </span>
                    </div>
                </div>

                
                <div class="card-action article-tags">
                    
                    <a href="/tags/Redis/">
                        <span class="chip bg-color">Redis</span>
                    </a>
                    
                    <a href="/tags/%E6%96%B0%E7%89%B9%E6%80%A7/">
                        <span class="chip bg-color">新特性</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                下一篇&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/2020/20200518/">
                    <div class="card-image">
                        
                        
                        <img src="/medias/featureimages/8.jpg" class="responsive-img" alt="Yapi的安装与使用">
                        
                        <span class="card-title">Yapi的安装与使用</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            前言
YApi 是高效、易用、功能强大的 api 管理平台，旨在为开发、产品、测试人员提供更优雅的接口管理服务。可以帮助开发者轻松创建、发布、维护 API，YApi 还为用户提供了优秀的交互体验，开发人员只需利用平台提供的接口数据写入工具以
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2020-05-18
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/%E5%B7%A5%E5%85%B7/" class="post-category">
                                    工具
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/%E5%B7%A5%E5%85%B7/">
                        <span class="chip bg-color">工具</span>
                    </a>
                    
                    <a href="/tags/Yapi/">
                        <span class="chip bg-color">Yapi</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>


<script>
    $('#articleContent').on('copy', function (e) {
        // IE8 or earlier browser is 'undefined'
        if (typeof window.getSelection === 'undefined') return;

        var selection = window.getSelection();
        // if the selection is short let's not annoy our users.
        if (('' + selection).length < Number.parseInt('120')) {
            return;
        }

        // create a div outside of the visible area and fill it with the selected text.
        var bodyElement = document.getElementsByTagName('body')[0];
        var newdiv = document.createElement('div');
        newdiv.style.position = 'absolute';
        newdiv.style.left = '-99999px';
        bodyElement.appendChild(newdiv);
        newdiv.appendChild(selection.getRangeAt(0).cloneContents());

        // we need a <pre> tag workaround.
        // otherwise the text inside "pre" loses all the line breaks!
        if (selection.getRangeAt(0).commonAncestorContainer.nodeName === 'PRE') {
            newdiv.innerHTML = "<pre>" + newdiv.innerHTML + "</pre>";
        }

        var url = document.location.href;
        newdiv.innerHTML += '<br />'
            + '来源: GMaya<br />'
            + '文章作者: GMaya<br />'
            + '文章链接: <a href="' + url + '">' + url + '</a><br />'
            + '本文章著作权归作者所有，任何形式的转载都请注明出处。';

        selection.selectAllChildren(newdiv);
        window.setTimeout(function () {bodyElement.removeChild(newdiv);}, 200);
    });
</script>


<!-- 代码块功能依赖 -->
<script type="text/javascript" src="/libs/codeBlock/codeBlockFuction.js"></script>

<!-- 代码语言 -->


<!-- 代码块复制 -->

<script type="text/javascript" src="/libs/codeBlock/codeCopy.js"></script>


<!-- 代码块收缩 -->

<script type="text/javascript" src="/libs/codeBlock/codeShrink.js"></script>


<!-- 代码块折行 -->

<style type="text/css">
code[class*="language-"], pre[class*="language-"] { white-space: pre !important; }
</style>


    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('3'),
            headingSelector: 'h2, h3, h4'
        });

        // modify the toc link href to support Chinese.
        let i = 0;
        let tocHeading = 'toc-heading-';
        $('#toc-content a').each(function () {
            $(this).attr('href', '#' + tocHeading + (++i));
        });

        // modify the heading title id to support Chinese.
        i = 0;
        $('#articleContent').children('h2, h3, h4').each(function () {
            $(this).attr('id', tocHeading + (++i));
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>

    

</main>




    <footer class="page-footer bg-color">
    
    <div class="container row center-align" style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            <!-- Copyright&nbsp; -->&copy;
            <span id="year">2019</span>
            <a href="/about" target="_blank">GMaya</a>
            |&nbsp;
			
			<span id="icp"><img src="/medias/icp.png" style="vertical-align: text-bottom;" />
			    <a href="http://www.beian.miit.gov.cn/" target="_blank">豫ICP备20000931号-1</a>
			</span>
			
            |&nbsp;
           <!-- <br> -->
            
            &nbsp;<i class="fas fa-chart-area"></i>&nbsp;总字数:&nbsp;<span
                class="white-color">60.4k</span>&nbsp;字
            
            |&nbsp;
            
            
            
            
            <!-- <br> -->
            
            <span id="sitetime">载入运行时间...</span>
            <script>
                function siteTime() {
                    var seconds = 1000;
                    var minutes = seconds * 60;
                    var hours = minutes * 60;
                    var days = hours * 24;
                    var years = days * 365;
                    var today = new Date();
                    var startYear = "2019";
                    var startMonth = "12";
                    var startDate = "16";
                    var startHour = "0";
                    var startMinute = "0";
                    var startSecond = "0";
                    var todayYear = today.getFullYear();
                    var todayMonth = today.getMonth() + 1;
                    var todayDate = today.getDate();
                    var todayHour = today.getHours();
                    var todayMinute = today.getMinutes();
                    var todaySecond = today.getSeconds();
                    var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                    var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                    var diff = t2 - t1;
                    var diffYears = Math.floor(diff / years);
                    var diffDays = Math.floor((diff / days) - diffYears * 365);
                    var diffHours = Math.floor((diff - (diffYears * 365 + diffDays) * days) / hours);
                    var diffMinutes = Math.floor((diff - (diffYears * 365 + diffDays) * days - diffHours * hours) /
                        minutes);
                    var diffSeconds = Math.floor((diff - (diffYears * 365 + diffDays) * days - diffHours * hours -
                        diffMinutes * minutes) / seconds);
                    if (startYear == todayYear) {
                        document.getElementById("year").innerHTML = todayYear;
                        document.getElementById("sitetime").innerHTML = "运行 " + diffDays + " 天 " + diffHours +
                            " 时 " + diffMinutes + " 分 " + diffSeconds + " 秒";
                    } else {
                        document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                        document.getElementById("sitetime").innerHTML = "运行 " + diffYears + " 年 " + diffDays +
                            " 天 " + diffHours + " 时 " + diffMinutes + " 分 " + diffSeconds + " 秒";
                    }
                }
                setInterval(siteTime, 1000);
            </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link ">
    <a href="https://gitee.com/GMaya" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:gmaya@qq.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>



    <a href="https://blog.csdn.net/gfl1427097103" class="tooltipped" target="_blank" data-tooltip="关注我的CSDN" data-position="top" data-delay="50">
        <i class="fab fa-csdn">C</i>
    </a>







    <a href="tencent://AddContact/?fromId=50&fromSubId=1&subcmd=all&uin=1427097103" class="tooltipped" target="_blank" data-tooltip="QQ联系我: 1427097103" data-position="top" data-delay="50">
        <i class="fab fa-qq"></i>
    </a>







    <a href="/atom.xml" class="tooltipped" target="_blank" data-tooltip="RSS 订阅" data-position="top" data-delay="50">
        <i class="fas fa-rss"></i>
    </a>

</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span>
            <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script src="/js/search.js"></script>
<script type="text/javascript">
$(function () {
    searchFunc("/search.xml", 'searchInput', 'searchResult');
});
</script>

    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/libs/materialize/materialize.min.js"></script>
    <script src="/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/libs/aos/aos.js"></script>
    <script src="/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/js/matery.js"></script>

    <!-- Baidu Analytics -->

<script>
    var _hmt = _hmt || [];
    (function () {
        var hm = document.createElement("script");
        hm.src = "https://hm.baidu.com/hm.js?0e55601a9032e26ff859010f72e59ff7";
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(hm, s);
    })();
</script>

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/libs/others/clicklove.js" async="async"></script>
    
    

    

    

    

    

    

    
    <script src="/libs/instantpage/instantpage.js" type="module"></script>
    

</body>

</html>
